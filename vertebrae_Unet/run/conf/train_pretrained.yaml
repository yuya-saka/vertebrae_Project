# ====================================================================
# Pre-trained U-Net Training Hyperparameters Configuration
# ====================================================================
# This configuration is specifically designed for training models
# with ImageNet pre-trained encoders (ResNet, EfficientNet, etc.)
# ====================================================================

# Training Settings
training:
  max_epochs: 100
  batch_size: 32  # ResNet34 supports up to batch_size=32 with 256x256 images
  num_workers: 8
  accumulate_grad_batches: 1

  # GPU Settings
  accelerator: gpu
  devices: [1]  # GPU number(s): 1, [0], [0,1], etc.

  # Precision
  precision: 16-mixed  # Mixed precision for faster training

  # Gradient Clipping
  gradient_clip_val: 1.0

  # Logging
  log_every_n_steps: 10

  # Validation
  val_check_interval: 1.0  # Check validation every epoch

  # Random Seed
  seed: 42

# Optimizer Settings
optimizer:
  name: adamw
  lr: 0.0001  # Base learning rate (for decoder)
  weight_decay: 0.00001
  betas: [0.9, 0.999]
  use_differential_lr: true  # Enable differential learning rates
  encoder_lr_multiplier: 0.1  # Encoder LR = base_lr * 0.1 = 1e-5

# Learning Rate Scheduler
scheduler:
  name: reduce_lr_on_plateau
  mode: max
  factor: 0.5
  patience: 5
  min_lr: 0.000001
  monitor: val_prauc  # Monitor Precision-Recall AUC

# Loss Function
# For small fracture regions (<1% of image), use 'focal_tversky' loss
# For general segmentation, use 'combined' loss (Dice + BCE)
loss:
  loss_type: focal_tversky  # 'focal_tversky' or 'combined'

  # ----- Focal Tversky Loss Configuration -----
  # Recommended for highly imbalanced segmentation with small target regions

  # Loss combination weights
  focal_tversky_weight: 0.7  # Weight for Focal Tversky Loss
  focal_weight: 0.3          # Weight for Focal Loss

  # Tversky Loss parameters
  # IMPORTANT: For fracture detection, we want to minimize false negatives (missed fractures)
  # Therefore beta should be HIGHER than alpha
  tversky_alpha: 0.3   # Weight for false positives (lower = allow some FP to catch all fractures)
  tversky_beta: 0.7    # Weight for false negatives (higher = penalize FN more, reduce missed fractures)
  tversky_gamma: 0.75  # Focusing parameter for Focal Tversky (higher = focus on hard examples)

  # Focal Loss parameters
  focal_alpha: 0.25    # Weight for positive class (0.25 = give more weight to positive class)
  focal_gamma: 2.0     # Focusing parameter for Focal Loss (higher = focus on hard negatives)

  # Smoothing factor
  smooth: 1.0

# Early Stopping
early_stopping:
  monitor: val_loss
  patience: 20
  mode: min
  min_delta: 0.001

# Model Checkpoint
checkpoint:
  monitor: val_prauc  # Save best model based on PRAUC
  mode: max
  save_top_k: 3
  save_last: true
  filename: 'epoch={epoch:02d}-val_prauc={val_prauc:.4f}'

# Threshold Optimization Settings
threshold_optimization:
  enabled: true
  min_threshold: 0.001  # Minimum threshold to search (low for imbalanced data)
  max_threshold: 0.900  # Maximum threshold to search
  num_candidates: 90    # Number of threshold candidates

# Weights & Biases Configuration
wandb:
  project: segmentation-pretrained-backbone
  entity: null  # Set your W&B entity here
  name: resnet34-unetplusplus-scse-fold0  # Experiment name
  log_model: true
  save_dir: ${dir.output.base}/pretrained/axial/fold_0

# ====================================================================
# Notes on Training with Pre-trained Backbone
# ====================================================================
#
# Differential Learning Rates:
#   When use_differential_lr=true, the optimizer will use:
#   - Encoder: lr * encoder_lr_multiplier = 1e-4 * 0.1 = 1e-5
#   - Decoder: lr = 1e-4
#
#   This is recommended because:
#   - Encoder already has good ImageNet features
#   - Decoder needs to learn from scratch
#
# Batch Size Recommendations:
#   - ResNet34: up to 32 (tested, uses ~8.5 GB GPU memory)
#   - ResNet50: up to 24 (uses ~6.4 GB GPU memory)
#   - EfficientNet-B3: up to 32 (uses ~8.5 GB GPU memory)
#   - If OOM: reduce batch_size or use accumulate_grad_batches
#
# Training Strategy:
#   1. Start with differential learning rates
#   2. If performance plateaus, try increasing encoder LR
#   3. Consider freezing encoder for first few epochs (optional)
#
# Expected Performance Improvement:
#   - Faster convergence: ~20-30% fewer epochs
#   - Better final metrics: +5-10% PRAUC improvement
#   - More stable training: lower validation loss variance
#
# ====================================================================

# Execution command:
# cd vertebrae_Unet
# uv run python run/scripts/train/train.py \
#   model=pretrained_unet \
#   training=train_pretrained



# cd /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/vertebrae_Unet

# uv run python run/scripts/train/train.py \
  #model=pretrained_unet \
  #experiment.name=test_pretrained_resnet34 \
  #training.max_epochs=2 \
  #optimizer.use_differential_lr=true \
  #wandb.project=segmentation-pretrained-backbone \
  #wandb.name=test-pretrained-resnet34-fold0
