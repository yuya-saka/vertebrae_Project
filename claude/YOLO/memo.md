## é€²æ—

---

## 2æ®µéšå­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®è©³ç´°ãƒ¡ãƒ¢ (2025/10/19)

### æ¦‚è¦

YOLO+LSTMãƒ¢ãƒ‡ãƒ«ã¯**2æ®µéšå­¦ç¿’**ã§æ§‹ç¯‰ã—ã¾ã™:
1. **Phase 1**: YOLOã‚’ã‚¹ãƒ©ã‚¤ã‚¹å˜ä½ã§å­¦ç¿’ (å…¨ã‚¹ãƒ©ã‚¤ã‚¹ç‹¬ç«‹)
2. **Phase 2**: LSTMã‚’æ¤ä½“å˜ä½ã§å­¦ç¿’ (YOLOã¯å›ºå®š or ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)

---

## Phase 1: YOLOäº‹å‰å­¦ç¿’

### ç›®çš„
ã‚¹ãƒ©ã‚¤ã‚¹ãƒ¬ãƒ™ãƒ«ã®éª¨æŠ˜æ¤œå‡ºå™¨ã‚’ä½œæˆ

### ãƒ‡ãƒ¼ã‚¿æ§‹æˆ
```python
# å…¨ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦æ‰±ã†
Dataset = [
    # æ‚£è€…1
    (inp1003/vertebra_27/slice_000.nii, bbox_label_000.txt),
    (inp1003/vertebra_27/slice_001.nii, bbox_label_001.txt),
    ...
    (inp1003/vertebra_40/slice_099.nii, bbox_label_099.txt),

    # æ‚£è€…2
    (inp1039/vertebra_27/slice_000.nii, bbox_label_000.txt),
    ...
]

# æ¨å®šã‚µãƒ³ãƒ—ãƒ«æ•°: 38ç—‡ä¾‹ Ã— 14æ¤ä½“/ç—‡ä¾‹ Ã— 70ã‚¹ãƒ©ã‚¤ã‚¹/æ¤ä½“ â‰ˆ 37,000ã‚µãƒ³ãƒ—ãƒ«
```

### æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰² (5-fold CV)
```python
fold_0:
  train: [inp1003, inp1039, ..., inp1078]  # 30ç—‡ä¾‹
  val:   [inp1059, ..., inp1088]           # 8ç—‡ä¾‹

# é‡è¦: åŒã˜æ‚£è€…ã®ã‚¹ãƒ©ã‚¤ã‚¹ãŒ train/val ã«è·¨ãŒã‚‰ãªã„ã“ã¨ï¼
```

### ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼å®Ÿè£…ä¾‹
```python
class YOLOSliceDataset(Dataset):
    def __init__(self, slice_paths, label_paths, augmentation=True):
        self.slice_paths = slice_paths  # å…¨ã‚¹ãƒ©ã‚¤ã‚¹ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
        self.label_paths = label_paths  # å¯¾å¿œã™ã‚‹YOLOãƒ©ãƒ™ãƒ«
        self.augmentation = augmentation

    def __len__(self):
        return len(self.slice_paths)

    def __getitem__(self, idx):
        # 1ã‚µãƒ³ãƒ—ãƒ« = 1æšã®ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒ
        image = load_nifti(self.slice_paths[idx])  # [H, W]
        bboxes = load_yolo_label(self.label_paths[idx])  # [[cls, x, y, w, h], ...]

        if self.augmentation:
            image, bboxes = augment(image, bboxes)  # å›è»¢ã€åè»¢ã€æ˜åº¦èª¿æ•´

        image = normalize(image)  # [0, 1] or [-1, 1]
        image = to_tensor(image).unsqueeze(0)  # [1, H, W]

        return {
            'image': image,
            'bboxes': bboxes,
            'path': self.slice_paths[idx]
        }
```

### å­¦ç¿’è¨­å®š
```yaml
data:
  batch_size: 32  # ã‚¹ãƒ©ã‚¤ã‚¹å˜ä½
  image_size: [256, 256]
  num_workers: 4

model:
  backbone: cspdarknet  # yolov8n
  pretrained: true
  num_classes: 1  # éª¨æŠ˜ã‚¯ãƒ©ã‚¹ã®ã¿ (äºŒå€¤åˆ†é¡)

training:
  epochs: 100
  optimizer: AdamW
  lr: 0.001
  scheduler: CosineAnnealingLR
  early_stopping_patience: 15
```

### å­¦ç¿’ã‚¿ã‚¹ã‚¯
- BBox Regression Loss (IoU Loss or GIoU Loss)
- Classification Loss (Focal Loss for ä¸å‡è¡¡å¯¾ç­–)
- Objectness Loss

### è©•ä¾¡ (ã“ã®æ®µéš)
- **ã‚¹ãƒ©ã‚¤ã‚¹ãƒ¬ãƒ™ãƒ«**: mAP@0.5, mAP@0.5:0.95, Precision, Recall
- **æ¤ä½“ãƒ¬ãƒ™ãƒ« (ç°¡æ˜“ç‰ˆ)**: å„æ¤ä½“ã®å…¨ã‚¹ãƒ©ã‚¤ã‚¹ã§å¤šæ•°æ±º
  - ä¾‹: vertebra_27ã®70ã‚¹ãƒ©ã‚¤ã‚¹ä¸­ã€30ã‚¹ãƒ©ã‚¤ã‚¹ã§éª¨æŠ˜æ¤œå‡º â†’ éª¨æŠ˜ã‚ã‚Š

### å‡ºåŠ›
- å­¦ç¿’æ¸ˆã¿YOLOãƒ¢ãƒ‡ãƒ«: `yolo_baseline.pth`
- ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½ã®ç¢ºèª (LSTMç„¡ã—)

---

## Phase 2: LSTMå­¦ç¿’

### ç›®çš„
æ¤ä½“ãƒ¬ãƒ™ãƒ«ã®éª¨æŠ˜åˆ†é¡å™¨ã‚’ä½œæˆ (æ™‚ç³»åˆ—çµ±åˆ)

### ãƒ‡ãƒ¼ã‚¿æ§‹æˆ
```python
# æ¤ä½“å˜ä½ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
Dataset = [
    # æ‚£è€…1ã®æ¤ä½“1
    {
        'slices': [vertebra_27/slice_000.nii, ..., slice_069.nii],  # 70æš
        'label': 1  # éª¨æŠ˜ã‚ã‚Š
    },
    # æ‚£è€…1ã®æ¤ä½“2
    {
        'slices': [vertebra_28/slice_000.nii, ..., slice_065.nii],  # 66æš â†’ 70æšã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        'label': 0  # éª¨æŠ˜ãªã—
    },
    ...
]

# æ¨å®šã‚µãƒ³ãƒ—ãƒ«æ•°: 38ç—‡ä¾‹ Ã— 14æ¤ä½“/ç—‡ä¾‹ â‰ˆ 532ã‚µãƒ³ãƒ—ãƒ«
```

### ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼å®Ÿè£…ä¾‹
```python
class LSTMVertebraeDataset(Dataset):
    def __init__(self, vertebra_list, max_slices=70, sampling='center_crop', padding='replicate'):
        self.vertebra_list = vertebra_list  # [(vertebra_path, label), ...]
        self.max_slices = max_slices
        self.sampling = sampling
        self.padding = padding

    def __len__(self):
        return len(self.vertebra_list)

    def __getitem__(self, idx):
        vertebra_path, label = self.vertebra_list[idx]
        slices = sorted(glob(f"{vertebra_path}/slice_*.nii"))

        # å›ºå®šé•·ã«èª¿æ•´
        slices = self.adjust_length(slices, self.max_slices)

        # å…¨ã‚¹ãƒ©ã‚¤ã‚¹ã‚’èª­ã¿è¾¼ã¿
        images = []
        for slice_path in slices:
            img = load_nifti(slice_path)
            img = normalize(img)
            images.append(to_tensor(img).unsqueeze(0))  # [1, H, W]

        images = torch.stack(images)  # [N_slices, 1, H, W]

        return {
            'images': images,        # [70, 1, 256, 256]
            'label': label,          # 0 or 1
            'vertebra_path': vertebra_path
        }

    def adjust_length(self, slices, target_len):
        """å¯å¤‰é•· â†’ å›ºå®šé•·å¤‰æ›"""
        n = len(slices)

        if n > target_len:
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            if self.sampling == 'center_crop':
                # ä¸­å¿ƒéƒ¨ã‚’å„ªå…ˆ (éª¨æŠ˜ã¯æ¤ä½“ä¸­å¿ƒã«å¤šã„)
                start = (n - target_len) // 2
                return slices[start:start + target_len]
            elif self.sampling == 'uniform_sample':
                # å‡ç­‰é–“éš”ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                indices = np.linspace(0, n-1, target_len, dtype=int)
                return [slices[i] for i in indices]

        elif n < target_len:
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            if self.padding == 'replicate':
                # æœ€çµ‚ã‚¹ãƒ©ã‚¤ã‚¹ã‚’è¤‡è£½
                return slices + [slices[-1]] * (target_len - n)
            elif self.padding == 'zero':
                # ã‚¼ãƒ­ç”»åƒã‚’è¿½åŠ 
                return slices + ['zero'] * (target_len - n)

        return slices
```

### ãƒ¢ãƒ‡ãƒ«æ§‹æˆ
```python
class YOLOLSTMModel(nn.Module):
    def __init__(self, yolo_checkpoint, freeze_yolo=True):
        super().__init__()

        # å­¦ç¿’æ¸ˆã¿YOLOã‚’ãƒ­ãƒ¼ãƒ‰
        self.yolo = load_pretrained_yolo(yolo_checkpoint)

        # YOLOã®é‡ã¿ã‚’å›ºå®š
        if freeze_yolo:
            for param in self.yolo.parameters():
                param.requires_grad = False
            self.yolo.eval()  # BNã‚’å‡çµ

        # LSTMå±¤
        self.lstm = nn.LSTM(
            input_size=256,      # YOLOã®ç‰¹å¾´æ¬¡å…ƒ
            hidden_size=256,
            num_layers=2,
            batch_first=True,
            dropout=0.3
        )

        # åˆ†é¡å™¨
        self.classifier = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 2)  # éª¨æŠ˜/ééª¨æŠ˜
        )

    def forward(self, sequence):
        """
        Args:
            sequence: [Batch, N_slices, C, H, W] (ä¾‹: [4, 70, 1, 256, 256])

        Returns:
            logits: [Batch, 2]
        """
        batch_size, seq_len = sequence.shape[:2]

        # å„ã‚¹ãƒ©ã‚¤ã‚¹ã‚’YOLOã§ç‰¹å¾´æŠ½å‡º
        features = []
        for t in range(seq_len):
            with torch.no_grad() if self.freeze_yolo else torch.enable_grad():
                feat = self.yolo.extract_features(sequence[:, t])  # [Batch, 256]
            features.append(feat)

        features = torch.stack(features, dim=1)  # [Batch, N_slices, 256]

        # LSTMå‡¦ç†
        lstm_out, (h_n, c_n) = self.lstm(features)  # lstm_out: [Batch, N_slices, 256]

        # æœ€çµ‚å‡ºåŠ›ã‚’ä½¿ç”¨ (ã¾ãŸã¯å…¨æ™‚åˆ»ã®å¹³å‡)
        final_feat = lstm_out[:, -1, :]  # [Batch, 256]
        # ã¾ãŸã¯: final_feat = lstm_out.mean(dim=1)

        # åˆ†é¡
        logits = self.classifier(final_feat)  # [Batch, 2]

        return logits
```

### å­¦ç¿’è¨­å®š
```yaml
data:
  batch_size: 4  # æ¤ä½“å˜ä½ (ãƒ¡ãƒ¢ãƒªæ¶ˆè²»å¤§)
  max_slices_per_vertebra: 70
  sampling_strategy: center_crop
  padding_mode: replicate

model:
  freeze_yolo: true
  lstm:
    hidden_dim: 256
    num_layers: 2
    dropout: 0.3

training:
  epochs: 50
  optimizer: AdamW
  lr: 0.001  # LSTMã¨åˆ†é¡å™¨ã®å­¦ç¿’ç‡
  scheduler: ReduceLROnPlateau
  early_stopping_patience: 10
```

### æå¤±é–¢æ•°
```python
# æ¤ä½“ãƒ¬ãƒ™ãƒ«ã®ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±
criterion = nn.CrossEntropyLoss(weight=class_weights)  # ä¸å‡è¡¡å¯¾ç­–

# ã¾ãŸã¯ Focal Loss
from torchvision.ops import focal_loss
loss = focal_loss.sigmoid_focal_loss(logits, labels, alpha=0.25, gamma=2.0)
```

### è©•ä¾¡ (ã“ã®æ®µéš)
- **æ¤ä½“ãƒ¬ãƒ™ãƒ«**: Accuracy, Precision, Recall, F1, AUC
- **æ¯”è¼ƒè©•ä¾¡**:
  - YOLOå˜ä½“ (Phase 1ã®å¤šæ•°æ±º) vs YOLO+LSTM
  - LSTMã®åŠ¹æœã‚’å®šé‡åŒ–

### å‡ºåŠ›
- å­¦ç¿’æ¸ˆã¿YOLO+LSTMãƒ¢ãƒ‡ãƒ«: `yolo_lstm.pth`

---

## é‡è¦ãªæ³¨æ„ç‚¹

### 1. æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²ã®å³å®ˆ
```python
# NGä¾‹: åŒã˜æ‚£è€…ãŒtrain/valã«æ··åœ¨
train_slices = [
    'inp1003/vertebra_27/slice_000.nii',
    'inp1003/vertebra_27/slice_001.nii',
    ...
]
val_slices = [
    'inp1003/vertebra_28/slice_000.nii',  # â† inp1003ãŒé‡è¤‡ï¼
    ...
]

# OKä¾‹: æ‚£è€…ã‚’å®Œå…¨ã«åˆ†é›¢
fold_0_train_patients = ['inp1003', 'inp1039', ...]
fold_0_val_patients = ['inp1059', 'inp1078', ...]  # é‡è¤‡ãªã—
```

### 2. YOLOã®é‡ã¿ç®¡ç†
```python
# Phase 2ã§YOLOã‚’å›ºå®šã™ã‚‹å ´åˆ
for param in yolo_model.parameters():
    param.requires_grad = False
yolo_model.eval()  # BatchNormã®çµ±è¨ˆã‚‚å›ºå®š

# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆ
optimizer = Adam([
    {'params': yolo_model.parameters(), 'lr': 1e-5},  # ä½å­¦ç¿’ç‡
    {'params': lstm_model.parameters(), 'lr': 1e-3}   # é€šå¸¸å­¦ç¿’ç‡
])
```

### 3. ãƒ¡ãƒ¢ãƒªç®¡ç†
```python
# LSTMå­¦ç¿’æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯å°ã•ãã™ã‚‹
# [4, 70, 1, 256, 256] â‰ˆ 180MB/ãƒãƒƒãƒ â†’ GPU ãƒ¡ãƒ¢ãƒªã«æ³¨æ„

# ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆ:
# - batch_size ã‚’ 2 ã«å‰Šæ¸›
# - max_slices ã‚’ 50 ã«å‰Šæ¸›
# - gradient_accumulation_steps ã‚’ä½¿ç”¨
```

### 4. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
```python
# YOLOå­¦ç¿’æ™‚: ç©æ¥µçš„ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
augmentation = A.Compose([
    A.Rotate(limit=15),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.3),
], bbox_params=A.BboxParams(format='yolo'))

# LSTMå­¦ç¿’æ™‚: è»½åº¦ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®ã¿
# (æ™‚ç³»åˆ—ã®ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚)
augmentation = A.Compose([
    A.RandomBrightnessContrast(p=0.2),
])
```

---

## ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“è¨ˆç”»

### å®Ÿé¨“1: LSTMæœ‰ç„¡ã®æ¯”è¼ƒ
- exp_001: YOLOå˜ä½“ (Phase 1) â†’ å¤šæ•°æ±º
- exp_002: YOLO + LSTM (Phase 2)

### å®Ÿé¨“2: ã‚¹ãƒ©ã‚¤ã‚¹æ•°ã®æœ€é©åŒ–
- exp_003: max_slices=50
- exp_004: max_slices=70 (æ¨å¥¨)
- exp_005: max_slices=100

### å®Ÿé¨“3: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥
- exp_006: center_crop (æ¨å¥¨)
- exp_007: uniform_sample
- exp_008: full (ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã—ã€å¯å¤‰é•·)

### å®Ÿé¨“4: ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æ¯”è¼ƒ
- exp_009: CSPDarknet (yolov8n)
- exp_010: EfficientNet-B0
- exp_011: EfficientNet-B1
- exp_012: ResNet-50

### å®Ÿé¨“5: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- exp_013: freeze_yolo=true (æ¨å¥¨)
- exp_014: freeze_yolo=false (ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰)

---

## ã¾ã¨ã‚

**2æ®µéšå­¦ç¿’ã®ãƒ¡ãƒªãƒƒãƒˆ:**
1. âœ… æ®µéšçš„æ¤œè¨¼ãŒå¯èƒ½ (YOLO â†’ LSTM)
2. âœ… å°‘æ•°ãƒ‡ãƒ¼ã‚¿ã«å¼·ã„ (äº‹å‰å­¦ç¿’æ¸ˆã¿YOLOæ´»ç”¨)
3. âœ… è§£é‡ˆæ€§ãŒé«˜ã„ (å„æ®µéšã®æ€§èƒ½ã‚’ç¢ºèªå¯èƒ½)
4. âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„ (YOLOå›ºå®šæ™‚)

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**
- Step A-1: YOLOå½¢å¼ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆã‹ã‚‰é–‹å§‹

---

## å®Ÿè£…è¨ˆç”» (Implementation Roadmap)

### æœ€çµ‚æ›´æ–°: 2025/10/19

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€YOLOv8+LSTMéª¨æŠ˜æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®å…·ä½“çš„ãªå®Ÿè£…æ‰‹é †ã‚’ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã«æ•´ç†ã—ãŸã‚‚ã®ã§ã™ã€‚
[knowledge.md](knowledge.md)ã®è¨­è¨ˆæ–¹é‡ã¨[improvements.md](improvements.md)ã®ãƒ‡ãƒ¼ã‚¿ä»•æ§˜ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚

---

## **å…¨ä½“å®Ÿè£…ãƒ•ãƒ­ãƒ¼ (6ãƒ•ã‚§ãƒ¼ã‚º)**

```mermaid
graph TD
    A[Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™] --> B[Phase 2: YOLOãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³]
    B --> C[Phase 3: YOLO+LSTMçµ±åˆ]
    C --> D[Phase 4: ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æœ€é©åŒ–]
    D --> E[Phase 5: æ¨è«–ãƒ»è©•ä¾¡]
    E --> F[Phase 6: å®Ÿé¨“ãƒ»æ”¹å–„]
```

---

### **Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™** ğŸ”§

**ç›®æ¨™**: ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒã‹ã‚‰YOLOå½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ç”¨DataLoaderã‚’å®Ÿè£…

#### **1-1. YOLOå½¢å¼å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (`data_preparing/convert_to_yolo.py`)

**å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æ§‹é€ **:
```
data/slice_train/
â”œâ”€â”€ axial/
â”‚    â”œâ”€â”€ {case_id}/           # ä¾‹: inp1003
â”‚    |     â””â”€â”€ {vertebra_id}/   # ä¾‹: 27, 28, ...
â”‚    |           â””â”€â”€ slice_*.nii  # å„ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒ
|    â””â”€â”€ fracture_labels_*.csv  # ãã®ç—‡ä¾‹ã®ã‚¹ãƒ©ã‚¤ã‚¹ãƒ‘ã‚¹ã¨æƒ…å ±
â””â”€â”€ axial_mask/
     â”œâ”€â”€ {case_id}/
     |     â””â”€â”€ {vertebra_id}/
     |           â””â”€â”€ slice_*.nii  # ãƒã‚¹ã‚¯(å€¤0-6: 0=èƒŒæ™¯, 1-6=éª¨æŠ˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹)
     â””â”€â”€ mask_labels_*.csv
                 

**å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿æ§‹é€ **:
```
data/yolo_format/
â”œâ”€â”€ images/
|    â””â”€â”€ axial/
â”‚         â”œâ”€â”€ train/
â”‚              â””â”€â”€ {case}_{vertebra}_{slice}.png  # ä¾‹: inp1003_27_slice_005.png
â””â”€â”€ labels/
     â””â”€â”€ axail/
          â”œâ”€â”€ train/
               â””â”€â”€ {case}_{vertebra}_{slice}.txt  # YOLOå½¢å¼ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
                  # å†…å®¹ä¾‹ (1ã‚¹ãƒ©ã‚¤ã‚¹ã«è¤‡æ•°éª¨æŠ˜ãŒã‚ã‚‹å ´åˆã¯è¤‡æ•°è¡Œ):
                  # 0 0.573 0.384 0.089 0.052
                  # 0 0.536 0.531 0.065 0.048
```

**å®Ÿè£…æ©Ÿèƒ½**:

```python
# æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰
def convert_to_yolo_format():
    """
    ãƒã‚¹ã‚¯ç”»åƒã‹ã‚‰YOLOå½¢å¼BBoxã‚’æŠ½å‡º
    """
    for case_id in patient_list:
        for vertebra_id in vertebra_list:
            for slice_file in slice_files:
                # 1. ãƒã‚¹ã‚¯èª­ã¿è¾¼ã¿
                mask = load_nifti(mask_path)

                # 2. ãƒãƒ«ãƒã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹BBoxæŠ½å‡º (å€¤1-6ã‚’ãƒ«ãƒ¼ãƒ—)
                bboxes = []
                for mask_value in range(1, 7):
                    if (mask == mask_value).any():
                        bbox = extract_bbox(mask, mask_value)
                        if is_valid_bbox(bbox):  # å“è³ªãƒã‚§ãƒƒã‚¯
                            bboxes.append(bbox)

                # 3. ç”»åƒã‚’PNGä¿å­˜ (256x256ã«ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°)
                image = load_nifti(image_path)
                image_padded = zero_pad_to_256(image)
                save_png(image_padded, output_image_path)

                # 4. YOLOå½¢å¼ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜
                save_yolo_labels(bboxes, output_label_path)

    # 5. train/valåˆ†å‰² (æ‚£è€…ãƒ¬ãƒ™ãƒ«5-fold)
    create_patient_level_splits()
```

**BBoxå“è³ªãƒã‚§ãƒƒã‚¯**:
- æœ€å°é¢ç©: 50pxÂ²ä»¥ä¸Š
- æ­£è¦åŒ–åº§æ¨™ç¯„å›²: [0, 1]
- ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: 1:20æœªæº€

**æ‚£è€…ãƒ¬ãƒ™ãƒ«5-foldåˆ†å‰²**:
```python
# æ‚£è€…ID â†’ foldç•ªå·ã®ãƒãƒƒãƒ”ãƒ³ã‚°
# ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢: åŒä¸€æ‚£è€…ã®ã™ã¹ã¦ã®æ¤ä½“ãƒ»ã‚¹ãƒ©ã‚¤ã‚¹ã¯åŒã˜foldã«é…ç½®
patient_folds = {
    'inp1003': 0,
    'inp1010': 0,
    'inp1012': 1,
    ...
}
```

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/data_preparing/convert_to_yolo.py`
- è¨­å®š: `run/conf/data_preparing.yaml`

**æ¤œè¨¼é …ç›®**:
- [ ] å…¨ã‚¹ãƒ©ã‚¤ã‚¹ãŒæ­£ã—ãå¤‰æ›ã•ã‚ŒãŸã‹ (ä»¶æ•°ç¢ºèª)
- [ ] è¤‡æ•°BBoxãŒæ­£ã—ãåˆ†é›¢ã•ã‚Œã¦ã„ã‚‹ã‹ (ç›®è¦–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
- [ ] train/valã§æ‚£è€…ãŒé‡è¤‡ã—ã¦ã„ãªã„ã‹

---

#### **1-2. é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ç”¨Dataset** (`src/dataset/yolo_dataset.py`)

**ãƒ‡ãƒ¼ã‚¿æ§‹é€ **:
```python
# 1ã‚µãƒ³ãƒ—ãƒ« = é€£ç¶šNæšã®ã‚¹ãƒ©ã‚¤ã‚¹ (N=7ã‹ã‚‰é–‹å§‹)
sample = {
    'images': [B, N, 3, 256, 256],      # é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒ
    'labels': List[Tensor],             # å„ã‚¹ãƒ©ã‚¤ã‚¹ã®YOLOå½¢å¼ãƒ©ãƒ™ãƒ«
    'sequence_info': {
        'case_id': 'inp1003',
        'vertebra_id': '27',
        'slice_indices': [5, 6, 7, 8, 9, 10, 11]  # é€£ç¶šæ€§ä¿æŒ
    }
}
```

**å®Ÿè£…æ©Ÿèƒ½**:

```python
class VertebraeSequenceDataset(Dataset):
    """
    é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ã‚’ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¨ã—ã¦è¿”ã™PyTorch Dataset
    """
    def __init__(self, data_root, split='train', sequence_length=7, stride=1):
        # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ã‚’æŠ½å‡º
        # ä¾‹: æ¤ä½“27ã«10ã‚¹ãƒ©ã‚¤ã‚¹ã‚ã‚‹å ´åˆ
        #   - seq1: [0,1,2,3,4,5,6]
        #   - seq2: [1,2,3,4,5,6,7]  (stride=1)
        #   - seq3: [2,3,4,5,6,7,8]
        self.data_root = data_root
        self.split = split
        self.sequence_length = sequence_length
        self.stride = stride

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ: å›è»¢ã€åè»¢ã€æ˜åº¦èª¿æ•´ (å…¨ã‚¹ãƒ©ã‚¤ã‚¹ã«ä¸€è²«ã—ã¦é©ç”¨)
        # YOLOå½¢å¼ãƒ©ãƒ™ãƒ«ã®èª­ã¿è¾¼ã¿
        pass
```

**ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥**:
- å¹¾ä½•å­¦å¤‰æ›: å›è»¢(Â±15Â°), æ°´å¹³åè»¢
- ç”»ç´ å€¤èª¿æ•´: æ˜åº¦Â±10%, ã‚¬ãƒ³ãƒè£œæ­£
- **æ³¨æ„**: é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹å…¨ä½“ã«åŒã˜å¤‰æ›ã‚’é©ç”¨ (ä¸€è²«æ€§ä¿æŒ)

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/src/dataset/yolo_dataset.py`
- è¨­å®š: `run/conf/data/yolo_data.yaml`

**æ¤œè¨¼é …ç›®**:
- [ ] ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é€£ç¶šæ€§ãŒä¿ãŸã‚Œã¦ã„ã‚‹ã‹
- [ ] æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²ãŒå®ˆã‚‰ã‚Œã¦ã„ã‚‹ã‹
- [ ] ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãŒå…¨ã‚¹ãƒ©ã‚¤ã‚¹ã«ä¸€è²«ã—ã¦é©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹

---

### **Phase 2: YOLOãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ§‹ç¯‰** ğŸ¯

**ç›®æ¨™**: LSTMç„¡ã—ã®YOLOv8å˜ä½“ã§éª¨æŠ˜æ¤œå‡ºã®åŸºæœ¬æ€§èƒ½ã‚’ç¢ºç«‹

#### **2-1. YOLOv8ãƒ¢ãƒ‡ãƒ«å®Ÿè£…** (`src/models/yolo_baseline.py`)

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
```python
class YOLOv8Baseline(nn.Module):
    """
    YOLOv8å˜ä½“ãƒ¢ãƒ‡ãƒ« (LSTMç„¡ã—)
    """
    def __init__(self, num_classes=2, backbone='cspdarknet'):
        super().__init__()
        # Ultralytics YOLOv8ã‚’ä½¿ç”¨
        from ultralytics import YOLO

        if backbone == 'cspdarknet':
            self.yolo = YOLO('yolov8n.pt')  # äº‹å‰å­¦ç¿’æ¸ˆã¿é‡ã¿ãƒ­ãƒ¼ãƒ‰

        # å‡ºåŠ›å±¤ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º (num_classes=2: éª¨æŠ˜/ééª¨æŠ˜)
        self.yolo.model.head.nc = num_classes

    def forward(self, x):
        # x: [B, 3, 256, 256] (å˜ä¸€ã‚¹ãƒ©ã‚¤ã‚¹)
        detections = self.yolo(x)  # [cls, x, y, w, h, conf] Ã— æ¤œå‡ºæ•°
        return detections
```

**æå¤±é–¢æ•°**:
- YOLOv8æ¨™æº–æå¤±: BBox loss + Classification loss + Objectness loss
- ä¸å‡è¡¡å¯¾ç­–: Focal Loss (éª¨æŠ˜ãŒå°‘æ•°ã‚¯ãƒ©ã‚¹)

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/src/models/yolo_baseline.py`
- è¨­å®š: `run/conf/model/yolo_baseline.yaml`

---

#### **2-2. å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å®Ÿè£…** (`src/utils/trainer.py`)

```python
class Trainer:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªPyTorchãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    """
    def __init__(self, model, train_loader, val_loader, optimizer, scheduler, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device

    def train_epoch(self):
        self.model.train()
        total_loss = 0
        for batch in self.train_loader:
            images, targets = batch
            images = images.to(self.device)

            self.optimizer.zero_grad()
            loss = self.model.compute_loss(images, targets)
            loss.backward()
            self.optimizer.step()

            total_loss += loss.item()

        return total_loss / len(self.train_loader)

    def validate(self):
        self.model.eval()
        metrics = compute_map(self.model, self.val_loader, self.device)
        return metrics
```

---

#### **2-3. å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (`run/scripts/train/train.py`)

```python
import hydra
from omegaconf import DictConfig
import torch
from torch.utils.data import DataLoader

@hydra.main(config_path="../../conf", config_name="config", version_base="1.2")
def main(cfg: DictConfig):
    # Deviceè¨­å®š
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Dataset
    train_dataset = YOLODataset(cfg.data, split='train')
    val_dataset = YOLODataset(cfg.data, split='val')

    # DataLoader
    train_loader = DataLoader(train_dataset, batch_size=cfg.data.batch_size,
                             shuffle=True, num_workers=cfg.data.num_workers)
    val_loader = DataLoader(val_dataset, batch_size=cfg.data.batch_size,
                           shuffle=False, num_workers=cfg.data.num_workers)

    # Model
    model = YOLOv8Baseline(cfg.model).to(device)

    # Optimizer & Scheduler
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.training.lr,
                                  weight_decay=cfg.training.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,
                                                            T_max=cfg.training.epochs)

    # Trainer
    trainer = Trainer(model, train_loader, val_loader, optimizer, scheduler, device)

    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    best_map = 0.0
    patience_counter = 0

    for epoch in range(cfg.training.epochs):
        train_loss = trainer.train_epoch()
        val_metrics = trainer.validate()

        # Checkpointä¿å­˜
        if val_metrics['map'] > best_map:
            best_map = val_metrics['map']
            torch.save(model.state_dict(), f'output/best_model.pth')
            patience_counter = 0
        else:
            patience_counter += 1

        # Early Stopping
        if patience_counter >= cfg.training.early_stopping_patience:
            break

        scheduler.step()
```

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¾‹** (`run/conf/train.yaml`):
```yaml
defaults:
  - model: yolo_baseline
  - data: yolo_sequence
  - split: fold_0

training:
  epochs: 100
  lr: 0.001
  weight_decay: 0.0001
  batch_size: 8

data:
  sequence_length: 1  # Phase 2ã§ã¯LSTMç„¡ã— (å˜ä¸€ã‚¹ãƒ©ã‚¤ã‚¹)
  image_size: 256
  num_workers: 4
```

**å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰**:
```bash
cd vertebrae_YOLO/run/scripts/train
python train.py split=fold_0  # Fold 0ã§å­¦ç¿’
```

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/run/scripts/train/train.py` (ã‚·ãƒ³ãƒ—ãƒ«ãªPyTorchå­¦ç¿’ãƒ«ãƒ¼ãƒ—)
- `vertebrae_YOLO/src/utils/trainer.py` (å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£)
- è¨­å®š: `run/conf/train.yaml`, `run/conf/model/yolo_baseline.yaml`

**æ¤œè¨¼é …ç›®**:
- [ ] å­¦ç¿’ãŒåæŸã™ã‚‹ã‹ (lossæ›²ç·šç¢ºèª)
- [ ] ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½ (mAP@0.5 > 0.5ç›®æ¨™)
- [ ] CheckpointãŒæ­£ã—ãä¿å­˜ã•ã‚Œã‚‹ã‹

---

### **Phase 3: YOLO+LSTMçµ±åˆ** ğŸ”—

**ç›®æ¨™**: é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ã®æ™‚ç³»åˆ—æƒ…å ±ã‚’LSTMã§çµ±åˆã—ã€æ¤œå‡ºç²¾åº¦ã‚’å‘ä¸Š

#### **3-1. YOLO+LSTMãƒ¢ãƒ‡ãƒ«å®Ÿè£…** (`src/models/yolo_lstm.py`)

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**:
```python
class YOLOv8LSTM(nn.Module):
    """
    YOLOv8 + LSTM 2æ®µéšãƒ¢ãƒ‡ãƒ«
    """
    def __init__(self, num_classes=2, hidden_dim=256, num_layers=2):
        super().__init__()

        # Stage 1: YOLOv8 (äº‹å‰å­¦ç¿’æ¸ˆã¿)
        self.yolo_backbone = YOLO('yolov8n.pt')

        # YOLOã®ä¸­é–“ç‰¹å¾´ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ãƒ•ãƒƒã‚¯
        self.feature_extractor = self._get_feature_hook()

        # Stage 2: LSTM
        # å…¥åŠ›: YOLOã®æ¤œå‡ºçµæœ(5æ¬¡å…ƒ: cls, x, y, w, h) + ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«(256æ¬¡å…ƒ)
        input_dim = 5 + 256  # BBoxæƒ…å ± + ç‰¹å¾´é‡
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True
        )

        # æœ€çµ‚äºˆæ¸¬å±¤
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        # x: [B, N, 3, 256, 256] (N=é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹æ•°)
        B, N, C, H, W = x.shape

        # Stage 1: YOLOã§å„ã‚¹ãƒ©ã‚¤ã‚¹ã‚’å‡¦ç†
        yolo_features = []
        for i in range(N):
            slice_img = x[:, i]  # [B, 3, 256, 256]

            # YOLOæ¤œå‡º
            detections = self.yolo_backbone(slice_img)  # [cls, x, y, w, h, conf]

            # ä¸­é–“ç‰¹å¾´å–å¾—
            features = self.feature_extractor.get_features()  # [B, 256]

            # æ¤œå‡ºæƒ…å ± + ç‰¹å¾´ã‚’çµåˆ
            combined = torch.cat([detections[:, :5], features], dim=-1)  # [B, 261]
            yolo_features.append(combined)

        # Stage 2: LSTMã§æ™‚ç³»åˆ—çµ±åˆ
        lstm_input = torch.stack(yolo_features, dim=1)  # [B, N, 261]
        lstm_out, _ = self.lstm(lstm_input)  # [B, N, 256]

        # æœ€çµ‚äºˆæ¸¬ (ä¸­å¿ƒã‚¹ãƒ©ã‚¤ã‚¹ã®å‡ºåŠ›ã‚’ä½¿ç”¨)
        center_idx = N // 2
        final_pred = self.fc(lstm_out[:, center_idx, :])  # [B, num_classes]

        return final_pred
```

**è¨­è¨ˆãƒã‚¤ãƒ³ãƒˆ**:
- YOLOã¯å‡çµ or ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Phase 2ã®é‡ã¿ã‚’åˆ©ç”¨)
- LSTMå…¥åŠ›: BBoxåº§æ¨™(5æ¬¡å…ƒ) + YOLOã®ä¸­é–“ç‰¹å¾´(256æ¬¡å…ƒ)
- å‡ºåŠ›: ä¸­å¿ƒã‚¹ãƒ©ã‚¤ã‚¹ã®æœ€çµ‚éª¨æŠ˜äºˆæ¸¬

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/src/models/yolo_lstm.py`
- è¨­å®š: `run/conf/model/yolo_lstm.yaml`

**è¨­å®šä¾‹** (`run/conf/model/yolo_lstm.yaml`):
```yaml
model:
  name: yolo_lstm
  num_classes: 2

  yolo:
    backbone: cspdarknet
    variant: yolov8n
    pretrained_path: output/train/baseline_exp/fold_0/best.pt  # Phase 2ã®é‡ã¿
    freeze: false  # true=å‡çµ, false=ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

  lstm:
    hidden_dim: 256
    num_layers: 2
    bidirectional: false
```

---

#### **3-2. DataLoaderä¿®æ­£**

Phase 1ã§å®Ÿè£…ã—ãŸDataLoaderã®`sequence_length`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´:

```yaml
# run/conf/data/yolo_sequence.yaml
data:
  sequence_length: 7  # LSTMç”¨ã«é€£ç¶š7æš
  stride: 1           # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¹ãƒ†ãƒƒãƒ—
```

---

#### **3-3. å­¦ç¿’å®Ÿè¡Œ**

```bash
cd vertebrae_YOLO/run/scripts/train
python train.py model=yolo_lstm data.sequence_length=7 split=fold_0
```

**æ¤œè¨¼é …ç›®**:
- [ ] LSTMè¿½åŠ ã§mAPå‘ä¸Šã™ã‚‹ã‹ (Phase 2ã¨ã®æ¯”è¼ƒ)
- [ ] é€£ç¶šæ€§ã‚’è€ƒæ…®ã—ãŸæ¤œå‡ºã®å®‰å®šæ€§
- [ ] æ¨è«–é€Ÿåº¦ã®å½±éŸ¿

---

### **Phase 4: ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æœ€é©åŒ–** ğŸš€

**ç›®æ¨™**: äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã§å°‘æ•°ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½ã‚’æœ€å¤§åŒ–

#### **4-1. EfficientNet-B0/B1å®Ÿè£…**

**YOLOãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã®ç½®ãæ›ãˆ**:

```python
class YOLOv8EfficientNet(nn.Module):
    """
    YOLOv8 + EfficientNetãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³
    """
    def __init__(self, backbone='efficientnet_b0', num_classes=2):
        super().__init__()

        # EfficientNetãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ (ImageNetäº‹å‰å­¦ç¿’æ¸ˆã¿)
        if backbone == 'efficientnet_b0':
            from efficientnet_pytorch import EfficientNet
            self.backbone = EfficientNet.from_pretrained('efficientnet-b0')
            backbone_channels = [40, 112, 320]  # B0ã®å‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«

        # åˆæœŸ3å±¤ã‚’å‡çµ (Transfer Learning)
        for i, (name, param) in enumerate(self.backbone.named_parameters()):
            if i < 30:  # åˆæœŸ30å±¤
                param.requires_grad = False

        # YOLOv8 Neck (PANet)
        self.neck = YOLOv8PAFPN(in_channels=backbone_channels)

        # YOLOv8 Head
        self.head = YOLOv8Head(num_classes=num_classes)

    def forward(self, x):
        # ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³
        features = self.backbone.extract_features(x)

        # Neck
        neck_out = self.neck(features)

        # Head
        detections = self.head(neck_out)

        return detections
```

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/src/models/yolo_efficientnet.py`
- è¨­å®š: `run/conf/model/yolo_efficientnet_b0.yaml`, `yolo_efficientnet_b1.yaml`

---

#### **4-2. ResNet-50å®Ÿè£…**

åŒæ§˜ã«ResNet-50ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’å®Ÿè£…:

```yaml
# run/conf/model/yolo_resnet50.yaml
model:
  backbone:
    type: resnet50
    pretrained: true  # ImageNeté‡ã¿
    freeze_layers: [0, 1, 2, 3]  # åˆæœŸ4å±¤å‡çµ
    out_channels: [512, 1024, 2048]
```

---

#### **4-3. ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æ¯”è¼ƒå®Ÿé¨“**

**å®Ÿé¨“è¨ˆç”»**:

| å®Ÿé¨“ID | ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ | äº‹å‰å­¦ç¿’ | å‡çµå±¤ | ç›®çš„ |
|--------|------------|---------|--------|------|
| exp_baseline | CSPDarknet (yolov8n) | COCO | ãªã— | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ |
| exp_effb0 | EfficientNet-B0 | ImageNet | [0,1,2] | è»½é‡ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ |
| exp_effb1 | EfficientNet-B1 | ImageNet | [0,1,2] | B0ã¨ã®æ¯”è¼ƒ |
| exp_resnet50 | ResNet-50 | ImageNet | [0,1,2,3] | æ¨™æº–ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ |

**å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (`run/scripts/train/run_ablation.sh`):
```bash
#!/bin/bash
for model in yolo_baseline yolo_efficientnet_b0 yolo_efficientnet_b1 yolo_resnet50; do
  for fold in 0 1 2 3 4; do
    python train.py model=${model} split=fold_${fold} \
      experiment.name=${model}_fold${fold}
  done
done
```

**è©•ä¾¡æŒ‡æ¨™**:
- mAP@0.5, mAP@0.5:0.95
- Precision, Recall, F1
- æ¨è«–é€Ÿåº¦ (FPS)
- GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/run/scripts/train/run_ablation.sh`
- `run/scripts/utils/compare_backbones.py` (çµæœæ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ)

---

### **Phase 5: æ¨è«–ãƒ»è©•ä¾¡** ğŸ“Š

**ç›®æ¨™**: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œã—ã€3Dçµ±åˆãƒ»è©•ä¾¡ã‚’è¡Œã†

#### **5-1. 2Dæ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (`run/scripts/inference/inference.py`)

```python
@hydra.main(config_path="../../conf", config_name="inference", version_base="1.2")
def main(cfg: DictConfig):
    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    model = load_checkpoint(cfg.checkpoint_path)

    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    datamodule = VertebraeDataModule(cfg.data, mode='test')

    # æ¨è«–å®Ÿè¡Œ
    results = []
    for batch in datamodule.test_dataloader():
        detections = model(batch['images'])

        # çµæœä¿å­˜
        for det in detections:
            results.append({
                'case_id': batch['case_id'],
                'vertebra_id': batch['vertebra_id'],
                'slice_idx': batch['slice_idx'],
                'bbox': det['bbox'],  # [x, y, w, h]
                'conf': det['conf'],
                'class': det['class']
            })

    # JSONä¿å­˜
    save_json(results, cfg.output_path)
```

**å‡ºåŠ›å½¢å¼**:
```json
[
  {
    "case_id": "inp1003",
    "vertebra_id": "27",
    "slice_idx": 5,
    "bbox": [0.573, 0.384, 0.089, 0.052],
    "conf": 0.92,
    "class": 0
  },
  ...
]
```

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/run/scripts/inference/inference.py`
- è¨­å®š: `run/conf/inference.yaml`

---

#### **5-2. 3Dçµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (`run/scripts/inference/reconstruct_3d.py`)

**çµ±åˆæ‰‹æ³•ã®å®Ÿè£…**:

```python
def integrate_3d_detections(detections_2d, method='weighted_nms'):
    """
    2Dæ¤œå‡ºçµæœã‚’3Dç©ºé–“ã«çµ±åˆ

    Args:
        detections_2d: List of 2D detections
        method: çµ±åˆæ‰‹æ³•
            - 'threshold': ä¿¡é ¼åº¦é–¾å€¤ãƒ™ãƒ¼ã‚¹
            - 'weighted_nms': ä¿¡é ¼åº¦é‡ã¿ä»˜ã‘NMS
            - 'clustering': DBSCANã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    """
    if method == 'threshold':
        # ä¿¡é ¼åº¦ > 0.5ã®æ¤œå‡ºã®ã¿æ¡ç”¨
        filtered = [d for d in detections_2d if d['conf'] > 0.5]
        return aggregate_by_or(filtered)

    elif method == 'weighted_nms':
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã§é‡ã¿ä»˜ã‘ã—ã¦NMS
        boxes = torch.tensor([d['bbox'] for d in detections_2d])
        scores = torch.tensor([d['conf'] for d in detections_2d])
        keep_indices = weighted_nms(boxes, scores, iou_threshold=0.3)
        return [detections_2d[i] for i in keep_indices]

    elif method == 'clustering':
        # DBSCAN ã§è¿‘æ¥æ¤œå‡ºã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        from sklearn.cluster import DBSCAN
        coords = np.array([[d['bbox'][0], d['bbox'][1]] for d in detections_2d])
        clustering = DBSCAN(eps=0.1, min_samples=3).fit(coords)
        # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ä»£è¡¨ç‚¹ã‚’é¸æŠ
        return select_cluster_representatives(detections_2d, clustering.labels_)
```

**3Då¯è¦–åŒ–**:
```python
def visualize_3d(detections_3d, ct_volume):
    """
    3Dæ¤œå‡ºçµæœã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D

    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection='3d')

    # CTãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’ãƒœã‚¯ã‚»ãƒ«è¡¨ç¤º
    # éª¨æŠ˜æ¤œå‡ºã‚’BBoxã§é‡ç•³è¡¨ç¤º
    for det in detections_3d:
        draw_3d_bbox(ax, det['bbox'], color='red')

    plt.savefig('3d_visualization.png')
```

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/run/scripts/inference/reconstruct_3d.py`
- `run/scripts/3Dvisualization/visualize_3d.py`

---

#### **5-3. è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (`run/scripts/utils/evaluate_3d.py`)

**è©•ä¾¡æŒ‡æ¨™è¨ˆç®—**:

```python
def compute_3d_metrics(predictions, ground_truth):
    """
    3Dæ¤œå‡ºã®è©•ä¾¡æŒ‡æ¨™

    Returns:
        - case_level_auc: ç—‡ä¾‹ãƒ¬ãƒ™ãƒ«AUC
        - vertebra_level_f1: æ¤ä½“ãƒ¬ãƒ™ãƒ«F1ã‚¹ã‚³ã‚¢
        - map_3d: 3D mAP
    """
    # ç—‡ä¾‹ãƒ¬ãƒ™ãƒ«: éª¨æŠ˜ã®æœ‰ç„¡ã‚’æ­£ã—ãåˆ¤å®šã§ããŸã‹
    case_auc = roc_auc_score(gt_case_labels, pred_case_scores)

    # æ¤ä½“ãƒ¬ãƒ™ãƒ«: å„æ¤ä½“ã®éª¨æŠ˜ã‚’æ­£ã—ãæ¤œå‡ºã§ããŸã‹
    vertebra_f1 = f1_score(gt_vertebra_labels, pred_vertebra_labels)

    # 3D mAP: 3D BBoxã®IoUãƒ™ãƒ¼ã‚¹è©•ä¾¡
    map_3d = compute_3d_map(predictions, ground_truth, iou_threshold=0.5)

    return {
        'case_auc': case_auc,
        'vertebra_f1': vertebra_f1,
        'map_3d': map_3d
    }
```

**5-foldçµæœçµ±åˆ**:
```python
def combine_fold_metrics(fold_results):
    """
    5-fold CVçµæœã®çµ±è¨ˆ
    """
    metrics_list = [load_json(f'output/inference/fold_{i}/metrics.json')
                    for i in range(5)]

    combined = {
        'case_auc_mean': np.mean([m['case_auc'] for m in metrics_list]),
        'case_auc_std': np.std([m['case_auc'] for m in metrics_list]),
        'map_3d_mean': np.mean([m['map_3d'] for m in metrics_list]),
        'map_3d_std': np.std([m['map_3d'] for m in metrics_list]),
    }

    return combined
```

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/run/scripts/utils/evaluate_3d.py`
- `run/scripts/utils/combine_metrics.py`
- è¨­å®š: `run/conf/combine_metrics.yaml`

---

### **Phase 6: å®Ÿé¨“ãƒ»æ”¹å–„** ğŸ”¬

**ç›®æ¨™**: ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–

#### **6-1. ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“**

**å®Ÿé¨“è¨ˆç”»**:

| å®Ÿé¨“ID | LSTM | é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹æ•° | ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ | ç›®çš„ |
|--------|------|--------------|------------|------|
| abl_001 | âŒ | 1 | CSPDarknet | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ |
| abl_002 | âœ… | 3 | CSPDarknet | LSTMåŠ¹æœ(N=3) |
| abl_003 | âœ… | 5 | CSPDarknet | LSTMåŠ¹æœ(N=5) |
| abl_004 | âœ… | 7 | CSPDarknet | LSTMåŠ¹æœ(N=7) |
| abl_005 | âœ… | 10 | CSPDarknet | LSTMåŠ¹æœ(N=10) |
| abl_006 | âœ… | 7 | EfficientNet-B1 | ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³+LSTM |

**å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ**:
```bash
# run/scripts/experiments/run_ablation.sh
experiments=(
  "model=yolo_baseline data.sequence_length=1"
  "model=yolo_lstm data.sequence_length=3"
  "model=yolo_lstm data.sequence_length=5"
  "model=yolo_lstm data.sequence_length=7"
  "model=yolo_lstm data.sequence_length=10"
  "model=yolo_efficientnet_lstm data.sequence_length=7"
)

for exp in "${experiments[@]}"; do
  python train.py ${exp} experiment.name=ablation_${exp}
done
```

---

#### **6-2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**

**Optunaçµ±åˆ**:
```python
import optuna

def objective(trial):
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç©ºé–“
    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)
    hidden_dim = trial.suggest_categorical('hidden_dim', [128, 256, 512])
    num_layers = trial.suggest_int('num_layers', 1, 3)

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = YOLOv8LSTM(hidden_dim=hidden_dim, num_layers=num_layers)
    trainer = Trainer(max_epochs=50)
    trainer.fit(model)

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¿”ã™
    return trainer.callback_metrics['val_map'].item()

# æœ€é©åŒ–å®Ÿè¡Œ
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

print('Best params:', study.best_params)
```

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/run/scripts/experiments/optimize_hyperparams.py`

---

#### **6-3. å¯è¦–åŒ–ãƒ»è«–æ–‡å›³è¡¨ä½œæˆ**

**å®Ÿè£…æ©Ÿèƒ½**:
- å­¦ç¿’æ›²ç·šãƒ—ãƒ­ãƒƒãƒˆ (loss, mAP)
- ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“çµæœã®è¡¨ãƒ»ã‚°ãƒ©ãƒ•
- 3Dæ¤œå‡ºçµæœã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
- å®šæ€§çš„è©•ä¾¡ (æˆåŠŸä¾‹ãƒ»å¤±æ•—ä¾‹)

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `vertebrae_YOLO/notebooks/visualization/plot_results.ipynb`
- `vertebrae_YOLO/run/scripts/utils/generate_figures.py`

---



## **æ¨å¥¨å®Ÿè£…å„ªå…ˆé †ä½**

### **Week 1-2: Phase 1 (ãƒ‡ãƒ¼ã‚¿æº–å‚™)**
1. `convert_to_yolo.py` å®Ÿè£…
2. YOLOå½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œè¨¼
3. `yolo_datamodule.py` å®Ÿè£…
4. DataLoaderå‹•ä½œç¢ºèª

### **Week 3-4: Phase 2 (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³)**
5. `yolo_baseline.py` å®Ÿè£…
6. `yolo_module.py` å®Ÿè£…
7. `train.py` å®Ÿè£…
8. Fold 0ã§å­¦ç¿’ãƒ»æ¤œè¨¼

### **Week 5-6: Phase 3 (LSTMçµ±åˆ)**
9. `yolo_lstm.py` å®Ÿè£…
10. DataLoaderä¿®æ­£ (sequence_lengthå¯¾å¿œ)
11. LSTMå­¦ç¿’ãƒ»æ¤œè¨¼
12. Phase 2ã¨ã®æ¯”è¼ƒ

### **Week 7-8: Phase 4 (ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æœ€é©åŒ–)**
13. EfficientNet/ResNetå®Ÿè£…
14. ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æ¯”è¼ƒå®Ÿé¨“
15. æœ€è‰¯ãƒ¢ãƒ‡ãƒ«é¸å®š

### **Week 9-10: Phase 5 (æ¨è«–ãƒ»è©•ä¾¡)**
16. æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…
17. 3Dçµ±åˆæ‰‹æ³•å®Ÿè£…
18. è©•ä¾¡æŒ‡æ¨™è¨ˆç®—

### **Week 11-12: Phase 6 (å®Ÿé¨“ãƒ»æ”¹å–„)**
19. ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“
20. å¯è¦–åŒ–ãƒ»è«–æ–‡å›³è¡¨ä½œæˆ

---

## **æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ **

### **immediate (ä»Šã™ãé–‹å§‹)**
- [ ] `vertebrae_YOLO/data_preparing/convert_to_yolo.py` ã®å®Ÿè£…é–‹å§‹
- [ ] è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« `run/conf/data_preparing.yaml` ã®ä½œæˆ
- [ ] 1ç—‡ä¾‹ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã—ã€YOLOå½¢å¼å¤‰æ›ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹æ¤œè¨¼

### **short-term (1é€±é–“ä»¥å†…)**
- [ ] å…¨ç—‡ä¾‹ã®YOLOå½¢å¼å¤‰æ›ã‚’å®Ÿè¡Œ
- [ ] çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆç¢ºèª (BBoxæ•°ã€ã‚µã‚¤ã‚ºåˆ†å¸ƒãªã©)
- [ ] ç›®è¦–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å“è³ªç¢ºèª

### **medium-term (2é€±é–“ä»¥å†…)**
- [ ] `yolo_datamodule.py` å®Ÿè£…
- [ ] DataLoaderã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
- [ ] Phase 2ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å­¦ç¿’é–‹å§‹

---

## **é‡è¦ãªå®Ÿè£…ä¸Šã®æ³¨æ„ç‚¹**

### **1. æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²ã®å¾¹åº•**
- åŒä¸€æ‚£è€…ã®ãƒ‡ãƒ¼ã‚¿ãŒ train/val ã«è·¨ãŒã‚‰ãªã„ã‚ˆã†ã«å³å®ˆ
- 5-foldåˆ†å‰²ã¯äº‹å‰ã«æ‚£è€…IDã§å®šç¾©ã—ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†

### **2. å†ç¾æ€§ã®ç¢ºä¿**
- ã™ã¹ã¦ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®š (PyTorch, NumPy, Python)
- Hydraã§è¨­å®šã‚’å®Œå…¨ã«è¨˜éŒ²
- å®Ÿé¨“ã”ã¨ã«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨Checkpointã‚’ã‚»ãƒƒãƒˆã§ä¿å­˜

### **3. ãƒ¡ãƒ¢ãƒªç®¡ç†**
- ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹æ•°ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®
- Gradient Accumulation ã®æ´»ç”¨
- Mixed Precision Training (FP16) ã®æ¤œè¨

### **4. åŒ»ç™‚AIç‰¹æœ‰ã®è¦ä»¶**
- è§£é‡ˆæ€§: å„æ®µéšã®å‡ºåŠ›ã‚’å¯è¦–åŒ–ãƒ»æ¤œè¨¼
- çµ±è¨ˆçš„å¦¥å½“æ€§: 5-fold CVã§å¹³å‡ã¨æ¨™æº–åå·®ã‚’å ±å‘Š
- å¤±æ•—ä¾‹åˆ†æ: èª¤æ¤œå‡ºãƒ»è¦‹é€ƒã—ã®åŸå› ã‚’è§£å‰–å­¦çš„ã«è€ƒå¯Ÿ

---

## **é€²æ—è¿½è·¡**

| Phase | ã‚¿ã‚¹ã‚¯ | çŠ¶æ…‹ | å®Œäº†æ—¥ | å‚™è€ƒ |
|-------|--------|------|--------|------|
| Phase 1 | YOLOå½¢å¼å¤‰æ› | âœ… å®Œäº† | 2025/10/20 | BBoxåº§æ¨™ãšã‚Œãƒ»ã‚¢ãƒ•ã‚£ãƒ³è¡Œåˆ—æœªé©ç”¨ã®å•é¡Œã‚’ä¿®æ­£å®Œäº†ã€‚90,000+ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ |
| Phase 1 | Datasetå®Ÿè£… | âœ… å®Œäº† | 2025/10/20 | yolo_dataset.py - 3ãƒãƒ£ãƒ³ãƒãƒ«HUå‡¦ç†å¯¾å¿œ |
| Phase 2 | YOLOãƒ¢ãƒ‡ãƒ«å®Ÿè£… | âœ… å®Œäº† | 2025/10/20 | yolo_baseline.py - Ultralytics YOLOv8ãƒ©ãƒƒãƒ‘ãƒ¼ |
| Phase 2 | å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ | âœ… å®Œäº† | 2025/10/20 | trainer.py - ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µåˆ¶å¾¡ |
| Phase 2 | å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ | âœ… å®Œäº† | 2025/10/20 | train.py - Hydraè¨­å®šç®¡ç†ã€5-fold CVå¯¾å¿œ |
| Phase 2 | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« | âœ… å®Œäº† | 2025/10/20 | config.yaml, model/yolo_baseline.yaml, split/fold_*.yaml, hyp_custom.yaml |
| Phase 2 | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å­¦ç¿’ | â¬œ æœªç€æ‰‹ | - | å®Ÿè£…å®Œäº†ã€å­¦ç¿’å®Ÿè¡Œå¾…ã¡ |
| Phase 3 | LSTMçµ±åˆ | â¬œ æœªç€æ‰‹ | - | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å­¦ç¿’å¾Œã«å®Ÿè£… |
| Phase 4 | ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æœ€é©åŒ– | â¬œ æœªç€æ‰‹ | - | EfficientNet/ResNetæ¯”è¼ƒå®Ÿé¨“ |
| Phase 5 | æ¨è«–ãƒ»è©•ä¾¡ | â¬œ æœªç€æ‰‹ | - | 3Dçµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ |
| Phase 6 | ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ | â¬œ æœªç€æ‰‹ | - | LSTMæœ‰ç„¡ã€ã‚¹ãƒ©ã‚¤ã‚¹æ•°æœ€é©åŒ– |

çŠ¶æ…‹: â¬œ æœªç€æ‰‹ / ğŸ”„ é€²è¡Œä¸­ / âœ… å®Œäº†

**æœ€æ–°æ›´æ–° (2025/10/20)**:
- Phase 1-2ã®å®Ÿè£…ãŒå®Œäº†ã—ã€å­¦ç¿’æº–å‚™ãŒæ•´ã„ã¾ã—ãŸ
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 90,638ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç”»åƒ+ãƒ©ãƒ™ãƒ«ï¼‰ãŒç”Ÿæˆæ¸ˆã¿
- ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã§éª¨æŠ˜ãªã—ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’åˆ¶å¾¡
- W&B/TensorBoardãƒ­ã‚°å¯¾å¿œå®Œå‚™
- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: Fold 0ã§ã®å­¦ç¿’å®Ÿè¡Œã¨æ€§èƒ½è©•ä¾¡

---

## **æœ€æ–°ã®æ›´æ–°å±¥æ­´**

### 2025/10/20: å®Ÿè£…æ–¹é‡å¤‰æ›´ - PyTorch Lightningã‚’ä½¿ã‚ãªã„ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ã¸

#### å¤‰æ›´ç†ç”±
- PyTorch Lightningã«ã‚ˆã‚‹æŠ½è±¡åŒ–ãŒéåº¦ã«è¤‡é›‘åŒ–
- ãƒ‡ãƒãƒƒã‚°ã‚„åˆ¶å¾¡ã®æ˜ç¢ºåŒ–ã®ãŸã‚ã€ç´ ã®PyTorchã«å¤‰æ›´
- Hydraã¯è¨­å®šç®¡ç†ã¨ã—ã¦ç¶­æŒï¼ˆæŸ”è»Ÿæ€§ã®ãŸã‚ï¼‰
- Ultralyticsã¯ç¶­æŒï¼ˆYOLOv8ã®å®Ÿè£…ã¨ã—ã¦æœ€é©ï¼‰

#### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿®æ­£
- âœ… [README.md](../../vertebrae_YOLO/README.md): Lightningè¨€åŠã‚’å‰Šé™¤ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’æ›´æ–°
- âœ… [knowledge.md](knowledge.md): å®Ÿè£…è¨ˆç”»ã‚’PyTorchãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã«å¤‰æ›´
- âœ… [memo.md](memo.md): Phase 2-3ã®å®Ÿè£…è¨ˆç”»ã‚’ä¿®æ­£ã€é€²æ—è¿½è·¡ã‚’æ›´æ–°
- âœ… [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆREADME.md](../../README.md): æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯èª¬æ˜ã‚’æ›´æ–°

#### æ–°ã—ã„å®Ÿè£…è¨ˆç”»
**Phase 1: Datasetå®Ÿè£…**
- `src/dataset/yolo_dataset.py`: æ¨™æº–çš„ãªPyTorch Dataset
- 3ãƒãƒ£ãƒ³ãƒãƒ«HUå‡¦ç†ã€æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²å¯¾å¿œ

**Phase 2: ãƒ¢ãƒ‡ãƒ«ãƒ»å­¦ç¿’å®Ÿè£…**
- `src/models/yolo_baseline.py`: YOLOv8ãƒ¢ãƒ‡ãƒ«ï¼ˆUltralyticsä½¿ç”¨ï¼‰
- `src/utils/trainer.py`: ã‚·ãƒ³ãƒ—ãƒ«ãªå­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
- `src/utils/metrics.py`: è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
- `run/scripts/train/train.py`: ç´ ã®PyTorchã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—

#### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. PyTorch Datasetå®Ÿè£…ï¼ˆ`yolo_dataset.py`ï¼‰
2. å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å®Ÿè£…ï¼ˆ`trainer.py`, `metrics.py`ï¼‰
3. å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…ï¼ˆ`train.py`ï¼‰
4. requirements.txtã‹ã‚‰PyTorch Lightningå‰Šé™¤

---

### 2025/10/20: Phase 1-2 å®Ÿè£…è¨ˆç”» - Datasetãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### å®Ÿè£…é …ç›®

**Phase 1: Datasetå®Ÿè£…**
- [yolo_dataset.py](../../vertebrae_YOLO/src/dataset/yolo_dataset.py) å®Ÿè£…äºˆå®š
  - 3ãƒãƒ£ãƒ³ãƒãƒ«HUã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å‡¦ç†ï¼ˆBone/Soft Tissue/Wide Windowï¼‰
  - æ‚£è€…ãƒ¬ãƒ™ãƒ«5-foldåˆ†å‰²å¯¾å¿œ
  - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆå›è»¢ã€åè»¢ã€æ˜åº¦èª¿æ•´ï¼‰with Albumentations
  - æ¨™æº–çš„ãªPyTorch Dataset
  - YOLOå½¢å¼ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒãƒ«ãƒã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¯¾å¿œï¼‰

**Phase 2: ãƒ¢ãƒ‡ãƒ«å®Ÿè£…**
- [yolo_baseline.py](../../vertebrae_YOLO/src/models/yolo_baseline.py) å®Ÿè£…äºˆå®š
  - YOLOv8nï¼ˆCSPDarknetãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ï¼‰
  - Ultralytics YOLOä½¿ç”¨
  - COCOäº‹å‰å­¦ç¿’æ¸ˆã¿é‡ã¿å¯¾å¿œ
  - éª¨æŠ˜æ¤œå‡ºï¼ˆ1ã‚¯ãƒ©ã‚¹ï¼‰

- [trainer.py](../../vertebrae_YOLO/src/utils/trainer.py) å®Ÿè£…äºˆå®š
  - ã‚·ãƒ³ãƒ—ãƒ«ãªPyTorchå­¦ç¿’ãƒ«ãƒ¼ãƒ—
  - mAP@0.5ã€mAP@0.5:0.95è©•ä¾¡
  - AdamWæœ€é©åŒ–å™¨ã€Cosine Annealing LR
  - Early Stoppingã€Checkpointä¿å­˜ã‚’è‡ªå‰å®Ÿè£…

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆHydraï¼‰**
- [config.yaml](../../vertebrae_YOLO/run/conf/config.yaml): ãƒ¡ã‚¤ãƒ³è¨­å®š
- [model/yolo_baseline.yaml](../../vertebrae_YOLO/run/conf/model/yolo_baseline.yaml): ãƒ¢ãƒ‡ãƒ«è¨­å®š
- [data/yolo_data.yaml](../../vertebrae_YOLO/run/conf/data/yolo_data.yaml): ãƒ‡ãƒ¼ã‚¿è¨­å®šï¼ˆ3ãƒãƒ£ãƒ³ãƒãƒ«HUè¨­å®šå«ã‚€ï¼‰
- [split/fold_*.yaml](../../vertebrae_YOLO/run/conf/split/): 5-foldåˆ†å‰²è¨­å®šï¼ˆfold_0ï½fold_4ï¼‰
  - å…¨30ç—‡ä¾‹ã‚’5åˆ†å‰²ï¼ˆå„fold: train 24ç—‡ä¾‹ã€val 6ç—‡ä¾‹ï¼‰

**å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
- [train.py](../../vertebrae_YOLO/run/scripts/train/train.py) å®Ÿè£…äºˆå®š
  - ã‚·ãƒ³ãƒ—ãƒ«ãªPyTorchã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—
  - Hydraã«ã‚ˆã‚‹è¨­å®šç®¡ç†
  - W&Bãƒ­ã‚®ãƒ³ã‚°å¯¾å¿œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  - Checkpointè‡ªå‹•ä¿å­˜
  - Early Stopping
  - å†ç¾æ€§ç¢ºä¿ï¼ˆã‚·ãƒ¼ãƒ‰å›ºå®šï¼‰

**ãã®ä»–**
- [requirements.txt](../../vertebrae_YOLO/requirements.txt): ä¾å­˜é–¢ä¿‚ãƒªã‚¹ãƒˆ
- [README.md](../../vertebrae_YOLO/README.md): ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜æ›¸

#### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ï¼ˆè¨ˆç”»ï¼‰

```
vertebrae_YOLO/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ yolo_baseline.py          # YOLOv8ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â””â”€â”€ yolo_dataset.py           # PyTorch Datasetï¼ˆ3ãƒãƒ£ãƒ³ãƒãƒ«HUå‡¦ç†ï¼‰
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ trainer.py                # å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚       â””â”€â”€ metrics.py                # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
â”œâ”€â”€ run/
â”‚   â”œâ”€â”€ conf/
â”‚   â”‚   â”œâ”€â”€ config.yaml               # ãƒ¡ã‚¤ãƒ³è¨­å®š
â”‚   â”‚   â”œâ”€â”€ model/yolo_baseline.yaml  # ãƒ¢ãƒ‡ãƒ«è¨­å®š
â”‚   â”‚   â”œâ”€â”€ data/yolo_data.yaml       # ãƒ‡ãƒ¼ã‚¿è¨­å®š
â”‚   â”‚   â””â”€â”€ split/fold_*.yaml         # 5-foldåˆ†å‰²ï¼ˆ0-4ï¼‰
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ train/
â”‚           â””â”€â”€ train.py              # ã‚·ãƒ³ãƒ—ãƒ«ãªPyTorchå­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ data_preparing/
â”‚   â””â”€â”€ convert_to_yolo.py            âœ… ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆPhase 1ã§å®Œäº†ï¼‰
â”œâ”€â”€ requirements.txt                   # ä¾å­˜é–¢ä¿‚ï¼ˆPyTorch Lightningã‚’å‰Šé™¤ï¼‰
â””â”€â”€ README.md                          âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜
```

#### ä½¿ç”¨æ–¹æ³•

**ç’°å¢ƒæ§‹ç¯‰**
```bash
cd vertebrae_YOLO
pip install -r requirements.txt
```

**å­¦ç¿’å®Ÿè¡Œ**
```bash
cd run/scripts/train

# Fold 0ã§å­¦ç¿’
python train.py

# ç‰¹å®šã®Foldã§å­¦ç¿’
python train.py split=fold_1

# è¨­å®šã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
python train.py training.max_epochs=50 data.batch_size=32
```

**DataLoaderå‹•ä½œç¢ºèª**
```bash
python test_dataloader.py
```

#### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**immediateï¼ˆå„ªå…ˆå®Ÿè£…ï¼‰**
1. PyTorch Datasetå®Ÿè£…ï¼ˆ`yolo_dataset.py`ï¼‰
2. å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å®Ÿè£…ï¼ˆ`trainer.py`, `metrics.py`ï¼‰
3. å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…ï¼ˆ`train.py`ï¼‰
4. requirements.txtã‹ã‚‰PyTorch Lightningå‰Šé™¤

**short-termï¼ˆ1é€±é–“ä»¥å†…ï¼‰**
5. å®Ÿè£…å®Œäº†å¾Œã€å‹•ä½œç¢ºèª
6. Fold 0ã§å­¦ç¿’å®Ÿè¡Œ
7. W&B/TensorBoardã§å­¦ç¿’æ›²ç·šç¢ºèª

**medium-termï¼ˆ2é€±é–“ä»¥å†…ï¼‰**
8. 5-fold CVå®Ÿè¡Œ
9. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½è©•ä¾¡ï¼ˆmAP@0.5 > 0.5ç›®æ¨™ï¼‰
10. Phase 3: LSTMçµ±åˆã®è¨­è¨ˆé–‹å§‹

#### é‡è¦ãªè¨­è¨ˆæ±ºå®š

**3ãƒãƒ£ãƒ³ãƒãƒ«HUå‡¦ç†ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰**
- R: Bone Window (WW=1400, WL=1100)
- G: Soft Tissue Window (WW=400, WL=100)
- B: Wide Window (WW=700, WL=150)
- DataModuleã§è‡ªå‹•çš„ã«3ãƒãƒ£ãƒ³ãƒãƒ«å¤‰æ›ã‚’å®Ÿè¡Œ

**æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰**
- 30ç—‡ä¾‹ã‚’5-foldã«åˆ†å‰²
- å„fold: train 24ç—‡ä¾‹ã€val 6ç—‡ä¾‹
- ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ï¼ˆåŒä¸€æ‚£è€…ã®ã‚¹ãƒ©ã‚¤ã‚¹ã¯åŒã˜foldï¼‰

**å®Ÿè£…æ–¹é‡**
- Ultralyticsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ´»ç”¨ã—ã¦YOLOv8ã‚’ç°¡æ½”ã«å®Ÿè£…
- ã‚·ãƒ³ãƒ—ãƒ«ãªPyTorchã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã§æ˜ç¢ºãªåˆ¶å¾¡
- Hydraã§è¨­å®šã‚’æŸ”è»Ÿã«ç®¡ç†ï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯¾å¿œï¼‰
- Mixed Precision Training (FP16) ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
- PyTorch Lightningã¯ä½¿ç”¨ã›ãšã€è¤‡é›‘ã•ã‚’æ’é™¤

---

### 2025/10/20 (æœ€æ–°): Phase 1-2 å®Ÿè£…å®Œäº† - å­¦ç¿’æº–å‚™å®Œäº†

#### å®Ÿè£…å®Œäº†é …ç›®

**Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå®Œäº†ï¼‰**
1. âœ… YOLOå½¢å¼ãƒ‡ãƒ¼ã‚¿å¤‰æ› - [convert_to_yolo.py](../../vertebrae_YOLO/data_preparing/convert_to_yolo.py)
   - 90,638ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆç”»åƒ+ãƒ©ãƒ™ãƒ«ï¼‰
   - ãƒãƒ«ãƒã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¯¾å¿œï¼ˆ1ã‚¹ãƒ©ã‚¤ã‚¹ã«è¤‡æ•°éª¨æŠ˜ï¼‰
   - BBoxåº§æ¨™ä¿®æ­£ã€ã‚¢ãƒ•ã‚£ãƒ³è¡Œåˆ—å¯¾å¿œæ¸ˆã¿

2. âœ… PyTorch Datasetå®Ÿè£… - [yolo_dataset.py](../../vertebrae_YOLO/src/dataset/yolo_dataset.py)
   - 3ãƒãƒ£ãƒ³ãƒãƒ«HUã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å‡¦ç†ï¼ˆBone/Soft Tissue/Wide Windowï¼‰
   - NIFTIç”»åƒèª­ã¿è¾¼ã¿
   - YOLOå½¢å¼ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿

**Phase 2: ãƒ¢ãƒ‡ãƒ«ãƒ»å­¦ç¿’å®Ÿè£…ï¼ˆå®Œäº†ï¼‰**
3. âœ… YOLOv8ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ« - [yolo_baseline.py](../../vertebrae_YOLO/src/models/yolo_baseline.py)
   - Ultralytics YOLOv8ãƒ©ãƒƒãƒ‘ãƒ¼
   - äº‹å‰å­¦ç¿’æ¸ˆã¿é‡ã¿å¯¾å¿œï¼ˆCOCOï¼‰
   - CSPDarknetãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³

4. âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ - [trainer.py](../../vertebrae_YOLO/src/utils/trainer.py)
   - CustomYOLOv8Dataset: éª¨æŠ˜ãªã—ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ç¢ºç‡çš„ã«ç„¡åŠ¹åŒ–
   - CustomDetectionTrainer: Ultralytics DetectionTrainerã‚’ç¶™æ‰¿
   - NIFTIâ†’PNGå¤‰æ›ã®è‡ªå‹•å®Ÿè¡Œ
   - Hydraè¨­å®šç®¡ç†çµ±åˆ

5. âœ… å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - [train.py](../../vertebrae_YOLO/run/scripts/train/train.py)
   - Hydraè¨­å®šç®¡ç†ï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯¾å¿œï¼‰
   - 5-foldäº¤å·®æ¤œè¨¼å¯¾å¿œ
   - ã‚·ãƒ¼ãƒ‰å›ºå®šã«ã‚ˆã‚‹å†ç¾æ€§ç¢ºä¿
   - W&B/TensorBoardãƒ­ã‚°å¯¾å¿œ

6. âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¾¤
   - [config.yaml](../../vertebrae_YOLO/run/conf/config.yaml): ãƒ¡ã‚¤ãƒ³è¨­å®š
   - [model/yolo_baseline.yaml](../../vertebrae_YOLO/run/conf/model/yolo_baseline.yaml): ãƒ¢ãƒ‡ãƒ«è¨­å®š
   - [constants/yolo_data.yaml](../../vertebrae_YOLO/run/conf/constants/yolo_data.yaml): ãƒ‡ãƒ¼ã‚¿è¨­å®šï¼ˆHUã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å«ã‚€ï¼‰
   - [split/fold_*.yaml](../../vertebrae_YOLO/run/conf/split/): 5-foldåˆ†å‰²ï¼ˆfold_0ï½4ï¼‰
   - [hyp_custom.yaml](../../vertebrae_YOLO/run/conf/hyp_custom.yaml): ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ»æå¤±é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

#### å®Ÿè£…ã®ç‰¹å¾´

**ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å·¥å¤«:**
- éª¨æŠ˜ã‚ã‚Šã‚µãƒ³ãƒ—ãƒ«: ç©æ¥µçš„ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆå›è»¢ã€åè»¢ã€æ˜åº¦èª¿æ•´ï¼‰
- éª¨æŠ˜ãªã—ã‚µãƒ³ãƒ—ãƒ«: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ç¢ºç‡çš„ã«ç„¡åŠ¹åŒ–ï¼ˆä¸å‡è¡¡å¯¾ç­–ï¼‰
- CustomYOLOv8Datasetã§ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡ã«å¿œã˜ã¦å‹•çš„ã«åˆ‡ã‚Šæ›¿ãˆ

**3ãƒãƒ£ãƒ³ãƒãƒ«HUã‚¦ã‚£ãƒ³ãƒ‰ã‚¦:**
- R (èµ¤): Bone Window (min=400, max=1800) - éª¨æ§‹é€ 
- G (ç·‘): Soft Tissue Window (min=-100, max=300) - è»Ÿéƒ¨çµ„ç¹”
- B (é’): Wide Window (min=-200, max=500) - å…¨ä½“ãƒãƒ©ãƒ³ã‚¹

**æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²:**
- 30ç—‡ä¾‹ã‚’5-foldã«åˆ†å‰²ï¼ˆå„fold: train 24ç—‡ä¾‹ã€val 6ç—‡ä¾‹ï¼‰
- ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ï¼ˆåŒä¸€æ‚£è€…ã®ã‚¹ãƒ©ã‚¤ã‚¹ã¯åŒã˜foldï¼‰

#### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**immediateï¼ˆä»Šã™ãå®Ÿè¡Œå¯èƒ½ï¼‰:**
1. Fold 0ã§å­¦ç¿’å®Ÿè¡Œ
   ```bash
   cd vertebrae_YOLO/run/scripts/train
   uv run python train.py
   ```
2. W&B/TensorBoardã§å­¦ç¿’æ›²ç·šç¢ºèª
3. mAP@0.5, mAP@0.5:0.95ã®è©•ä¾¡

**short-termï¼ˆ1é€±é–“ä»¥å†…ï¼‰:**
4. 5-foldäº¤å·®æ¤œè¨¼ã®å®Ÿè¡Œ
5. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½ã®ç¢ºç«‹ï¼ˆmAP@0.5 > 0.5ç›®æ¨™ï¼‰
6. å¤±æ•—ã‚±ãƒ¼ã‚¹ã®åˆ†æ

**medium-termï¼ˆ2é€±é–“ä»¥å†…ï¼‰:**
7. Phase 3: LSTMçµ±åˆã®è¨­è¨ˆé–‹å§‹
8. Phase 4: ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æ¯”è¼ƒå®Ÿé¨“ï¼ˆEfficientNet-B0/B1, ResNet-50ï¼‰

---

### 2025/10/20: Phase 1 - YOLOå½¢å¼å¤‰æ›å®Œäº†ã¨é‡å¤§ãªãƒã‚°ä¿®æ­£

#### è¨­è¨ˆå¤‰æ›´: 3ãƒãƒ£ãƒ³ãƒãƒ«HUã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å…¥åŠ›ã®æ¡ç”¨
**æ±ºå®šäº‹é …:**
- 3ã¤ã®ç•°ãªã‚‹HUå€¤ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§å‡¦ç†ã—ãŸç”»åƒã‚’3ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆRGBï¼‰ã¨ã—ã¦å…¥åŠ›
  - R (èµ¤): Bone Window (WW=1400, WL=1100) - éª¨æ§‹é€ 
  - G (ç·‘): Soft Tissue Window (WW=400, WL=100) - è»Ÿéƒ¨çµ„ç¹”
  - B (é’): Wide Window (WW=700, WL=150) - å…¨ä½“ãƒãƒ©ãƒ³ã‚¹

**ç†ç”±:**
- éª¨çµ„ç¹”ã¨è»Ÿéƒ¨çµ„ç¹”ã®æƒ…å ±ã‚’åŒæ™‚ã«æ´»ç”¨å¯èƒ½
- ImageNetäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ï¼ˆRGB 3ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰ã¨ã®æ•´åˆæ€§
- åŒ»ç™‚ç”»åƒè§£æã«ãŠã‘ã‚‹æ¨™æº–çš„æ‰‹æ³•

**å®Ÿè£…ã¸ã®å½±éŸ¿:**
- `convert_to_yolo.py`ã®`normalize_and_pad_image()`ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«å¯¾å¿œã«ä¿®æ­£äºˆå®š
- ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: [B, 1, H, W] â†’ [B, 3, H, W]

è©³ç´°ã¯[improvements.md](improvements.md#2025/10/20-ãƒãƒ«ãƒã‚¦ã‚£ãƒ³ãƒ‰ã‚¦huå€¤ã«ã‚ˆã‚‹3ãƒãƒ£ãƒ³ãƒãƒ«å…¥åŠ›ã®æ¡ç”¨)ã‚’å‚ç…§

#### å®Ÿè£…å†…å®¹
[vertebrae_YOLO/data_preparing/convert_to_yolo.py](../../vertebrae_YOLO/data_preparing/convert_to_yolo.py)ã®å®Ÿè£…å®Œäº†

#### ä¿®æ­£ã—ãŸé‡å¤§ãªå•é¡Œ
è©³ç´°ã¯[improvements.md](improvements.md)ã®ã€Œå¤±æ•—ã—ãŸå®Ÿè£…ã¨ãã®åŸå› åˆ†æã€ä¿®æ­£ç‚¹ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§

**å•é¡Œ1: BBoxåº§æ¨™ã®ãšã‚Œï¼ˆåº§æ¨™ç³»ã®ä¸ä¸€è‡´ï¼‰**
- åŸå› : å¤‰å½¢å‰ã®ãƒã‚¹ã‚¯ã‹ã‚‰åº§æ¨™è¨ˆç®— â†’ ç”»åƒã®ã¿ãƒªã‚µã‚¤ã‚º â†’ åº§æ¨™ç³»ã®ä¸ä¸€è‡´
- è§£æ±º: ç”»åƒã¨ãƒã‚¹ã‚¯ä¸¡æ–¹ã‚’å…ˆã«256x256ã«å¤‰å½¢ â†’ å¤‰å½¢å¾Œã®ãƒã‚¹ã‚¯ã‹ã‚‰BBoxæŠ½å‡º
- å®Ÿè£…: [normalize_and_pad_mask()](../../vertebrae_YOLO/data_preparing/convert_to_yolo.py#L232-L274)é–¢æ•°ã‚’æ–°è¦è¿½åŠ ï¼ˆæœ€è¿‘å‚è£œé–“ï¼‰

**å•é¡Œ2: ç”»åƒã®å‚¾ãï¼ˆã‚¢ãƒ•ã‚£ãƒ³è¡Œåˆ—ã®æœªé©ç”¨ï¼‰**
- åŸå› : `np.asarray(nii.dataobj)`ã§ã‚¢ãƒ•ã‚£ãƒ³è¡Œåˆ—ã‚’ç„¡è¦–
- è§£æ±º: `nii.get_fdata()`ã§ã‚¢ãƒ•ã‚£ãƒ³è¡Œåˆ—ã‚’è‡ªå‹•é©ç”¨ã—ã€å‚¾ãè£œæ­£
- å®Ÿè£…: [load_nifti_slice()](../../vertebrae_YOLO/data_preparing/convert_to_yolo.py#L89-L101)é–¢æ•°ã‚’ä¿®æ­£

**å‰¯æ¬¡çš„ãªä¿®æ­£:**
- HUå€¤ä¿æŒ: PILã‹ã‚‰scipyã®zoomã«å¤‰æ›´ï¼ˆCTå€¤ç¯„å›²-1000ï½3000ã‚’ä¿æŒï¼‰
- ãƒã‚¹ã‚¯æ•´æ•°æ€§æ‹…ä¿: `get_fdata()`ã®æµ®å‹•å°æ•°ç‚¹å‡ºåŠ›ã‚’`np.round().astype(np.int32)`ã§æ•´æ•°åŒ–

#### ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ
BBoxå“è³ªæ¤œè¨¼ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè£…: [yolo_bbox_quality_analysis.py](../../vertebrae_YOLO/notebook/yolo_bbox_quality_analysis.py)
- å…¨BBoxåº§æ¨™ã®çµ±è¨ˆåˆ†æ
- ã‚µã‚¤ã‚ºåˆ†å¸ƒãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ç¢ºèª
- ç›®è¦–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç”¨å¯è¦–åŒ–

#### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
- Phase 1æ®‹ã‚¿ã‚¹ã‚¯: DataLoaderå®Ÿè£…ï¼ˆ`yolo_datamodule.py`ï¼‰
- é€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ç”¨ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼æ§‹ç¯‰
- Phase 2æº–å‚™: YOLOãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å­¦ç¿’ç’°å¢ƒã®æ•´å‚™

---

**æœ€çµ‚æ›´æ–°æ—¥**: 2025/10/20