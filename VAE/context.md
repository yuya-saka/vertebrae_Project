# VAE ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ å®Ÿè£…é€²æ—

æœ€çµ‚æ›´æ–°æ—¥: 2025-11-23

## å®Ÿè£…å®Œäº†äº‹é …

### âœ… Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

#### 1. 3D Datasetå®Ÿè£… ([src/datamodule/dataset.py](src/datamodule/dataset.py))
- âœ“ `.npy`å½¢å¼ã®3Dãƒœãƒªãƒ¥ãƒ¼ãƒ (128Â³)èª­ã¿è¾¼ã¿
- âœ“ æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
- âœ“ åŒ…æ‹¬çš„ãª3D Data Augmentationå®Ÿè£…:
  - å·¦å³åè»¢
  - zè»¸å›ã‚Šã®å›è»¢ (-15Â°~15Â°)
  - xyæ–¹å‘ã®å¹³è¡Œç§»å‹• (5%)
  - ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° (0.9-1.1)
  - ã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºä»˜åŠ 
  - è¼åº¦ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
- âœ“ æ‚£è€…IDãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†

#### 2. DataModuleå®Ÿè£… ([src/datamodule/dataloader.py](src/datamodule/dataloader.py))
- âœ“ PyTorch Lightning DataModule
- âœ“ 5-Fold Cross Validationå¯¾å¿œ
- âœ“ fold_plan.mdã«åŸºã¥ãæ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²
- âœ“ FOLD_DEFINITIONè¾æ›¸ã«ã‚ˆã‚‹å³å¯†ãªFoldç®¡ç†
- âœ“ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢æ©Ÿèƒ½

### âœ… Phase 2: ãƒ¢ãƒ‡ãƒ«å®Ÿè£…

#### 1. Vector Quantizerå±¤ ([src/models/vector_quantizer.py](src/models/vector_quantizer.py))
- âœ“ ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯å­¦ç¿’ (embedding_dim Ã— num_embeddings)
- âœ“ Commitment Losså®Ÿè£…
- âœ“ Straight-Through Estimator (STE)
- âœ“ Exponential Moving Average (EMA) ã‚ªãƒ—ã‚·ãƒ§ãƒ³
- âœ“ Perplexityè¨ˆç®— (ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ä½¿ç”¨å¤šæ§˜æ€§)
- âœ“ ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ä½¿ç”¨ç‡ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

#### 2. 3D VQ-VAEæœ¬ä½“ ([src/models/vq_vae_3d.py](src/models/vq_vae_3d.py))
- âœ“ 3D Encoderå®Ÿè£…:
  - å…¥åŠ›: (B, 1, 128, 128, 128)
  - 4å±¤ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: [32, 64, 128, 256]ãƒãƒ£ãƒãƒ«
  - BatchNorm + LeakyReLU + Dropout
  - å‡ºåŠ›: (B, 256, 8, 8, 8) æ½œåœ¨è¡¨ç¾
- âœ“ 3D Decoderå®Ÿè£…:
  - Encoderã®å¯¾ç§°æ§‹é€ 
  - 4å±¤ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
  - æœ€çµ‚å±¤: Sigmoidæ´»æ€§åŒ– ([0,1]ç¯„å›²)
- âœ“ å†æ§‹æˆèª¤å·®ãƒãƒƒãƒ—ç”Ÿæˆæ©Ÿèƒ½ (éª¨æŠ˜æ¤œå‡ºç”¨)
- âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ“ãƒ«ãƒ€ãƒ¼é–¢æ•°

### âœ… Phase 3: å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

#### Lightning Module ([src/training/lightning_module.py](src/training/lightning_module.py))
- âœ“ å­¦ç¿’ãƒ«ãƒ¼ãƒ—å®Ÿè£…:
  - å†æ§‹æˆLoss (L1/L2é¸æŠå¯èƒ½)
  - VQ Lossçµ±åˆ
  - ç·åˆLoss = recon_loss + vq_loss
- âœ“ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š (Adam/AdamW)
- âœ“ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©è¨­å®š:
  - CosineAnnealingLR
  - ReduceLROnPlateau
- âœ“ WandBãƒ­ã‚®ãƒ³ã‚°:
  - train/val losså„ç¨®
  - Perplexity, ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ä½¿ç”¨ç‡
  - å†æ§‹æˆç”»åƒã‚µãƒ³ãƒ—ãƒ« (epochæ¯)
- âœ“ å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°

### âœ… Phase 4: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

#### Hydraè¨­å®šæ§‹é€ 
1. âœ“ [config.yaml](run/conf/config.yaml) - ãƒ¡ã‚¤ãƒ³è¨­å®š
2. âœ“ [config_debug.yaml](run/conf/config_debug.yaml) - ãƒ‡ãƒãƒƒã‚°ç”¨è¨­å®š
3. âœ“ [model/vq_vae.yaml](run/conf/model/vq_vae.yaml) - ãƒ¢ãƒ‡ãƒ«ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
4. âœ“ [dataset/vae_data.yaml](run/conf/dataset/vae_data.yaml) - ãƒ‡ãƒ¼ã‚¿ãƒ»Augmentationè¨­å®š
5. âœ“ [training/vae_training.yaml](run/conf/training/vae_training.yaml) - å­¦ç¿’è¨­å®š

#### è¨­å®šã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
```yaml
# ãƒ¢ãƒ‡ãƒ«
latent_dim: 256
num_embeddings: 512
commitment_cost: 0.25

# å­¦ç¿’
max_epochs: 200
learning_rate: 1e-4
batch_size: 4
early_stopping_patience: 20

# Augmentation
- å·¦å³åè»¢ã€zè»¸å›è»¢(-15Â°~15Â°)ã€xyå¹³è¡Œç§»å‹•(5%)
- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºã€è¼åº¦ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
```

### âœ… Phase 5: å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### [run/scripts/train_vae.py](run/scripts/train_vae.py)
- âœ“ Hydraçµ±åˆ
- âœ“ 5-Fold CVå¯¾å¿œ
- âœ“ WandBãƒ­ã‚®ãƒ³ã‚° (foldåˆ¥)
- âœ“ Model Checkpoint & Early Stopping
- âœ“ è¨­å®šã®è‡ªå‹•ä¿å­˜

#### ä½¿ç”¨ä¾‹
```bash
# 1ã¤ã®Foldã§å­¦ç¿’
python train_vae.py fold_id=1

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
python train_vae.py --config-name=config_debug fold_id=1

# å…¨Foldå®Ÿè¡Œ
for i in {1..5}; do python train_vae.py fold_id=$i; done
```

### âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

1. âœ“ [README.md](README.md) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã€ä½¿ç”¨æ–¹æ³•
2. âœ“ [PLAN.md](PLAN.md) - ç ”ç©¶å…¨ä½“ã®è¨ˆç”» (æ—¢å­˜)
3. âœ“ [fold_plan.md](fold_plan.md) - Foldåˆ†å‰²è©³ç´° (æ—¢å­˜)
4. âœ“ [data.md](data.md) - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± (æ—¢å­˜)
5. âœ“ [context.md](context.md) - ã“ã®ãƒ•ã‚¡ã‚¤ãƒ« (å®Ÿè£…é€²æ—)
6. âœ“ [test_installation.py](test_installation.py) - å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
VAE/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/              # VQ-VAEãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â”œâ”€â”€ vector_quantizer.py
â”‚   â”‚   â””â”€â”€ vq_vae_3d.py
â”‚   â”œâ”€â”€ datamodule/          # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â””â”€â”€ dataloader.py
â”‚   â””â”€â”€ training/            # Lightning Module
â”‚       â””â”€â”€ lightning_module.py
â”œâ”€â”€ run/
â”‚   â”œâ”€â”€ conf/                # Hydraè¨­å®š
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â”œâ”€â”€ config_debug.yaml
â”‚   â”‚   â”œâ”€â”€ model/vq_vae.yaml
â”‚   â”‚   â”œâ”€â”€ data/vae_data.yaml
â”‚   â”‚   â””â”€â”€ training/vae_training.yaml
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ train_vae.py     # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ outputs/                 # å­¦ç¿’çµæœ
â””â”€â”€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå„ç¨®
```

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **PyTorch**: æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **PyTorch Lightning**: å­¦ç¿’ãƒ«ãƒ¼ãƒ—æŠ½è±¡åŒ–
- **Hydra**: è¨­å®šç®¡ç†
- **WandB**: å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- **NumPy**: æ•°å€¤è¨ˆç®—

## ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

1. **å…¥åŠ›**: æ­£å¸¸æ¤ä½“ã®3Dãƒœãƒªãƒ¥ãƒ¼ãƒ  (128Â³, .npy, [0,1]æ­£è¦åŒ–æ¸ˆã¿)
2. **Augmentation**: å›è»¢ã€åè»¢ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ãƒã‚¤ã‚ºç­‰
3. **Encoder**: (B, 1, 128Â³) â†’ (B, 256, 8Â³)
4. **Vector Quantizer**: æ½œåœ¨è¡¨ç¾ã®é›¢æ•£åŒ–
5. **Decoder**: (B, 256, 8Â³) â†’ (B, 1, 128Â³) å†æ§‹æˆ
6. **Loss**: reconstruction + vq_loss

## Foldåˆ†å‰²ã®è©³ç´°

- **Train**: 30ç—‡ä¾‹ (5 Fold)
- **Test**: 8ç—‡ä¾‹ (Hold-outã€æœ€çµ‚è©•ä¾¡ç”¨)
- **Foldæ¯ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿**: ç´„180å€‹ã®æ­£å¸¸æ¤ä½“
- **Foldæ¯ã®æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿**: ç´„45å€‹ã®æ­£å¸¸æ¤ä½“

å„Foldã®æ‚£è€…IDå‰²ã‚Šå½“ã¦ã¯[dataloader.py](src/datamodule/dataloader.py)ã®`FOLD_DEFINITION`å‚ç…§ã€‚

## WandBæŒ‡æ¨™

### å­¦ç¿’æ™‚
- `train/recon_loss`: è¨“ç·´å†æ§‹æˆLoss (L1 or L2)
- `train/vq_loss`: Vector Quantization Loss
- `train/total_loss`: ç·åˆLoss
- `train/perplexity`: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ä½¿ç”¨å¤šæ§˜æ€§
- `train/codebook_usage`: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ä½¿ç”¨ç‡ (0-1)
- `train/learning_rate`: å­¦ç¿’ç‡

### æ¤œè¨¼æ™‚
- `val/recon_loss`: æ¤œè¨¼å†æ§‹æˆLoss
- `val/vq_loss`: æ¤œè¨¼VQ Loss
- `val/total_loss`: æ¤œè¨¼ç·åˆLoss
- `val/perplexity`: æ¤œè¨¼Perplexity
- `val/original_slice_epochX`: å…ƒç”»åƒã®ä¸­å¤®ã‚¹ãƒ©ã‚¤ã‚¹
- `val/recon_slice_epochX`: å†æ§‹æˆç”»åƒã®ä¸­å¤®ã‚¹ãƒ©ã‚¤ã‚¹
- `val/error_slice_epochX`: å†æ§‹æˆèª¤å·®ãƒãƒƒãƒ—

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### ğŸ”„ å®Ÿè£…äºˆå®š (å„ªå…ˆåº¦é †)

1. **å­¦ç¿’å®Ÿè¡Œã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**
   - [ ] Fold 1ã§ãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œ
   - [ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
   - [ ] å…¨Fold (1-5) ã§ã®å­¦ç¿’

2. **å†æ§‹æˆèª¤å·®ãƒãƒƒãƒ—ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
   - [ ] å­¦ç¿’æ¸ˆã¿VQVAEã§å…¨ãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆèª¤å·®ã‚’è¨ˆç®—
   - [ ] `.npy`å½¢å¼ã§ä¿å­˜ (éª¨æŠ˜æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ç”¨)

3. **éª¨æŠ˜æ¤œå‡ºãƒ¢ãƒ‡ãƒ« (Phase 2)**
   - [ ] 3D U-Netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
   - [ ] å¼±æ•™å¸«ã‚ã‚ŠLossé–¢æ•°å®Ÿè£… (L1, L2, L3, L4)
   - [ ] å†æ§‹æˆèª¤å·®ãƒãƒƒãƒ— + å¼±ãƒ©ãƒ™ãƒ«ã§ã®å­¦ç¿’

4. **è©•ä¾¡ãƒ»å¯è¦–åŒ–**
   - [ ] Hold-out Testãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡
   - [ ] å†æ§‹æˆèª¤å·®ã®çµ±è¨ˆåˆ†æ
   - [ ] 3Då¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«

## æ—¢çŸ¥ã®åˆ¶ç´„ãƒ»æ³¨æ„äº‹é …

1. **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**
   - 3Dãƒœãƒªãƒ¥ãƒ¼ãƒ  (128Â³) Ã— ãƒãƒƒãƒã‚µã‚¤ã‚º4 â†’ ç´„8GB GPU RAM
   - ãƒ¡ãƒ¢ãƒªä¸è¶³æ™‚ã¯batch_size=2ã¾ãŸã¯precision=16æ¨å¥¨

2. **å­¦ç¿’æ™‚é–“**
   - 1 epoch: ç´„5-10åˆ† (GPUä¾å­˜)
   - å…¨å­¦ç¿’ (200 epochs): ç´„16-32æ™‚é–“
   - 5-Fold CVå…¨ä½“: ç´„80-160æ™‚é–“

3. **ãƒ‡ãƒ¼ã‚¿é‡ã®é™ç•Œ**
   - å„Foldã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: ç´„180å€‹ (å°è¦æ¨¡)
   - Augmentationå¼·åŒ–ãŒå¿…é ˆ
   - Early Stoppingæ¨å¥¨ (éå­¦ç¿’é˜²æ­¢)

4. **ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯å´©å£Šãƒªã‚¹ã‚¯**
   - num_embeddingsãŒå¤§ãã™ãã‚‹ã¨ä¸€éƒ¨ã—ã‹ä½¿ã‚ã‚Œãªã„
   - Perplexity/Usageç›£è¦–ãŒé‡è¦
   - åˆæœŸå€¤: 512 (çµŒé¨“çš„ã«é©åˆ‡)

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q. VQ LossãŒæ¸›å°‘ã—ãªã„
- A. commitment_costã‚’èª¿æ•´ (0.1-0.5)
- A. num_embeddingsã‚’æ¸›ã‚‰ã™ (256-512)

### Q. å†æ§‹æˆãŒä¸é®®æ˜
- A. latent_dimã‚’å¢—ã‚„ã™ (256â†’512)
- A. hidden_dimsã‚’æ·±ãã™ã‚‹

### Q. PerplexityãŒä½ã„ (ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ä½¿ç”¨ç‡ä½)
- A. num_embeddingsã‚’æ¸›ã‚‰ã™
- A. EMAã‚’æœ‰åŠ¹åŒ– (use_ema=True)

## å‚è€ƒæ–‡çŒ®ãƒ»ãƒªãƒ³ã‚¯

- [VQ-VAEè«–æ–‡](https://arxiv.org/abs/1711.00937)
- [PyTorch Lightning Docs](https://lightning.ai/docs/pytorch/stable/)
- [Hydra Docs](https://hydra.cc/)

## å¤‰æ›´å±¥æ­´

### 2025-11-23
- âœ… åˆå›å®Ÿè£…å®Œäº†
- âœ… å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
- âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™
- ğŸ”„ å­¦ç¿’å®Ÿè¡Œå¾…ã¡
