## 1. プロジェクト名

Attention-Guided Multi-Task Modelによる椎骨骨折検出と高精度3D可視化

## 2. 目的

現行の卒業論文の手法 （スライス単位の画像分類と単純平均による3D統合）では、最終的なPR-AUCが0.17と低いこと 、および予測領域がアノテーションよりも過大に（直方体状に）広がるという課題 が特定されている。

本プロジェクトの目的は、以下の2点を達成するマルチタスク・アーキテクチャを実装することである。

1. **分類精度の向上:** セグメンテーションタスクを補助的に解かせることで、モデル（エンコーダ）が骨折の「位置」を学習し、分類ヘッドの特徴抽出能力を向上させる。
    
2. **3D可視化の精緻化:** 分類確率とセグメンテーションマスクを組み合わせて投影し、3D空間での論理積（乗算）統合を行うことで、アーティファクトを排除し 、骨折領域の局在性を高める。
    

## 3. ベースライン（現行手法）

- **モデル:** ResNet18
    
- **タスク:** 2Dスライス（Axial, Coronal, Sagittal）の2クラス画像分類（骨折あり/なし）
    
- **3D統合法:** 各方向から得られた確率マップの3D空間での単純平均
    

## 4. 提案アーキテクチャ（Y字型マルチタスクモデル）

ベースラインのResNet18 （またはEfficientNet ）を共通エンコーダ（幹）として流用し、2つのヘッド（枝）を持つY字型モデルを構築する。

### (A) 共通エンコーダ (Encoder)

- **役割:** 特徴抽出。
    
- **構成:** U-Netのエンコーダ部に相当。ResNet18の `conv1` から `conv5`（最終全結合層の手前）までの特徴マップを利用する。
    

### (B) 枝1： セグメンテーション・デコーダ (Decoder)

- **役割:** 骨折領域の位置特定（ピクセル単位）。
    
- **構成:** U-Netのデコーダ部。
    
- **キー機構:** アップサンプリングとスキップ接続の合流地点に「**アテンション・ゲート (Attention Gate)**」を挿入する。これにより、背景ノイズを抑制し、骨折関連領域の特徴のみを強調させる。
    
- **出力:** `P_seg(x, y)` （ピクセル単位のセグメンテーション確率マップ, 0.0〜1.0）
    

### (C) 枝2： 分類ヘッド (Classification Head)

- **役割:** スライス全体の骨折有無の判定（論文のタスクと同じ ）。
    
- **構成:**
    
    1. エンコーダの最深部（ボトルネック、`conv5` の出力）を入力とする。
        
    2. グローバル平均プーリング (GAP) を適用。
        
    3. 全結合層(FC), Dropout(0.2) , Sigmoid を適用。
        
- **出力:** `P_class` （スライス単位の単一の分類確率, 0.0〜1.0）
    

## 5. データパイプライン

- **入力:** 2Dスライス画像（Axial, Coronal, Sagittal） 。
    
- **正解ラベル:** 以下の2つをペアで用意する。
    
    1. **`Label_class`**: スライス単位の2値ラベル（0 or 1）。アノテーションピクセルが1つでも存在すれば「1」 。
        
    2. **`Label_seg`**: ピクセル単位の2値アノテーションマスク 。
        
- **データ拡張:** 画像と `Label_seg` マスクに対し、論文と同一の変換（回転、平行移動、反転、ノイズ等 ）を同時に適用する。
    

## 6. 学習戦略（Segをガイドとして利用）

骨折領域が小さく、セグメンテーションタスクが過度に学習に影響するのを防ぐため、損失の重み付けを行う。

- **総損失 (Total Loss):**
    
    Total_Loss=(wclass​×Lossclass​)+(wseg​×Lossseg​)
    
- **`Loss_class` (分類損失):**
    
    - **関数:** `BCELoss`（ベースラインと同様 ）。
        
    - **重み (w_class):** **1.0** （主タスク）
        
- **`Loss_seg` (セグメンテーション損失):**
    
    - **関数:** **Focal Loss** または **Focal Tversky Loss**（小さなターゲット領域 の学習に特化させるため）。
        
    - **重み (w_seg):** **0.1** （補助タスク）
        
- **その他:** Optimizer (Adam) , Scheduler (ReduceLROnPlateau) はベースラインを踏襲する。
    

## 7. 推論・3D統合法（2段階絞り込み）

現行の単純平均 を廃止し、以下の2段階の乗算（論理積）プロセスを実行する。

### ステップ1： スライス単位での確率マップ絞り込み

- **目的:** 論文の課題である「予測領域の肥大化」 を2Dスライスレベルで解決する。
    
- **処理:** モデルから出力された `P_class`（スライス全体の信頼度）と `P_seg(x, y)`（空間的な位置ガイド）を乗算する。
    
    Pfinal_slice​(x,y)=Pclass​×Pseg​(x,y)
    
- **効果:** セグメンテーションが誤ってノイズを検出しても `P_class` が低ければ抑制され、逆に `P_class` が高くても `P_seg` が低い背景領域の確率はゼロに近づく。
    

### ステップ2： 3Dボクセル空間での論理積（AND）統合

- **目的:** 3方向からの情報を統合し、アーティファクト を除去し、3D空間での局在性を最大化する。
    
- **処理:**
    
    1. 3方向（Axial, Coronal, Sagittal）のモデルそれぞれで「ステップ1」を実行し、`P_final_slice` を得る。
        
    2. これらの3D確率ボリュームを `P_ax(x,y,z)`, `P_co(x,y,z)`, `P_sa(x,y,z)` として構築する。
        
    3. これらをボクセル単位で**乗算**する。
        
        Pvoxel​(x,y,z)=Pax​(x,y,z)×Pco​(x,y,z)×Psa​(x,y,z)
        

## 8. 評価指標

- **主要評価:** 最終的な3Dボクセル確率マップ `P_voxel` に対する **PR-AUC** 。ベースラインの0.17 からの改善を測定する。
    
- **副次評価:** `Precision`, `Recall`, `F1-score` を最適なしきい値で算出。
    
- **定性評価:** 3D可視化結果をベースライン（図18） と比較し、予測領域の精緻化を確認する。

A/
├── src/
│   ├── model/
│   │   └── unet.py (新規)
│   ├── modelmodule/
│   │   └── loss.py (新規)
│   ├── datamodule/
│   │   └── dataset.py (新規)
│   └── inference/
│       └── inference.py (新規)
├── run/
│   ├── conf/ (設定ファイル)
│   └── scripts/
│       ├── train/train.py
│       └── eval/evaluate.py

