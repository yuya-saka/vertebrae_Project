# A/ Attention-Guided Multi-Task Model å®Œå…¨å®Ÿè£…è¨ˆç”»

## ğŸ“‘ å®Ÿè£…æ¦‚è¦

**A/ãƒ•ã‚©ãƒ«ãƒ€ã§ä¸€ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰**ã—ã¾ã™ã€‚Hydra+WandBã«ã‚ˆã‚‹è¨­å®šç®¡ç†ã¨å¯è¦–åŒ–ã‚’å«ã‚€ã€å®Œå…¨ãªåŒ»ç™‚AIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Ÿè£…ã—ã¾ã™ã€‚

## ğŸ¯ å®Ÿè£…æ–¹é‡

- âœ… **ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†** (3æ–¹å‘ã‚¹ãƒ©ã‚¤ã‚¹ + ãƒã‚¹ã‚¯ + CSV)
- **å­¦ç¿’æ™‚ã«256Ã—256ã¸ãƒªã‚µã‚¤ã‚º**
- **HUå€¤ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¨­å®šå¯èƒ½ã«** (3ãƒãƒ£ãƒ³ãƒãƒ«å…¥åŠ›)
- **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–**: **ãƒãƒƒãƒå†…ã‚¯ãƒ©ã‚¹å‡è¡¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°** + **ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µ** (å¼·ã„å›è»¢æ‹¡å¼µ)
- **Hydra (YAML)** ã§è¨­å®šç®¡ç†
- **WandB** ã§å­¦ç¿’æ›²ç·šå¯è¦–åŒ–

---

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
A/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ multitask_unet.py          # Yå­—å‹ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯U-Net
â”‚   â”‚   â””â”€â”€ attention_gate.py          # Attention Gateå®Ÿè£…
â”‚   â”œâ”€â”€ modelmodule/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ multitask_loss.py          # åˆ†é¡+ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¤‡åˆæå¤±
â”‚   â”‚   â””â”€â”€ metrics.py                 # Dice, IoU, PR-AUCè¨ˆç®—
â”‚   â”œâ”€â”€ datamodule/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py                 # MultiTaskDataset (CT + Mask + Label)
â”‚   â”‚   â”œâ”€â”€ sampler.py                 # BalancedBatchSampler (ãƒãƒƒãƒå†…ã‚¯ãƒ©ã‚¹å‡è¡¡)
â”‚   â”‚   â””â”€â”€ dataloader.py              # DataLoaderä½œæˆé–¢æ•°
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ common.py                  # ã‚·ãƒ¼ãƒ‰å›ºå®šã€æ‚£è€…åˆ†å‰²ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ run/
â”‚   â”œâ”€â”€ conf/
â”‚   â”‚   â”œâ”€â”€ config.yaml                # ãƒ¡ã‚¤ãƒ³è¨­å®š
â”‚   â”‚   â”œâ”€â”€ constants.yaml             # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã€æ‚£è€…IDå®šç¾©
â”‚   â”‚   â”œâ”€â”€ train.yaml                 # å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”‚   â”œâ”€â”€ multitask_unet_resnet18.yaml
â”‚   â”‚   â”‚   â””â”€â”€ multitask_unet_efficientnet.yaml
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ axial.yaml             # Axialæ–¹å‘ã®ãƒ‡ãƒ¼ã‚¿è¨­å®š
â”‚   â”‚   â”‚   â”œâ”€â”€ coronal.yaml
â”‚   â”‚   â”‚   â””â”€â”€ sagittal.yaml
â”‚   â”‚   â””â”€â”€ split/
â”‚   â”‚       â”œâ”€â”€ fold_0.yaml            # æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²
â”‚   â”‚       â”œâ”€â”€ fold_1.yaml
â”‚   â”‚       â”œâ”€â”€ fold_2.yaml
â”‚   â”‚       â”œâ”€â”€ fold_3.yaml
â”‚   â”‚       â””â”€â”€ fold_4.yaml
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ train.py                   # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚       â””â”€â”€ eval.py                    # è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (å¾Œã§å®Ÿè£…)
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ data_verification.ipynb        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ç”¨ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
â”œâ”€â”€ output/                             # å­¦ç¿’çµæœä¿å­˜å…ˆï¼ˆæ–¹å‘åˆ¥ãƒ»foldåˆ¥ã«è‡ªå‹•åˆ†å‰²ï¼‰
â”‚   â”œâ”€â”€ axial/
â”‚   â”‚   â”œâ”€â”€ fold_0/
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoints/          # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿
â”‚   â”‚   â”‚   â”œâ”€â”€ logs/                 # å­¦ç¿’ãƒ­ã‚°
â”‚   â”‚   â”‚   â””â”€â”€ config.yaml           # ä½¿ç”¨ã—ãŸè¨­å®š
â”‚   â”‚   â”œâ”€â”€ fold_1/
â”‚   â”‚   â”œâ”€â”€ fold_2/
â”‚   â”‚   â”œâ”€â”€ fold_3/
â”‚   â”‚   â””â”€â”€ fold_4/
â”‚   â”œâ”€â”€ coronal/
â”‚   â”‚   â”œâ”€â”€ fold_0/
â”‚   â”‚   â”œâ”€â”€ fold_1/
â”‚   â”‚   â”œâ”€â”€ fold_2/
â”‚   â”‚   â”œâ”€â”€ fold_3/
â”‚   â”‚   â””â”€â”€ fold_4/
â”‚   â””â”€â”€ sagittal/
â”‚       â”œâ”€â”€ fold_0/
â”‚       â”œâ”€â”€ fold_1/
â”‚       â”œâ”€â”€ fold_2/
â”‚       â”œâ”€â”€ fold_3/
â”‚       â””â”€â”€ fold_4/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml                      # uvç®¡ç†
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ— (Phaseåˆ¥)

### **Phase 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç›¤æ§‹ç¯‰**

#### 1.1 ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
- A/ ä»¥ä¸‹ã®å…¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
- `__init__.py` ã‚’å„ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«é…ç½®
- `pyproject.toml` ä½œæˆ (uvç”¨)
- `.gitignore` ä½œæˆ

#### 1.2 ä¾å­˜é–¢ä¿‚å®šç¾©

`pyproject.toml`:
```toml
[project]
name = "vertebrae-multitask"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
    "torch>=2.0.0",
    "torchvision",
    "nibabel",
    "numpy",
    "pandas",
    "opencv-python",
    "hydra-core>=1.3.0",
    "wandb",
    "scikit-learn",
    "matplotlib",
    "tqdm"
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

---

### **Phase 2: ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…**

#### 2.1 `src/datamodule/dataset.py` - MultiTaskDataset

**ä¸»è¦æ©Ÿèƒ½:**
- CTç”»åƒã¨ãƒã‚¹ã‚¯ç”»åƒã®ãƒšã‚¢èª­ã¿è¾¼ã¿
- CSV: `FullPath`, `Fracture_Label` ã¨å¯¾å¿œã™ã‚‹ `MaskPath` ã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
- **3ãƒãƒ£ãƒ³ãƒãƒ«HU Windowå¤‰æ›** (è¨­å®šå¯èƒ½):
  - Ch1: [0, 1800] (éª¨å…¨ä½“)
  - Ch2: [-200, 300] (è»Ÿéƒ¨çµ„ç¹”)
  - Ch3: [200, 1200] (éª¨æ¡ä»¶)
- **256Ã—256ã¸ãƒªã‚µã‚¤ã‚º** (cv2.INTER_LINEAR for image, cv2.INTER_NEAREST for mask)
- **ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µ** (is_training=Trueã®æ™‚ã®ã¿ã€`__getitem__()`ã§æ¯å›é©ç”¨):
  - **å›è»¢: Â±45åº¦ (å¤§ãã‚)**
  - å¹³è¡Œç§»å‹•: Â±20px
  - ã‚¹ã‚±ãƒ¼ãƒ«: 0.8-1.2
  - æ°´å¹³åè»¢: 50%
  - è¼åº¦/ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ: Â±0%
- **ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆå–å¾—ãƒ¡ã‚½ãƒƒãƒ‰**: `get_labels()` ã§å…¨ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ©ãƒ™ãƒ«ã‚’è¿”ã™ (BalancedBatchSamplerç”¨)

**è¿”ã‚Šå€¤:**
```python
{
    'image': torch.Tensor (3, 256, 256),  # 3ch HU window
    'mask': torch.Tensor (1, 256, 256),   # ã‚»ã‚°ãƒã‚¹ã‚¯
    'label_class': torch.Tensor (scalar), # 0 or 1
    'metadata': {
        'case': int,
        'vertebra': str,
        'slice_index': int
    }
}
```

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:**
```python
class MultiTaskDataset(Dataset):
    def __init__(
        self,
        csv_files: List[str],
        image_base_dir: str,
        mask_base_dir: str,
        hu_windows: Dict,
        image_size: Tuple[int, int] = (256, 256),
        augmentation: Optional[Dict] = None,
        is_training: bool = True,
    ):
        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        self.data = self._load_csv_files(csv_files)

        # ãƒã‚¹ã‚¯ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ (CTç”»åƒãƒ‘ã‚¹ã‹ã‚‰å¯¾å¿œã™ã‚‹ãƒã‚¹ã‚¯ãƒ‘ã‚¹ã‚’ç”Ÿæˆ)
        self.data['MaskPath'] = self.data.apply(
            lambda row: self._construct_mask_path(row, mask_base_dir),
            axis=1
        )

        # ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯ä½¿ç”¨ã—ãªã„ï¼ˆBalancedBatchSamplerã§å¯¾å¿œï¼‰
        print(f"Dataset initialized with {len(self.data)} samples")
        fracture_count = (self.data['Fracture_Label'] == 1).sum()
        print(f"Fracture slices: {fracture_count} ({fracture_count/len(self.data)*100:.2f}%)")

    def _construct_mask_path(self, row, mask_base_dir):
        # CT: .../axial/inp1003/27/slice_000.nii
        # -> Mask: .../axial_mask/inp1003/27/mask_000.nii
        ct_path = Path(row['FullPath'])
        case_id = f"inp{row['Case']}"
        vertebra = str(row['Vertebra'])
        slice_idx = row['SliceIndex']

        mask_path = Path(mask_base_dir) / case_id / vertebra / f"mask_{slice_idx:03d}.nii"
        return str(mask_path)

    def _create_3channel_input(self, image: np.ndarray) -> np.ndarray:
        """3ãƒãƒ£ãƒ³ãƒãƒ«HU Windowå¤‰æ›"""
        ch1 = self._normalize_hu_window(image.copy(),
                                        self.hu_windows['channel_1']['min'],
                                        self.hu_windows['channel_1']['max'])
        ch2 = self._normalize_hu_window(image.copy(),
                                        self.hu_windows['channel_2']['min'],
                                        self.hu_windows['channel_2']['max'])
        ch3 = self._normalize_hu_window(image.copy(),
                                        self.hu_windows['channel_3']['min'],
                                        self.hu_windows['channel_3']['max'])
        return np.stack([ch1, ch2, ch3], axis=0)

    def _apply_augmentation(self, image: np.ndarray, mask: np.ndarray):
        """å¼·ã„ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ (Â±45åº¦å›è»¢ãªã©)"""
        if self.augmentation is None:
            return image, mask

        # ç”»åƒã¨ãƒã‚¹ã‚¯ã‚’åŒæ™‚ã«å¤‰æ›
        # å›è»¢è§’åº¦ã¯ Â±45åº¦
        if np.random.rand() < 0.5:
            angle = np.random.uniform(
                -self.augmentation['rotation_degrees'],
                self.augmentation['rotation_degrees']
            )
            # ... (å›è»¢å‡¦ç†)

        # ... (ãã®ä»–ã®æ‹¡å¼µå‡¦ç†)
        return image, mask

    def get_labels(self) -> List[int]:
        """
        å…¨ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼ˆBalancedBatchSamplerç”¨ï¼‰

        Returns:
            ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆ [0, 1, 0, 1, ...]
        """
        return self.data['Fracture_Label'].tolist()
```

#### 2.2 `src/datamodule/sampler.py` - BalancedBatchSampler

**å½¹å‰²:**
- **ãƒãƒƒãƒå†…ã§ã‚¯ãƒ©ã‚¹å‡è¡¡ã‚’ä¿ã¤ã‚«ã‚¹ã‚¿ãƒ ã‚µãƒ³ãƒ—ãƒ©ãƒ¼**
- å„ãƒãƒƒãƒã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1 ã«ãªã‚‹ã‚ˆã†ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- ã‚¨ãƒãƒƒã‚¯å…¨ä½“ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’åŠ¹ç‡çš„ã«ç¶²ç¾…

**ä¸»è¦æ©Ÿèƒ½:**
- ãƒãƒƒãƒã‚µã‚¤ã‚º16ã®å ´åˆ: éª¨æŠ˜8æš + ééª¨æŠ˜8æš
- å„ã‚¨ãƒãƒƒã‚¯ã§éª¨æŠ˜ãƒ»ééª¨æŠ˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«
- ãƒãƒƒãƒã”ã¨ã«å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰å‡ç­‰ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

**å®Ÿè£…ä¾‹:**
```python
import torch
from torch.utils.data import Sampler
import numpy as np
from typing import Iterator, List

class BalancedBatchSampler(Sampler):
    """
    ãƒãƒƒãƒå†…ã§ã‚¯ãƒ©ã‚¹å‡è¡¡ã‚’ä¿ã¤ã‚µãƒ³ãƒ—ãƒ©ãƒ¼

    å„ãƒãƒƒãƒã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1 ã«ãªã‚‹ã‚ˆã†ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

    Args:
        labels: å…¨ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆ (0 or 1)
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆå¶æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰
        drop_last: æœ€å¾Œã®ä¸å®Œå…¨ãªãƒãƒƒãƒã‚’æ¨ã¦ã‚‹ã‹
    """

    def __init__(
        self,
        labels: List[int],
        batch_size: int,
        drop_last: bool = True
    ):
        if batch_size % 2 != 0:
            raise ValueError(f"batch_size must be even, got {batch_size}")

        self.labels = np.array(labels)
        self.batch_size = batch_size
        self.drop_last = drop_last

        # éª¨æŠ˜ãƒ»ééª¨æŠ˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ†é›¢
        self.positive_indices = np.where(self.labels == 1)[0].tolist()
        self.negative_indices = np.where(self.labels == 0)[0].tolist()

        self.n_positive = len(self.positive_indices)
        self.n_negative = len(self.negative_indices)

        # å„ãƒãƒƒãƒã§ã®ã‚¯ãƒ©ã‚¹ã”ã¨ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        self.samples_per_class = batch_size // 2

        # ã‚¨ãƒãƒƒã‚¯å†…ã®ãƒãƒƒãƒæ•°ã‚’è¨ˆç®—
        self.n_batches = self._calculate_n_batches()

        print(f"BalancedBatchSampler initialized:")
        print(f"  Positive samples: {self.n_positive}")
        print(f"  Negative samples: {self.n_negative}")
        print(f"  Batch size: {batch_size} ({self.samples_per_class} pos + {self.samples_per_class} neg)")
        print(f"  Batches per epoch: {self.n_batches}")

    def _calculate_n_batches(self) -> int:
        """ã‚¨ãƒãƒƒã‚¯å†…ã®ãƒãƒƒãƒæ•°ã‚’è¨ˆç®—"""
        # å„ã‚¯ãƒ©ã‚¹ã§åˆ©ç”¨å¯èƒ½ãªãƒãƒƒãƒæ•°
        n_batches_positive = self.n_positive // self.samples_per_class
        n_batches_negative = self.n_negative // self.samples_per_class

        # å°‘ãªã„æ–¹ã«åˆã‚ã›ã‚‹
        n_batches = min(n_batches_positive, n_batches_negative)

        return n_batches

    def __iter__(self) -> Iterator[List[int]]:
        """ãƒãƒƒãƒã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’è¿”ã™"""
        # å„ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        np.random.shuffle(self.positive_indices)
        np.random.shuffle(self.negative_indices)

        # ãƒãƒƒãƒã‚’ç”Ÿæˆ
        for batch_idx in range(self.n_batches):
            # å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—
            pos_start = batch_idx * self.samples_per_class
            pos_end = pos_start + self.samples_per_class

            neg_start = batch_idx * self.samples_per_class
            neg_end = neg_start + self.samples_per_class

            batch_positive = self.positive_indices[pos_start:pos_end]
            batch_negative = self.negative_indices[neg_start:neg_end]

            # ãƒãƒƒãƒã‚’çµåˆã—ã¦ã‚·ãƒ£ãƒƒãƒ•ãƒ«
            batch = batch_positive + batch_negative
            np.random.shuffle(batch)

            yield batch

    def __len__(self) -> int:
        """ã‚¨ãƒãƒƒã‚¯å†…ã®ãƒãƒƒãƒæ•°ã‚’è¿”ã™"""
        return self.n_batches
```

#### 2.3 `src/datamodule/dataloader.py`

**ä¸»è¦æ©Ÿèƒ½:**
- `create_dataloaders()` é–¢æ•°
- æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²ã‚’ã‚µãƒãƒ¼ãƒˆ (æ‚£è€…IDãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚‹)
- **å­¦ç¿’ç”¨: BalancedBatchSamplerä½¿ç”¨** (ãƒãƒƒãƒå†…ã‚¯ãƒ©ã‚¹å‡è¡¡)
- **æ¤œè¨¼ç”¨: é€šå¸¸ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**

**å®Ÿè£…ä¾‹:**
```python
from torch.utils.data import DataLoader
from .sampler import BalancedBatchSampler

def create_dataloaders(
    train_patient_ids: List[int],
    val_patient_ids: List[int],
    cfg: DictConfig
) -> Tuple[DataLoader, DataLoader]:
    """
    æ‚£è€…IDãƒªã‚¹ãƒˆã‹ã‚‰å­¦ç¿’/æ¤œè¨¼ç”¨DataLoaderã‚’ä½œæˆ
    """
    # å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
    all_train_csv_files = list(Path(cfg.image_base_dir).glob("inp*/fracture_labels_inp*.csv"))

    # æ‚£è€…IDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    train_csv_files = [
        str(f) for f in all_train_csv_files
        if int(f.parent.name[3:]) in train_patient_ids
    ]
    val_csv_files = [
        str(f) for f in all_train_csv_files
        if int(f.parent.name[3:]) in val_patient_ids
    ]

    # Datasetä½œæˆ
    train_dataset = MultiTaskDataset(
        csv_files=train_csv_files,
        image_base_dir=cfg.image_base_dir,
        mask_base_dir=cfg.mask_base_dir,
        hu_windows=cfg.hu_windows,
        image_size=cfg.image_size,
        augmentation=cfg.augmentation,
        is_training=True,
        # oversample_fracture ã¯å‰Šé™¤ (BalancedBatchSamplerã§å¯¾å¿œ)
    )

    val_dataset = MultiTaskDataset(
        csv_files=val_csv_files,
        image_base_dir=cfg.image_base_dir,
        mask_base_dir=cfg.mask_base_dir,
        hu_windows=cfg.hu_windows,
        image_size=cfg.image_size,
        is_training=False
    )

    # BalancedBatchSamplerä½œæˆï¼ˆå­¦ç¿’ç”¨ã®ã¿ï¼‰
    train_sampler = BalancedBatchSampler(
        labels=train_dataset.get_labels(),
        batch_size=cfg.training.batch_size,
        drop_last=True  # ä¸å®Œå…¨ãªãƒãƒƒãƒã‚’æ¨ã¦ã‚‹
    )

    # DataLoaderä½œæˆ
    train_loader = DataLoader(
        train_dataset,
        batch_sampler=train_sampler,  # batch_samplerã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€batch_size/shuffleã¯æŒ‡å®šã—ãªã„
        num_workers=cfg.training.num_workers,
        pin_memory=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.training.batch_size * 2,
        shuffle=False,
        num_workers=cfg.training.num_workers,
        pin_memory=True
    )

    return train_loader, val_loader
```

#### 2.4 `src/utils/common.py`

**ä¸»è¦æ©Ÿèƒ½:**
- `set_seed(seed)`: torch/numpy/randomã®ã‚·ãƒ¼ãƒ‰å›ºå®š
- `split_patients(patient_ids, n_folds, fold_id)`: æ‚£è€…ãƒ¬ãƒ™ãƒ«ã§ã®CVåˆ†å‰²

```python
import random
import numpy as np
import torch
from typing import List, Tuple

def set_seed(seed: int):
    """å†ç¾æ€§ã®ãŸã‚ã®ã‚·ãƒ¼ãƒ‰å›ºå®š"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def split_patients(
    patient_ids: List[int],
    n_folds: int,
    fold_id: int
) -> Tuple[List[int], List[int]]:
    """
    æ‚£è€…ãƒ¬ãƒ™ãƒ«ã§ã®K-foldåˆ†å‰²

    Args:
        patient_ids: å…¨æ‚£è€…IDãƒªã‚¹ãƒˆ
        n_folds: foldæ•°
        fold_id: ç¾åœ¨ã®fold (0-indexed)

    Returns:
        (train_patient_ids, val_patient_ids)
    """
    np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚å›ºå®š
    shuffled_ids = np.array(patient_ids)
    np.random.shuffle(shuffled_ids)

    fold_size = len(shuffled_ids) // n_folds
    val_start = fold_id * fold_size
    val_end = val_start + fold_size if fold_id < n_folds - 1 else len(shuffled_ids)

    val_ids = shuffled_ids[val_start:val_end].tolist()
    train_ids = np.concatenate([
        shuffled_ids[:val_start],
        shuffled_ids[val_end:]
    ]).tolist()

    return train_ids, val_ids
```

---

### **Phase 3: ãƒ¢ãƒ‡ãƒ«å®Ÿè£…**

#### 3.1 `src/model/attention_gate.py` - AttentionGate

**å½¹å‰²:**
- U-Netã®ã‚¹ã‚­ãƒƒãƒ—ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã«Attentionã‚’è¿½åŠ 
- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‹ã‚‰ã®ç‰¹å¾´ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ã‹ã‚‰ã®ç‰¹å¾´ã‚’ã‚²ãƒ¼ãƒˆå‡¦ç†
- å‚è€ƒ: [Attention U-Netè«–æ–‡](https://arxiv.org/abs/1804.03999)

**å®Ÿè£…ä¾‹:**
```python
import torch
import torch.nn as nn

class AttentionGate(nn.Module):
    """
    Attention Gate for U-Net skip connections

    Args:
        F_g: Number of feature maps in gating signal (decoder)
        F_l: Number of feature maps in skip connection (encoder)
        F_int: Number of intermediate feature maps
    """
    def __init__(self, F_g: int, F_l: int, F_int: int):
        super().__init__()

        self.W_g = nn.Sequential(
            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(F_int)
        )

        self.W_x = nn.Sequential(
            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(F_int)
        )

        self.psi = nn.Sequential(
            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )

        self.relu = nn.ReLU(inplace=True)

    def forward(self, g, x):
        """
        Args:
            g: gating signal from decoder (B, F_g, H, W)
            x: skip connection from encoder (B, F_l, H, W)

        Returns:
            Attention-weighted feature map (B, F_l, H, W)
        """
        g1 = self.W_g(g)
        x1 = self.W_x(x)

        psi = self.relu(g1 + x1)
        psi = self.psi(psi)

        return x * psi
```

#### 3.2 `src/model/multitask_unet.py` - MultiTaskUNet

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:**
```
Input (3, 256, 256)
    â†“
[Encoder] (ResNet18/EfficientNet-B0ã®pretrained backbone)
    â”œâ”€ conv1 â†’ encoder_features[0]
    â”œâ”€ conv2 â†’ encoder_features[1]
    â”œâ”€ conv3 â†’ encoder_features[2]
    â”œâ”€ conv4 â†’ encoder_features[3]
    â””â”€ conv5 (bottleneck) â†’ encoder_features[4]
         â†“
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
[Branch 1] [Branch 2]
åˆ†é¡ãƒ˜ãƒƒãƒ‰  ã‚»ã‚°ãƒ‡ã‚³ãƒ¼ãƒ€
    â”‚         â”‚
   GAP   Attention-UNet Decoder
    â†“    (AttentionGate at skip connections)
   FC         â†“
    â†“    1Ã—1 Conv
 Sigmoid   Sigmoid
    â†“         â†“
P_class   P_seg (1, 256, 256)
(scalar)
```

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:**
```python
import torch
import torch.nn as nn
import torchvision.models as models
from typing import Tuple
from .attention_gate import AttentionGate

class MultiTaskUNet(nn.Module):
    """
    Yå­—å‹ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯U-Net
    - å…±é€šEncoder (ResNet18/EfficientNet pretrained)
    - Branch 1: åˆ†é¡ãƒ˜ãƒƒãƒ‰ (GAP + FC)
    - Branch 2: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚³ãƒ¼ãƒ€ (Attention Gatesä»˜ã)
    """

    def __init__(self, cfg):
        super().__init__()

        # Encoder (ResNet18 pretrained)
        if cfg.encoder_name == 'resnet18':
            backbone = models.resnet18(pretrained=True)
            # æœ€åˆã®convå±¤ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«å…¥åŠ›ã«å¯¾å¿œ
            self.encoder_conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
            if cfg.encoder_weights == 'imagenet':
                # ImageNet pretrainedã®é‡ã¿ã‚’ã‚³ãƒ”ãƒ¼
                self.encoder_conv1.weight.data = backbone.conv1.weight.data

            self.encoder_bn1 = backbone.bn1
            self.encoder_relu = backbone.relu
            self.encoder_maxpool = backbone.maxpool

            self.encoder_layer1 = backbone.layer1  # 64 channels
            self.encoder_layer2 = backbone.layer2  # 128 channels
            self.encoder_layer3 = backbone.layer3  # 256 channels
            self.encoder_layer4 = backbone.layer4  # 512 channels (bottleneck)

        # Branch 1: åˆ†é¡ãƒ˜ãƒƒãƒ‰
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Dropout(cfg.classifier.dropout),
            nn.Linear(512, 1),
            nn.Sigmoid()
        )

        # Branch 2: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚³ãƒ¼ãƒ€ (Attention Gatesä»˜ã)
        self.decoder_channels = cfg.decoder_channels  # [256, 128, 64, 32, 16]

        # Attention Gates
        self.att4 = AttentionGate(F_g=self.decoder_channels[0], F_l=256, F_int=128)
        self.att3 = AttentionGate(F_g=self.decoder_channels[1], F_l=128, F_int=64)
        self.att2 = AttentionGate(F_g=self.decoder_channels[2], F_l=64, F_int=32)
        self.att1 = AttentionGate(F_g=self.decoder_channels[3], F_l=64, F_int=16)

        # Decoder blocks
        self.up4 = self._make_decoder_block(512, self.decoder_channels[0])
        self.up3 = self._make_decoder_block(self.decoder_channels[0] + 256, self.decoder_channels[1])
        self.up2 = self._make_decoder_block(self.decoder_channels[1] + 128, self.decoder_channels[2])
        self.up1 = self._make_decoder_block(self.decoder_channels[2] + 64, self.decoder_channels[3])
        self.up0 = self._make_decoder_block(self.decoder_channels[3] + 64, self.decoder_channels[4])

        # æœ€çµ‚ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‡ºåŠ›
        self.seg_head = nn.Sequential(
            nn.Conv2d(self.decoder_channels[4], 1, kernel_size=1),
            nn.Sigmoid()
        )

    def _make_decoder_block(self, in_channels: int, out_channels: int):
        """Decoderãƒ–ãƒ­ãƒƒã‚¯: Upsample + Conv"""
        return nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            x: Input image (B, 3, 256, 256)

        Returns:
            p_class: Classification probability (B,)
            p_seg: Segmentation probability map (B, 1, 256, 256)
        """
        # Encoder forward
        x0 = self.encoder_conv1(x)  # (B, 64, 128, 128)
        x0 = self.encoder_bn1(x0)
        x0 = self.encoder_relu(x0)

        x1 = self.encoder_maxpool(x0)  # (B, 64, 64, 64)
        x1 = self.encoder_layer1(x1)   # (B, 64, 64, 64)

        x2 = self.encoder_layer2(x1)   # (B, 128, 32, 32)
        x3 = self.encoder_layer3(x2)   # (B, 256, 16, 16)
        x4 = self.encoder_layer4(x3)   # (B, 512, 8, 8) - bottleneck

        # Branch 1: åˆ†é¡ãƒ˜ãƒƒãƒ‰
        p_class = self.classifier(x4).squeeze(1)  # (B,)

        # Branch 2: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚³ãƒ¼ãƒ€
        d4 = self.up4(x4)  # (B, 256, 16, 16)
        x3_att = self.att4(g=d4, x=x3)
        d4 = torch.cat([d4, x3_att], dim=1)

        d3 = self.up3(d4)  # (B, 128, 32, 32)
        x2_att = self.att3(g=d3, x=x2)
        d3 = torch.cat([d3, x2_att], dim=1)

        d2 = self.up2(d3)  # (B, 64, 64, 64)
        x1_att = self.att2(g=d2, x=x1)
        d2 = torch.cat([d2, x1_att], dim=1)

        d1 = self.up1(d2)  # (B, 32, 128, 128)
        x0_att = self.att1(g=d1, x=x0)
        d1 = torch.cat([d1, x0_att], dim=1)

        d0 = self.up0(d1)  # (B, 16, 256, 256)

        p_seg = self.seg_head(d0)  # (B, 1, 256, 256)

        return p_class, p_seg

    def freeze_encoder(self):
        """Encoderã®é‡ã¿ã‚’å‡çµ (ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨)"""
        for param in self.encoder_conv1.parameters():
            param.requires_grad = False
        for param in self.encoder_bn1.parameters():
            param.requires_grad = False
        for param in self.encoder_layer1.parameters():
            param.requires_grad = False
        for param in self.encoder_layer2.parameters():
            param.requires_grad = False
        for param in self.encoder_layer3.parameters():
            param.requires_grad = False
        for param in self.encoder_layer4.parameters():
            param.requires_grad = False

    def get_encoder_params(self):
        """Encoder ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾— (å·®åˆ†å­¦ç¿’ç‡ç”¨)"""
        encoder_params = []
        encoder_params.extend(self.encoder_conv1.parameters())
        encoder_params.extend(self.encoder_bn1.parameters())
        encoder_params.extend(self.encoder_layer1.parameters())
        encoder_params.extend(self.encoder_layer2.parameters())
        encoder_params.extend(self.encoder_layer3.parameters())
        encoder_params.extend(self.encoder_layer4.parameters())
        return encoder_params

    def get_decoder_params(self):
        """Decoder + Classifier ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—"""
        decoder_params = []
        decoder_params.extend(self.classifier.parameters())
        decoder_params.extend(self.att4.parameters())
        decoder_params.extend(self.att3.parameters())
        decoder_params.extend(self.att2.parameters())
        decoder_params.extend(self.att1.parameters())
        decoder_params.extend(self.up4.parameters())
        decoder_params.extend(self.up3.parameters())
        decoder_params.extend(self.up2.parameters())
        decoder_params.extend(self.up1.parameters())
        decoder_params.extend(self.up0.parameters())
        decoder_params.extend(self.seg_head.parameters())
        return decoder_params
```

---

### **Phase 4: æå¤±é–¢æ•°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£…**

#### 4.1 `src/modelmodule/multitask_loss.py` - MultiTaskLoss

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class FocalLoss(nn.Module):
    """
    Focal Loss for addressing class imbalance

    Args:
        alpha: Weighting factor (0-1) for positive class
        gamma: Focusing parameter (typically 2.0)
    """
    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        Args:
            pred: Predicted probabilities (B, 1, H, W) or (B, H, W)
            target: Ground truth binary mask (B, 1, H, W) or (B, H, W)
        """
        pred = pred.view(-1)
        target = target.view(-1)

        bce = F.binary_cross_entropy(pred, target, reduction='none')
        pt = torch.exp(-bce)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce

        return focal_loss.mean()


class DiceLoss(nn.Module):
    """Dice Loss for segmentation"""
    def __init__(self, smooth: float = 1.0):
        super().__init__()
        self.smooth = smooth

    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        Args:
            pred: Predicted probabilities (B, 1, H, W)
            target: Ground truth binary mask (B, 1, H, W)
        """
        pred = pred.view(-1)
        target = target.view(-1)

        intersection = (pred * target).sum()
        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)

        return 1 - dice


class MultiTaskLoss(nn.Module):
    """
    ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯æå¤±é–¢æ•°
    - åˆ†é¡æå¤± (BCELoss) Ã— w_class
    - ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æå¤± (FocalLoss/DiceLoss) Ã— w_seg

    Args:
        w_class: åˆ†é¡æå¤±ã®é‡ã¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0)
        w_seg: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æå¤±ã®é‡ã¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.1)
        seg_loss_type: ã‚»ã‚°æå¤±ã®ã‚¿ã‚¤ãƒ— ('focal', 'dice', 'focal_dice')
        focal_alpha: Focal Lossã®alphaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        focal_gamma: Focal Lossã®gammaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    """
    def __init__(
        self,
        w_class: float = 1.0,
        w_seg: float = 0.1,
        seg_loss_type: str = 'focal',
        focal_alpha: float = 0.25,
        focal_gamma: float = 2.0
    ):
        super().__init__()
        self.w_class = w_class
        self.w_seg = w_seg
        self.seg_loss_type = seg_loss_type

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æå¤±ã®é¸æŠ
        if seg_loss_type == 'focal':
            self.seg_criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        elif seg_loss_type == 'dice':
            self.seg_criterion = DiceLoss()
        elif seg_loss_type == 'focal_dice':
            self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
            self.dice_loss = DiceLoss()
        else:
            raise ValueError(f"Unknown seg_loss_type: {seg_loss_type}")

    def forward(
        self,
        pred_class: torch.Tensor,
        pred_seg: torch.Tensor,
        target_class: torch.Tensor,
        target_seg: torch.Tensor
    ) -> dict:
        """
        Args:
            pred_class: Classification predictions (B,)
            pred_seg: Segmentation predictions (B, 1, H, W)
            target_class: Classification labels (B,)
            target_seg: Segmentation masks (B, 1, H, W)

        Returns:
            Dict with 'total', 'class', 'seg' losses
        """
        # åˆ†é¡æå¤±
        loss_class = F.binary_cross_entropy(pred_class, target_class)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æå¤±
        if self.seg_loss_type == 'focal_dice':
            loss_focal = self.focal_loss(pred_seg, target_seg)
            loss_dice = self.dice_loss(pred_seg, target_seg)
            loss_seg = (loss_focal + loss_dice) / 2.0
        else:
            loss_seg = self.seg_criterion(pred_seg, target_seg)

        # ç·æå¤±
        total_loss = self.w_class * loss_class + self.w_seg * loss_seg

        return {
            'total': total_loss,
            'class': loss_class.item(),
            'seg': loss_seg.item()
        }
```

#### 4.2 `src/modelmodule/metrics.py`

```python
import torch
import numpy as np
from sklearn.metrics import precision_recall_curve, auc
from typing import Tuple

def dice_coefficient(pred: torch.Tensor, target: torch.Tensor, threshold: float = 0.5) -> float:
    """
    Diceä¿‚æ•°ã®è¨ˆç®—

    Args:
        pred: Predicted probabilities (B, 1, H, W)
        target: Ground truth binary mask (B, 1, H, W)
        threshold: Binarization threshold

    Returns:
        Dice coefficient (0-1)
    """
    pred_binary = (pred > threshold).float()
    target_binary = target.float()

    pred_flat = pred_binary.view(-1)
    target_flat = target_binary.view(-1)

    intersection = (pred_flat * target_flat).sum()
    dice = (2. * intersection) / (pred_flat.sum() + target_flat.sum() + 1e-8)

    return dice.item()


def iou_score(pred: torch.Tensor, target: torch.Tensor, threshold: float = 0.5) -> float:
    """
    IoU (Intersection over Union) ã®è¨ˆç®—

    Args:
        pred: Predicted probabilities (B, 1, H, W)
        target: Ground truth binary mask (B, 1, H, W)
        threshold: Binarization threshold

    Returns:
        IoU score (0-1)
    """
    pred_binary = (pred > threshold).float()
    target_binary = target.float()

    pred_flat = pred_binary.view(-1)
    target_flat = target_binary.view(-1)

    intersection = (pred_flat * target_flat).sum()
    union = pred_flat.sum() + target_flat.sum() - intersection

    iou = intersection / (union + 1e-8)

    return iou.item()


def compute_pr_auc(pred_probs: np.ndarray, targets: np.ndarray) -> float:
    """
    PR-AUC (Precision-Recall Area Under Curve) ã®è¨ˆç®—

    Args:
        pred_probs: Predicted probabilities (N,)
        targets: Ground truth labels (N,)

    Returns:
        PR-AUC score (0-1)
    """
    if len(np.unique(targets)) < 2:
        # Only one class present
        return 0.0

    precision, recall, _ = precision_recall_curve(targets, pred_probs)
    pr_auc = auc(recall, precision)

    return pr_auc


def compute_metrics_batch(
    pred_class: torch.Tensor,
    pred_seg: torch.Tensor,
    target_class: torch.Tensor,
    target_seg: torch.Tensor
) -> dict:
    """
    ãƒãƒƒãƒå…¨ä½“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—

    Args:
        pred_class: Classification predictions (B,)
        pred_seg: Segmentation predictions (B, 1, H, W)
        target_class: Classification labels (B,)
        target_seg: Segmentation masks (B, 1, H, W)

    Returns:
        Dict with all metrics
    """
    # åˆ†é¡ç²¾åº¦
    pred_class_binary = (pred_class > 0.5).float()
    class_acc = (pred_class_binary == target_class).float().mean().item()

    # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦
    dice = dice_coefficient(pred_seg, target_seg)
    iou = iou_score(pred_seg, target_seg)

    return {
        'class_acc': class_acc,
        'dice': dice,
        'iou': iou
    }
```

---

### **Phase 5: Hydraè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹ç¯‰**

#### 5.1 `run/conf/config.yaml` (ãƒ¡ã‚¤ãƒ³è¨­å®š)

```yaml
defaults:
  - constants
  - train
  - data: axial           # å®Ÿé¨“ã”ã¨ã«å¤‰æ›´: axial, coronal, sagittal
  - model: multitask_unet_resnet18
  - split: fold_0
  - _self_

experiment:
  # å®Ÿé¨“åã¯è‡ªå‹•ç”Ÿæˆ: {axis}/fold_{fold_id}
  # name ã¯ train.py ã§ data.axis ã¨ split.fold_id ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹
  description: "Multi-task U-Net with ${model.encoder_name} on ${data.axis} slices"
  # tags ã‚‚ train.py ã§è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹

seed: 42

# WandBè¨­å®š
wandb:
  project: "vertebrae_multitask"
  entity: null  # è‡ªåˆ†ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’è¨­å®š (nullã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¢ã‚«ã‚¦ãƒ³ãƒˆ)
  mode: "online"  # "online", "offline", "disabled"
  log_interval: 10  # ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—é–“éš”
  # group ã¨ name ã¯ train.py ã§è‡ªå‹•è¨­å®šã•ã‚Œã‚‹
```

#### 5.2 `run/conf/constants.yaml` (ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ãƒ»æ‚£è€…ID)

```yaml
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ (çµ¶å¯¾ãƒ‘ã‚¹)
project_root: "/mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka"

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
data_dir: "${project_root}/data"
slice_train_dir: "${data_dir}/slice_train"
slice_test_dir: "${data_dir}/slice_test"

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆæ–¹å‘åˆ¥ãƒ»foldåˆ¥ã«è‡ªå‹•åˆ†å‰²ï¼‰
output_base_dir: "${project_root}/A/output"
# å®Ÿéš›ã®å‡ºåŠ›å…ˆã¯è‡ªå‹•ç”Ÿæˆ: {output_base_dir}/{axis}/fold_{fold_id}/

# æ‚£è€…IDå®šç¾© (train/teståˆ†å‰²)
train_patient_ids: [
  1003, 1015, 1017, 1025, 1027, 1030, 1035, 1038, 1039, 1043,
  1045, 1046, 1047, 1049, 1052, 1055, 1059, 1060, 1061, 1062,
  1067, 1069, 1070, 1073, 1074, 1075, 1077, 1080, 1082, 1083
]

test_patient_ids: [1010, 1012, 1016, 1021, 1051, 1054, 1079, 1084]
```

#### 5.3 `run/conf/train.yaml` (å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)

```yaml
# å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
training:
  batch_size: 16
  num_workers: 4
  max_epochs: 100
  accumulation_steps: 1  # Gradient accumulation (GPUãƒ¡ãƒ¢ãƒªä¸è¶³æ™‚ã¯2ä»¥ä¸Šã«)

  # æ—©æœŸçµ‚äº†
  early_stopping:
    enabled: true
    patience: 15
    monitor: "val_loss"  # "val_loss" or "val_pr_auc"
    mode: "min"          # "min" for loss, "max" for pr_auc

  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
  checkpoint:
    save_top_k: 3
    monitor: "val_pr_auc"
    mode: "max"
    save_last: true

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
optimizer:
  name: "AdamW"
  lr: 0.001
  weight_decay: 0.0001

  # å·®åˆ†å­¦ç¿’ç‡ (Encoder vs Decoder)
  use_differential_lr: true
  encoder_lr_factor: 0.1  # encoder_lr = lr * 0.1

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
scheduler:
  name: "ReduceLROnPlateau"  # "ReduceLROnPlateau", "CosineAnnealingLR", "StepLR"
  mode: "min"
  factor: 0.5
  patience: 5
  min_lr: 0.00001

# æå¤±é–¢æ•°ã®é‡ã¿
loss:
  w_class: 1.0            # åˆ†é¡æå¤±ã®é‡ã¿ (ä¸»ã‚¿ã‚¹ã‚¯)
  w_seg: 0.1              # ã‚»ã‚°æå¤±ã®é‡ã¿ (è£œåŠ©ã‚¿ã‚¹ã‚¯)
  seg_loss_type: "focal"  # 'focal', 'dice', 'focal_dice'
  focal_alpha: 0.25
  focal_gamma: 2.0
```

#### 5.4 `run/conf/data/axial.yaml`

```yaml
# Axialæ–¹å‘ã®ãƒ‡ãƒ¼ã‚¿è¨­å®š
axis: "axial"

# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ (constants.yamlã®å¤‰æ•°ã‚’ä½¿ç”¨)
image_base_dir: "${slice_train_dir}/axial"
mask_base_dir: "${slice_train_dir}/axial_mask"

# ç”»åƒè¨­å®š
image_size: [256, 256]  # (H, W)

# HU Windowè¨­å®š (3ãƒãƒ£ãƒ³ãƒãƒ«)
hu_windows:
  channel_1:
    min: 0
    max: 1800
    description: "å…¨éª¨æ¡ä»¶"
  channel_2:
    min: -200
    max: 300
    description: "è»Ÿéƒ¨çµ„ç¹”"
  channel_3:
    min: 200
    max: 1200
    description: "éª¨æ¡ä»¶"

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®š
augmentation:
  rotation_degrees: 45      # Â±45åº¦ (å¤§ãã‚)
  translation_pixels: 20    # Â±20px
  scale_range: [0.8, 1.2]   # 0.8x ~ 1.2x
  horizontal_flip_prob: 0.5
  contrast_range: [0.9, 1.1]

# ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–
# BalancedBatchSamplerã§å¯¾å¿œï¼ˆãƒãƒƒãƒå†…ã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1ï¼‰
```

#### 5.5 `run/conf/data/coronal.yaml`

```yaml
# Coronalæ–¹å‘ã®ãƒ‡ãƒ¼ã‚¿è¨­å®š
axis: "coronal"

image_base_dir: "${slice_train_dir}/coronal"
mask_base_dir: "${slice_train_dir}/coronal_mask"

image_size: [256, 256]

hu_windows:
  channel_1:
    min: 0
    max: 1800
    description: "å…¨éª¨æ¡ä»¶"
  channel_2:
    min: -200
    max: 300
    description: "è»Ÿéƒ¨çµ„ç¹”"
  channel_3:
    min: 200
    max: 1200
    description: "éª¨æ¡ä»¶"

augmentation:
  rotation_degrees: 45
  translation_pixels: 20
  scale_range: [0.8, 1.2]
  horizontal_flip_prob: 0.5
  contrast_range: [0.9, 1.1]

# ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–
# BalancedBatchSamplerã§å¯¾å¿œï¼ˆãƒãƒƒãƒå†…ã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1ï¼‰
```

#### 5.6 `run/conf/data/sagittal.yaml`

```yaml
# Sagittalæ–¹å‘ã®ãƒ‡ãƒ¼ã‚¿è¨­å®š
axis: "sagittal"

image_base_dir: "${slice_train_dir}/sagittal"
mask_base_dir: "${slice_train_dir}/sagittal_mask"

image_size: [256, 256]

hu_windows:
  channel_1:
    min: 0
    max: 1800
    description: "å…¨éª¨æ¡ä»¶"
  channel_2:
    min: -200
    max: 300
    description: "è»Ÿéƒ¨çµ„ç¹”"
  channel_3:
    min: 200
    max: 1200
    description: "éª¨æ¡ä»¶"

augmentation:
  rotation_degrees: 45
  translation_pixels: 20
  scale_range: [0.8, 1.2]
  horizontal_flip_prob: 0.5
  contrast_range: [0.9, 1.1]

# ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–
# BalancedBatchSamplerã§å¯¾å¿œï¼ˆãƒãƒƒãƒå†…ã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1ï¼‰
```

#### 5.7 `run/conf/model/multitask_unet_resnet18.yaml`

```yaml
model:
  name: "MultiTaskUNet"

  # Encoderè¨­å®š
  encoder_name: "resnet18"
  encoder_weights: "imagenet"  # "imagenet" or null (random init)
  in_channels: 3

  # Decoderè¨­å®š
  decoder_channels: [256, 128, 64, 32, 16]
  decoder_attention_type: "scse"  # 'scse', 'cbam', null (no attention)

  # åˆ†é¡ãƒ˜ãƒƒãƒ‰è¨­å®š
  classifier:
    dropout: 0.2
    use_gap: true  # Global Average Pooling
```

#### 5.8 `run/conf/model/multitask_unet_efficientnet.yaml`

```yaml
model:
  name: "MultiTaskUNet"

  # Encoderè¨­å®š
  encoder_name: "efficientnet-b0"
  encoder_weights: "imagenet"
  in_channels: 3

  # Decoderè¨­å®š
  decoder_channels: [256, 128, 64, 32, 16]
  decoder_attention_type: "scse"

  # åˆ†é¡ãƒ˜ãƒƒãƒ‰è¨­å®š
  classifier:
    dropout: 0.3  # EfficientNetã¯éå­¦ç¿’ã—ã‚„ã™ã„ã®ã§å°‘ã—å¤§ãã‚
    use_gap: true
```

#### 5.9 `run/conf/split/fold_0.yaml`

```yaml
# K-fold CVè¨­å®š
n_folds: 5
fold_id: 0

# ã“ã®è¨­å®šã¯è‡ªå‹•çš„ã«æ‚£è€…ã‚’åˆ†å‰²ã—ã¾ã™
# train_patient_ids ã¯ constants.yaml ã‹ã‚‰èª­ã¿è¾¼ã¿
```

#### 5.10 `run/conf/split/fold_1.yaml`

```yaml
n_folds: 5
fold_id: 1
```

#### 5.11 `run/conf/split/fold_2.yaml`

```yaml
n_folds: 5
fold_id: 2
```

#### 5.12 `run/conf/split/fold_3.yaml`

```yaml
n_folds: 5
fold_id: 3
```

#### 5.13 `run/conf/split/fold_4.yaml`

```yaml
n_folds: 5
fold_id: 4
```

---

### **Phase 6: å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…**

#### 6.1 `run/scripts/train.py`

**å®Œå…¨ãªå­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (é•·ã„ã®ã§ä¸»è¦éƒ¨åˆ†ã®ã¿è¨˜è¼‰):

```python
#!/usr/bin/env python3
"""
Multi-Task U-Net Training Script
"""

import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(project_root))

import hydra
from omegaconf import DictConfig, OmegaConf
import wandb
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np

from src.model.multitask_unet import MultiTaskUNet
from src.modelmodule.multitask_loss import MultiTaskLoss
from src.modelmodule.metrics import compute_pr_auc, compute_metrics_batch
from src.datamodule.dataloader import create_dataloaders
from src.utils.common import set_seed, split_patients


@hydra.main(version_base=None, config_path="../conf", config_name="config")
def main(cfg: DictConfig):
    """ãƒ¡ã‚¤ãƒ³å­¦ç¿’é–¢æ•°"""

    # ========================================
    # 0. å®Ÿé¨“åã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è‡ªå‹•ç”Ÿæˆ
    # ========================================
    axis = cfg.data.axis  # "axial", "coronal", "sagittal"
    fold_id = cfg.split.fold_id  # 0, 1, 2, 3, 4
    model_name = cfg.model.encoder_name  # "resnet18", "efficientnet-b0"

    # å®Ÿé¨“å: axis/fold_X
    experiment_name = f"{axis}/fold_{fold_id}"

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: A/output/axis/fold_X/
    output_dir = Path(cfg.output_base_dir) / axis / f"fold_{fold_id}"
    output_dir.mkdir(parents=True, exist_ok=True)

    # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    checkpoint_dir = output_dir / "checkpoints"
    log_dir = output_dir / "logs"
    checkpoint_dir.mkdir(exist_ok=True)
    log_dir.mkdir(exist_ok=True)

    # è¨­å®šã‚’å‹•çš„ã«æ›´æ–°
    OmegaConf.set_struct(cfg, False)  # æ§‹é€ ã‚’ä¸€æ™‚çš„ã«è§£é™¤
    if 'experiment' not in cfg:
        cfg.experiment = {}
    cfg.experiment.name = experiment_name
    cfg.output_dir = str(output_dir)
    cfg.checkpoint_dir = str(checkpoint_dir)
    cfg.log_dir = str(log_dir)
    OmegaConf.set_struct(cfg, True)  # æ§‹é€ ã‚’å†åº¦æœ‰åŠ¹åŒ–

    # ========================================
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®š
    # ========================================
    from datetime import datetime
    import logging

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"train_{timestamp}.log"

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ã‚’è¿½åŠ ï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã¨ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã®ä¸¡æ–¹ï¼‰
    file_handler = logging.FileHandler(log_file)
    file_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)

    logger = logging.getLogger()
    logger.addHandler(file_handler)

    # ========================================
    # 1. åˆæœŸåŒ–
    # ========================================
    print("="*80)
    print("Multi-Task U-Net Training")
    print("="*80)
    print(f"Experiment: {experiment_name}")
    print(f"Axis: {axis}")
    print(f"Fold: {fold_id}")
    print(f"Model: {model_name}")
    print(f"Description: {cfg.experiment.description}")
    print(f"Output dir: {output_dir}")
    print(f"Checkpoint dir: {checkpoint_dir}")
    print(f"Log file: {log_file}")
    print("="*80)

    set_seed(cfg.seed)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")

    # ä½¿ç”¨ã—ãŸè¨­å®šã‚’ä¿å­˜
    config_save_path = output_dir / "config.yaml"
    with open(config_save_path, 'w') as f:
        OmegaConf.save(cfg, f)
    print(f"Config saved: {config_save_path}")

    # ========================================
    # 2. WandBåˆæœŸåŒ–ï¼ˆéšå±¤çš„ãªç®¡ç†ï¼‰
    # ========================================
    if cfg.wandb.mode != "disabled":
        wandb.init(
            project=cfg.wandb.project,
            entity=cfg.wandb.entity,
            name=experiment_name,  # "axial/fold_0"
            group=axis,  # åŒã˜æ–¹å‘ã®å®Ÿé¨“ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            tags=[
                axis,
                f"fold_{fold_id}",
                model_name,
                "multitask",
                "attention"
            ],
            config=OmegaConf.to_container(cfg, resolve=True),
            mode=cfg.wandb.mode
        )

        # WandBã«è¿½åŠ æƒ…å ±ã‚’ãƒ­ã‚°
        wandb.config.update({
            "experiment_name": experiment_name,
            "output_dir": str(output_dir),
            "axis": axis,
            "fold_id": fold_id
        })

    # 3. æ‚£è€…åˆ†å‰²
    train_ids, val_ids = split_patients(
        cfg.train_patient_ids,
        cfg.n_folds,
        cfg.fold_id
    )
    print(f"\nPatient Split (Fold {cfg.fold_id}/{cfg.n_folds}):")
    print(f"  Train patients: {len(train_ids)} - {train_ids[:5]}...")
    print(f"  Val patients: {len(val_ids)} - {val_ids}")

    # 4. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
    print("\nCreating DataLoaders...")
    train_loader, val_loader = create_dataloaders(
        train_patient_ids=train_ids,
        val_patient_ids=val_ids,
        cfg=cfg
    )
    print(f"  Train batches: {len(train_loader)}")
    print(f"  Val batches: {len(val_loader)}")

    # 5. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    print("\nCreating Model...")
    model = MultiTaskUNet(cfg.model).to(device)

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  Total parameters: {total_params:,}")
    print(f"  Trainable parameters: {trainable_params:,}")

    # 6. æå¤±é–¢æ•°
    criterion = MultiTaskLoss(
        w_class=cfg.loss.w_class,
        w_seg=cfg.loss.w_seg,
        seg_loss_type=cfg.loss.seg_loss_type,
        focal_alpha=cfg.loss.focal_alpha,
        focal_gamma=cfg.loss.focal_gamma
    )

    # 7. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
    if cfg.optimizer.use_differential_lr:
        optimizer = torch.optim.AdamW([
            {
                'params': model.get_encoder_params(),
                'lr': cfg.optimizer.lr * cfg.optimizer.encoder_lr_factor
            },
            {
                'params': model.get_decoder_params(),
                'lr': cfg.optimizer.lr
            }
        ], weight_decay=cfg.optimizer.weight_decay)
        print(f"\nOptimizer: AdamW with differential LR")
        print(f"  Encoder LR: {cfg.optimizer.lr * cfg.optimizer.encoder_lr_factor}")
        print(f"  Decoder LR: {cfg.optimizer.lr}")
    else:
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=cfg.optimizer.lr,
            weight_decay=cfg.optimizer.weight_decay
        )
        print(f"\nOptimizer: AdamW with LR={cfg.optimizer.lr}")

    # 8. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
    if cfg.scheduler.name == "ReduceLROnPlateau":
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode=cfg.scheduler.mode,
            factor=cfg.scheduler.factor,
            patience=cfg.scheduler.patience,
            min_lr=cfg.scheduler.min_lr
        )

    # 9. å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    best_val_metric = 0.0 if cfg.training.checkpoint.mode == "max" else float('inf')
    patience_counter = 0

    for epoch in range(cfg.training.max_epochs):
        print(f"\n{'='*80}")
        print(f"Epoch {epoch+1}/{cfg.training.max_epochs}")
        print(f"{'='*80}")

        # Training
        train_metrics = train_one_epoch(
            model=model,
            loader=train_loader,
            criterion=criterion,
            optimizer=optimizer,
            device=device,
            epoch=epoch,
            cfg=cfg
        )

        # Validation
        val_metrics = validate(
            model=model,
            loader=val_loader,
            criterion=criterion,
            device=device,
            epoch=epoch
        )

        # Scheduler step
        if cfg.scheduler.name == "ReduceLROnPlateau":
            scheduler.step(val_metrics['val_loss'])

        # ç¾åœ¨ã®å­¦ç¿’ç‡
        current_lr = optimizer.param_groups[0]['lr']

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        print(f"\nEpoch {epoch+1} Summary:")
        print(f"  Train Loss: {train_metrics['train_loss']:.4f} | Val Loss: {val_metrics['val_loss']:.4f}")
        print(f"  Train PR-AUC: {train_metrics['train_pr_auc']:.4f} | Val PR-AUC: {val_metrics['val_pr_auc']:.4f}")
        print(f"  Val Dice: {val_metrics['val_dice']:.4f} | Val IoU: {val_metrics['val_iou']:.4f}")
        print(f"  Learning Rate: {current_lr:.6f}")

        # WandB logging
        if cfg.wandb.mode != "disabled":
            wandb.log({
                **train_metrics,
                **val_metrics,
                'lr': current_lr,
                'epoch': epoch
            })

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
        monitor_metric = val_metrics[cfg.training.checkpoint.monitor]
        is_best = False

        if cfg.training.checkpoint.mode == "max":
            if monitor_metric > best_val_metric:
                best_val_metric = monitor_metric
                is_best = True
                patience_counter = 0
            else:
                patience_counter += 1
        else:  # mode == "min"
            if monitor_metric < best_val_metric:
                best_val_metric = monitor_metric
                is_best = True
                patience_counter = 0
            else:
                patience_counter += 1

        if is_best:
            save_checkpoint(
                model=model,
                optimizer=optimizer,
                epoch=epoch,
                metrics=val_metrics,
                cfg=cfg,
                filename='best_model.pth'
            )
            print(f"  âœ“ Best model saved! ({cfg.training.checkpoint.monitor}={monitor_metric:.4f})")

        # æœ€å¾Œã®ã‚¨ãƒãƒƒã‚¯ã‚’å¸¸ã«ä¿å­˜
        if cfg.training.checkpoint.save_last:
            save_checkpoint(
                model=model,
                optimizer=optimizer,
                epoch=epoch,
                metrics=val_metrics,
                cfg=cfg,
                filename='last_model.pth'
            )

        # Early stopping
        if cfg.training.early_stopping.enabled:
            if patience_counter >= cfg.training.early_stopping.patience:
                print(f"\nâš  Early stopping triggered after {epoch+1} epochs")
                print(f"  No improvement for {patience_counter} epochs")
                break

    # å­¦ç¿’å®Œäº†
    print(f"\n{'='*80}")
    print("Training completed!")
    print(f"Best {cfg.training.checkpoint.monitor}: {best_val_metric:.4f}")
    print(f"{'='*80}")

    if cfg.wandb.mode != "disabled":
        wandb.finish()


def train_one_epoch(
    model: nn.Module,
    loader: DataLoader,
    criterion: MultiTaskLoss,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
    epoch: int,
    cfg: DictConfig
) -> dict:
    """1ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’"""
    model.train()

    total_loss = 0.0
    total_loss_class = 0.0
    total_loss_seg = 0.0

    all_preds_class = []
    all_targets_class = []

    pbar = tqdm(loader, desc=f"Train", leave=False)

    for batch_idx, batch in enumerate(pbar):
        images = batch['image'].to(device)
        masks = batch['mask'].to(device)
        labels_class = batch['label_class'].to(device).float()

        # Forward
        pred_class, pred_seg = model(images)

        # Lossè¨ˆç®—
        losses = criterion(pred_class, pred_seg, labels_class, masks)
        loss = losses['total']

        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        total_loss += loss.item()
        total_loss_class += losses['class']
        total_loss_seg += losses['seg']

        all_preds_class.extend(pred_class.detach().cpu().numpy())
        all_targets_class.extend(labels_class.detach().cpu().numpy())

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°
        pbar.set_postfix({
            'loss': loss.item(),
            'loss_cls': losses['class'],
            'loss_seg': losses['seg']
        })

    # ã‚¨ãƒãƒƒã‚¯å…¨ä½“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    avg_loss = total_loss / len(loader)
    avg_loss_class = total_loss_class / len(loader)
    avg_loss_seg = total_loss_seg / len(loader)

    pr_auc = compute_pr_auc(
        np.array(all_preds_class),
        np.array(all_targets_class)
    )

    return {
        'train_loss': avg_loss,
        'train_loss_class': avg_loss_class,
        'train_loss_seg': avg_loss_seg,
        'train_pr_auc': pr_auc
    }


def validate(
    model: nn.Module,
    loader: DataLoader,
    criterion: MultiTaskLoss,
    device: torch.device,
    epoch: int
) -> dict:
    """æ¤œè¨¼"""
    model.eval()

    total_loss = 0.0
    total_loss_class = 0.0
    total_loss_seg = 0.0

    all_preds_class = []
    all_targets_class = []

    all_dice = []
    all_iou = []

    pbar = tqdm(loader, desc=f"Val", leave=False)

    with torch.no_grad():
        for batch in pbar:
            images = batch['image'].to(device)
            masks = batch['mask'].to(device)
            labels_class = batch['label_class'].to(device).float()

            # Forward
            pred_class, pred_seg = model(images)

            # Lossè¨ˆç®—
            losses = criterion(pred_class, pred_seg, labels_class, masks)
            loss = losses['total']

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
            total_loss += loss.item()
            total_loss_class += losses['class']
            total_loss_seg += losses['seg']

            all_preds_class.extend(pred_class.cpu().numpy())
            all_targets_class.extend(labels_class.cpu().numpy())

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            batch_metrics = compute_metrics_batch(pred_class, pred_seg, labels_class, masks)
            all_dice.append(batch_metrics['dice'])
            all_iou.append(batch_metrics['iou'])

            pbar.set_postfix({'loss': loss.item()})

    # ã‚¨ãƒãƒƒã‚¯å…¨ä½“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    avg_loss = total_loss / len(loader)
    avg_loss_class = total_loss_class / len(loader)
    avg_loss_seg = total_loss_seg / len(loader)

    pr_auc = compute_pr_auc(
        np.array(all_preds_class),
        np.array(all_targets_class)
    )

    avg_dice = np.mean(all_dice)
    avg_iou = np.mean(all_iou)

    return {
        'val_loss': avg_loss,
        'val_loss_class': avg_loss_class,
        'val_loss_seg': avg_loss_seg,
        'val_pr_auc': pr_auc,
        'val_dice': avg_dice,
        'val_iou': avg_iou
    }


def save_checkpoint(
    model: nn.Module,
    optimizer: torch.optim.Optimizer,
    epoch: int,
    metrics: dict,
    cfg: DictConfig,
    filename: str
):
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
    # cfg.checkpoint_dir ã¯ main() ã§è¨­å®šæ¸ˆã¿
    checkpoint_dir = Path(cfg.checkpoint_dir)

    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': metrics,
        'config': OmegaConf.to_container(cfg, resolve=True),
        # ãƒ¡ã‚¿æƒ…å ±ã‚’è¿½åŠ 
        'axis': cfg.data.axis,
        'fold_id': cfg.split.fold_id,
        'model_name': cfg.model.encoder_name
    }

    checkpoint_path = checkpoint_dir / filename
    torch.save(checkpoint, checkpoint_path)

    print(f"  Checkpoint saved: {checkpoint_path}")


if __name__ == "__main__":
    main()
```

---

### **Phase 7: å®Ÿè¡Œæº–å‚™**

#### 7.1 `.gitignore`

```
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
.venv/
virtual_env/
ENV/

# Hydra
outputs/
multirun/
.hydra/

# WandB
wandb/

# å‡ºåŠ›
output/
*.pth
*.pt

# Jupyter
.ipynb_checkpoints/
*.ipynb

# IDE
.vscode/
.idea/
*.swp
*.swo
```

#### 7.2 ç’°å¢ƒæ§‹ç¯‰

```bash
cd /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/A/

# uvç’°å¢ƒåˆæœŸåŒ–
uv init
uv sync

# ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–
source .venv/bin/activate
```

#### 7.3 å­¦ç¿’å®Ÿè¡Œ

**å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ä¾‹**ï¼ˆæ–¹å‘åˆ¥ãƒ»foldåˆ¥ã«è‡ªå‹•ç®¡ç†ï¼‰ï¼š

```bash
cd run/scripts

# Axialæ–¹å‘ã€Fold 0 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
uv run python train.py
# -> å‡ºåŠ›å…ˆ: A/output/axial/fold_0/
# -> WandB runå: axial/fold_0

# Axialæ–¹å‘ã€å…¨Foldå®Ÿè¡Œ
uv run python train.py split.fold_id=0  # A/output/axial/fold_0/
uv run python train.py split.fold_id=1  # A/output/axial/fold_1/
uv run python train.py split.fold_id=2  # A/output/axial/fold_2/
uv run python train.py split.fold_id=3  # A/output/axial/fold_3/
uv run python train.py split.fold_id=4  # A/output/axial/fold_4/

# Coronalæ–¹å‘ã€Fold 0
uv run python train.py data=coronal split.fold_id=0
# -> å‡ºåŠ›å…ˆ: A/output/coronal/fold_0/
# -> WandB runå: coronal/fold_0

# Sagittalæ–¹å‘ã€Fold 1
uv run python train.py data=sagittal split.fold_id=1
# -> å‡ºåŠ›å…ˆ: A/output/sagittal/fold_1/
# -> WandB runå: sagittal/fold_1

# EfficientNetã§å®Ÿè¡Œ
uv run python train.py model=multitask_unet_efficientnet
# -> A/output/axial/fold_0/ (ãƒ¢ãƒ‡ãƒ«åã¯è‡ªå‹•åæ˜ )

# 3æ–¹å‘Ã—5fold = 15å®Ÿé¨“ã‚’é †æ¬¡å®Ÿè¡Œ
for axis in axial coronal sagittal; do
  for fold in 0 1 2 3 4; do
    uv run python train.py data=$axis split.fold_id=$fold
  done
done

# WandBã‚’ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ (ãƒ‡ãƒãƒƒã‚°ç”¨)
uv run python train.py wandb.mode=offline

# å­¦ç¿’ç‡ã‚’å¤‰æ›´ã—ã¦å®Ÿè¡Œ
uv run python train.py optimizer.lr=0.0005
```

**ç”Ÿæˆã•ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ **ï¼š
```
A/output/
â”œâ”€â”€ axial/
â”‚   â”œâ”€â”€ fold_0/
â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”‚   â””â”€â”€ last_model.pth
â”‚   â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”‚   â””â”€â”€ train_20250112_143000.log
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ fold_1/
â”‚   â”œâ”€â”€ fold_2/
â”‚   â”œâ”€â”€ fold_3/
â”‚   â””â”€â”€ fold_4/
â”œâ”€â”€ coronal/
â”‚   â”œâ”€â”€ fold_0/
â”‚   â”œâ”€â”€ fold_1/
â”‚   â”œâ”€â”€ fold_2/
â”‚   â”œâ”€â”€ fold_3/
â”‚   â””â”€â”€ fold_4/
â””â”€â”€ sagittal/
    â”œâ”€â”€ fold_0/
    â”œâ”€â”€ fold_1/
    â”œâ”€â”€ fold_2/
    â”œâ”€â”€ fold_3/
    â””â”€â”€ fold_4/
```

---

## ğŸ“Š å®Ÿè£…å„ªå…ˆé †ä½ã¨ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

### **Week 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç›¤ + ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**

**Day 1-2: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ**
- [ ] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
- [ ] `__init__.py` é…ç½®
- [ ] `pyproject.toml` ä½œæˆ
- [ ] `.gitignore` ä½œæˆ

**Day 3-5: ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…**
- [ ] `src/utils/common.py` å®Ÿè£…
- [ ] `src/datamodule/dataset.py` å®Ÿè£… (ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µ + get_labels()ãƒ¡ã‚½ãƒƒãƒ‰)
- [ ] `src/datamodule/sampler.py` å®Ÿè£… (BalancedBatchSampler)
- [ ] `src/datamodule/dataloader.py` å®Ÿè£… (BalancedBatchSamplerä½¿ç”¨)
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å‹•ä½œç¢ºèª (ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼)
- [ ] ãƒãƒƒãƒå†…ã‚¯ãƒ©ã‚¹æ¯”ãŒ1:1ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª

### **Week 2: ãƒ¢ãƒ‡ãƒ« + æå¤±é–¢æ•°å®Ÿè£…**

**Day 1-3: ãƒ¢ãƒ‡ãƒ«å®Ÿè£…**
- [ ] `src/model/attention_gate.py` å®Ÿè£…
- [ ] `src/model/multitask_unet.py` å®Ÿè£…
- [ ] ãƒ¢ãƒ‡ãƒ«ã®forward passæ¤œè¨¼ (ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ç¢ºèª)

**Day 4-5: æå¤±é–¢æ•°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£…**
- [ ] `src/modelmodule/multitask_loss.py` å®Ÿè£…
- [ ] `src/modelmodule/metrics.py` å®Ÿè£…
- [ ] æå¤±é–¢æ•°ã®å‹•ä½œç¢ºèª

### **Week 3: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« + å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**

**Day 1-2: Hydraè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**
- [ ] å…¨YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
- [ ] Hydraã®å‹•ä½œç¢ºèª (è¨­å®šèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ)

**Day 3-5: å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…**
- [ ] `run/scripts/train.py` å®Ÿè£…
- [ ] å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®å‹•ä½œç¢ºèª (å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ)

### **Week 4: ãƒ‡ãƒãƒƒã‚°ãƒ»å­¦ç¿’å®Ÿè¡Œ**

**Day 1-2: ãƒ‡ãƒãƒƒã‚°**
- [ ] ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§ã®å‹•ä½œç¢ºèª
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
- [ ] WandBé€£æºç¢ºèª

**Day 3-5: å­¦ç¿’å®Ÿè¡Œ**
- [ ] Axialæ–¹å‘ã§å­¦ç¿’é–‹å§‹
- [ ] å­¦ç¿’æ›²ç·šã®ç¢ºèª
- [ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´

---

## âœ… å®Ÿè£…ç¢ºèªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### **ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**
- [ ] Dataset: 256Ã—256ãƒªã‚µã‚¤ã‚ºç¢ºèª
- [ ] Dataset: 3ãƒãƒ£ãƒ³ãƒãƒ«HU Windowå¤‰æ›ç¢ºèª
- [ ] Dataset: CTç”»åƒã¨ãƒã‚¹ã‚¯ã®ãƒ‘ã‚¹å¯¾å¿œç¢ºèª
- [ ] Dataset: `get_labels()` ãƒ¡ã‚½ãƒƒãƒ‰ãŒæ­£ã—ããƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã‚’è¿”ã™
- [ ] Dataset: Â±45åº¦å›è»¢æ‹¡å¼µç¢ºèªï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µï¼‰
- [ ] Sampler: BalancedBatchSamplerãŒæ­£ã—ãåˆæœŸåŒ–ã•ã‚Œã‚‹
- [ ] Sampler: å„ãƒãƒƒãƒã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] DataLoader: BalancedBatchSamplerã‚’ä½¿ç”¨ã—ã¦ãƒãƒƒãƒãŒç”Ÿæˆã•ã‚Œã‚‹
- [ ] DataLoader: æ‚£è€…ãƒ¬ãƒ™ãƒ«åˆ†å‰²ã§ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãªã—

### **ãƒ¢ãƒ‡ãƒ«**
- [ ] Model: forward()ã§ (p_class, p_seg) ãŒè¿”ã‚‹
- [ ] Model: p_class ã® shape ãŒ (B,) ã«ãªã‚‹
- [ ] Model: p_seg ã® shape ãŒ (B, 1, 256, 256) ã«ãªã‚‹
- [ ] Model: Attention GateãŒæ­£ã—ãå‹•ä½œã™ã‚‹
- [ ] Model: Encoder/Decoderã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰å‹•ä½œç¢ºèª

### **æå¤±é–¢æ•°**
- [ ] Loss: w_class=1.0, w_seg=0.1 ã®é‡ã¿ä»˜ã‘ç¢ºèª
- [ ] Loss: Focal Loss ã®å‹•ä½œç¢ºèª
- [ ] Loss: ç·æå¤±ãŒé©åˆ‡ã«è¨ˆç®—ã•ã‚Œã‚‹

### **å­¦ç¿’**
- [ ] Training: WandBã«loss/PR-AUCãŒãƒ­ã‚°ã•ã‚Œã‚‹
- [ ] Training: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã‚‹
- [ ] Training: Early stoppingãŒå‹•ä½œã™ã‚‹
- [ ] Training: å·®åˆ†å­¦ç¿’ç‡ãŒé©ç”¨ã•ã‚Œã‚‹
- [ ] Training: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ»OOMãŒç™ºç”Ÿã—ãªã„

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ— (Phase 8ä»¥é™)

### **Phase 8: è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
- `run/scripts/eval.py` å®Ÿè£…
- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ¨è«–
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç®—å‡º

### **Phase 9: 3Dçµ±åˆå®Ÿè£…**
- ã‚¹ãƒ†ãƒƒãƒ—1: P_final = P_class Ã— P_seg
- ã‚¹ãƒ†ãƒƒãƒ—2: P_voxel = P_ax Ã— P_co Ã— P_sa
- 3Då¯è¦–åŒ–

### **Phase 10: å®Ÿé¨“ãƒ»è«–æ–‡åŸ·ç­†**
- 3æ–¹å‘ã§ã®å®Ÿé¨“å®Ÿæ–½
- ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ãƒ‡ã‚£
- çµæœã®å¯è¦–åŒ–
- è«–æ–‡åŸ·ç­†

---

## ğŸ“š å‚è€ƒè³‡æ–™

### **è«–æ–‡**
- Attention U-Net: https://arxiv.org/abs/1804.03999
- Focal Loss: https://arxiv.org/abs/1708.02002
- Multi-Task Learning: https://arxiv.org/abs/1706.05098

### **å®Ÿè£…å‚è€ƒ**
- segmentation_models_pytorch: https://github.com/qubvel/segmentation_models.pytorch
- Hydra: https://hydra.cc/docs/intro/

---

## ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ³•æ”¹å–„ã®æ¦‚è¦

### **æ”¹å–„å‰: ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ–¹å¼**
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã§éª¨æŠ˜ã‚¹ãƒ©ã‚¤ã‚¹ã‚’3å€ã«è¤‡è£½
- ã‚¨ãƒãƒƒã‚¯å…¨ä½“ã§ã¯å‡è¡¡ã ãŒã€**ãƒãƒƒãƒå†…ã§ã¯ä¸å‡è¡¡**
- ã‚ã‚‹ãƒãƒƒãƒã¯å…¨ã¦ééª¨æŠ˜ã€åˆ¥ã®ãƒãƒƒãƒã¯éª¨æŠ˜ãŒå¤šã„ã¨ã„ã†åã‚Š

### **æ”¹å–„å¾Œ: ãƒãƒƒãƒå†…ã‚¯ãƒ©ã‚¹å‡è¡¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° + ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µ**
- **BalancedBatchSampler** ã§å„ãƒãƒƒãƒå†…ã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1
- **ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µ** ã§æ¯ã‚¨ãƒãƒƒã‚¯ç•°ãªã‚‹æ‹¡å¼µãƒ‘ã‚¿ãƒ¼ãƒ³
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¤‡è£½ã—ãªã„ï¼‰
- å­¦ç¿’ã®å®‰å®šæ€§å‘ä¸Šï¼ˆãƒãƒƒãƒé–“ã®æå¤±ã®ã°ã‚‰ã¤ããŒæ¸›å°‘ï¼‰

### **åˆ©ç‚¹ã¾ã¨ã‚**
âœ… ãƒãƒƒãƒå†…ã‚¯ãƒ©ã‚¹å‡è¡¡: å„ãƒãƒƒãƒã§éª¨æŠ˜:ééª¨æŠ˜ = 1:1
âœ… ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µ: æ¯ã‚¨ãƒãƒƒã‚¯ç•°ãªã‚‹æ‹¡å¼µãƒ‘ã‚¿ãƒ¼ãƒ³
âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¤‡è£½ã—ãªã„
âœ… å­¦ç¿’ã®å®‰å®šæ€§: ãƒãƒƒãƒã”ã¨ã®æå¤±ã®ã°ã‚‰ã¤ããŒæ¸›å°‘
âœ… æ±åŒ–æ€§èƒ½: å¼·ã„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‹¡å¼µã«ã‚ˆã‚Šéå­¦ç¿’ã‚’æŠ‘åˆ¶

---

## ğŸ“ æ–¹å‘åˆ¥ãƒ»Foldåˆ¥çµæœç®¡ç†ã®æ”¹å–„æ¦‚è¦

### **æ”¹å–„ã®ãƒã‚¤ãƒ³ãƒˆ**

#### **1. éšå±¤çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ **
```
A/output/
â”œâ”€â”€ axial/fold_0/, axial/fold_1/, axial/fold_2/, axial/fold_3/, axial/fold_4/
â”œâ”€â”€ coronal/fold_0/, coronal/fold_1/, coronal/fold_2/, coronal/fold_3/, coronal/fold_4/
â””â”€â”€ sagittal/fold_0/, sagittal/fold_1/, sagittal/fold_2/, sagittal/fold_3/, sagittal/fold_4/
```

å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…:
- `checkpoints/`: ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿
- `logs/`: å­¦ç¿’ãƒ­ã‚°ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
- `config.yaml`: ä½¿ç”¨ã—ãŸè¨­å®š

#### **2. å®Ÿé¨“åã®è‡ªå‹•ç”Ÿæˆ**
- ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: `{axis}/fold_{fold_id}`
- ä¾‹: `axial/fold_0`, `coronal/fold_1`, `sagittal/fold_2`
- `data.axis` ã¨ `split.fold_id` ã‹ã‚‰è‡ªå‹•ç”Ÿæˆ

#### **3. WandBã®éšå±¤çš„ç®¡ç†**
- **Runå**: `{axis}/fold_{fold_id}`
- **Group**: `{axis}` (åŒã˜æ–¹å‘ã®å®Ÿé¨“ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–)
- **Tags**: `[axis, fold_id, model_name, ...]`

#### **4. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ¡ã‚¿æƒ…å ±**
```python
checkpoint = {
    'epoch': epoch,
    'model_state_dict': ...,
    'metrics': ...,
    # ãƒ¡ã‚¿æƒ…å ±
    'axis': 'axial',
    'fold_id': 0,
    'model_name': 'resnet18'
}
```

#### **5. è¨­å®šã®è‡ªå‹•ä¿å­˜**
- å„å®Ÿé¨“ã® `config.yaml` ã‚’è‡ªå‹•ä¿å­˜
- å†ç¾æ€§ã®ç¢ºä¿

### **åˆ©ç‚¹ã¾ã¨ã‚**

âœ… **è‡ªå‹•åŒ–**: å®Ÿé¨“åãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’è‡ªå‹•ç”Ÿæˆï¼ˆæ‰‹å‹•è¨­å®šä¸è¦ï¼‰
âœ… **éšå±¤çš„ç®¡ç†**: æ–¹å‘åˆ¥ãƒ»foldåˆ¥ã«æ˜ç¢ºã«åˆ†é›¢
âœ… **æ¤œç´¢æ€§**: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã§ç›´æ„Ÿçš„ã«æ¤œç´¢å¯èƒ½
âœ… **WandBçµ±åˆ**: ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ã‚¿ã‚°ã§éšå±¤çš„ã«ç®¡ç†
âœ… **å†ç¾æ€§**: ä½¿ç”¨ã—ãŸè¨­å®šã‚’config.yamlã¨ã—ã¦ä¿å­˜
âœ… **ãƒ­ã‚°ç®¡ç†**: å„å®Ÿé¨“ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã«ä¿å­˜ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰

### **çµæœã®ç¢ºèªæ–¹æ³•**

#### **ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã§ç¢ºèª**
```bash
# Axialæ–¹å‘ã®å…¨foldã‚’ç¢ºèª
ls A/output/axial/
# -> fold_0  fold_1  fold_2  fold_3  fold_4

# ç‰¹å®šfoldã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèª
ls A/output/axial/fold_0/checkpoints/
# -> best_model.pth  last_model.pth

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
cat A/output/axial/fold_0/logs/train_*.log
```

#### **WandBã§ç¢ºèª**
1. **Group by Axis**: å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ "Group" â†’ `group` ã‚’é¸æŠ
2. **Filter by Tags**: `axial`, `fold_0` ãªã©ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
3. **æ¯”è¼ƒ**: åŒã˜æ–¹å‘ã®ç•°ãªã‚‹foldã‚’ä¸¦ã¹ã¦æ¯”è¼ƒ

---

ã“ã‚Œã§**A/ãƒ•ã‚©ãƒ«ãƒ€ã§å®Œå…¨ãªå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä¸€ã‹ã‚‰æ§‹ç¯‰**ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸ!