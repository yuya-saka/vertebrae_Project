# セグメンテーションで精度が出ず、YOLOの方がマシな理由の考察

**作成日**: 2025/10/15
**目的**: Attention U-NetによるセグメンテーションとYOLOによる物体検出の性能差の原因を分析し、改善策を提案する

---

## 1. 現状の把握

### 1.1 セグメンテーション（Attention U-Net）の現状
- **PRAUC**: 0.06前後（Epoch 8-14）
  - ほぼランダム予測に近い（理想値は1.0）
  - 改善が見られない
- **最適閾値**: 0.010（探索範囲の下限値）
  - より低い閾値が最適な可能性
- **損失関数**: Focal Tversky Loss + Focal Loss
  - alpha=0.3, beta=0.7（False Negative重視）
  - gamma=0.75（困難例に注目）
- **モデルアーキテクチャ**: Attention U-Net
  - Depth=4, init_features=64
  - Attention Gate付きスキップ接続
- **データ特性**:
  - 骨折スライス: 10.83% (Train), 9.39% (Test)
  - 骨折ピクセル比率: 平均0.616%
  - オーバーサンプリング: 9倍（骨折スライス50%目標）

### 1.2 YOLO（物体検出）の現状
- **最終評価指標** (training_summary.yaml):
  - mAP50: 0.00（期待値より極端に低い）
  - mAP50-95: 0.00
  - Precision: 0.00
  - Recall: 0.00
- **学習設定**:
  - モデル: YOLOv8m
  - Batch size: 16
  - Epochs: 100
  - Augmentation: Mosaic (0.8), Mixup (0.1), Copy-paste (0.1)
  - Optimizer: Auto (SGD with momentum 0.937)

**⚠️ 重要**: YOLOの最終評価指標も0.00であり、実際には良好な性能ではないことが判明。ユーザーの「YOLOの方がマシ」という認識は、学習中の中間的な挙動や可視化結果に基づいている可能性がある。

---

## 2. セグメンテーションで精度が出ない原因の仮説

### 2.1 タスク定義の根本的なミスマッチ

#### 仮説A: セグメンテーションは椎骨骨折に対して過度に詳細すぎる
- **問題点**:
  - セグメンテーションはピクセル単位の正確なマスク予測を要求
  - 医療画像の骨折アノテーションは、アノテーター間でも境界の曖昧さがある
  - 骨折領域が極小（0.6%）で、1-2ピクセルのズレでも大きく評価が下がる
- **YOLOが有利な理由**:
  - バウンディングボックスは位置の曖昧さに寛容
  - IoU 0.5でもTP判定されるため、多少のズレが許容される

#### 仮説B: ピクセルレベルのノイズに対する脆弱性
- **問題点**:
  - 骨折領域の境界が不明瞭（グレーゾーン）
  - CT画像のノイズやアーチファクトがピクセルレベルで影響
  - モデルが「どこまでを骨折とすべきか」の判断に迷う
- **YOLOが有利な理由**:
  - バウンディングボックスはノイズを含む領域全体をカバー
  - 細かいピクセルレベルの判断を回避

### 2.2 データとアノテーションの問題

#### 仮説C: マスクアノテーションの品質問題
- **問題点**:
  - マスクの境界が実際の骨折領域と乖離している可能性
  - 2Dスライス単位のマスクでは、3D的な連続性が考慮されていない
  - アノテーションのばらつきが大きい
- **検証方法**:
  - マスクとCT画像のオーバーレイを複数サンプルで目視確認
  - アノテーターが異なる場合、同一症例の再アノテーション一致率を確認

#### 仮説D: データローダーのバグ（マスクと画像の不一致）
- **問題点**:
  - マスクと画像の対応が間違っている
  - HU値ウィンドウ処理で情報が失われている
  - データ拡張により、マスクと画像の位置関係がズレている
- **検証方法** ✅:
  - バッチを1つ取得し、画像とマスクを可視化
  - 骨折領域がマスクと一致しているか確認（実施済み: 2025/10/15）
  - **結果**: データローダー修正済み（project_progress.md参照）

### 2.3 モデルアーキテクチャの問題

#### 仮説E: Attention機構が小さな骨折領域に対して機能していない
- **問題点**:
  - 骨折領域が0.6%と極小すぎて、Attentionが収束しない
  - Attention Gateが「どこに注目すべきか」を学習できていない
  - 最終的に全体にぼやけたAttentionマップになっている
- **検証方法**:
  - Attention Gateの出力を可視化
  - どの領域にAttentionがかかっているか確認
- **YOLOが有利な理由**:
  - YOLOはアンカーベース（またはアンカーフリー）で、特定のグリッドセルに対して骨折の有無を判定
  - 小さな物体検出に特化した設計

#### 仮説F: 受容野の不足
- **問題点**:
  - Depth=4の場合、最小受容野は約64ピクセル
  - 骨折領域が数ピクセル程度の場合、十分にコンテキストを捉えられない
  - または逆に、受容野が広すぎて細部が失われる
- **検証方法**:
  - 骨折領域のサイズ分布を確認（ピクセル数のヒストグラム）
  - 異なるDepthでの性能比較

### 2.4 損失関数の問題

#### 仮説G: Focal Tversky Lossのパラメータが不適切
- **問題点**:
  - alpha=0.3, beta=0.7の設定が、このタスクに合っていない
  - gamma=0.75では困難例への注目が不十分
  - 損失値が小さすぎる／大きすぎる → 勾配消失／爆発
- **検証方法**:
  - 学習初期のバッチで損失値を手動計算
  - 損失値の推移を確認（W&Bログ）
  - 異なるパラメータ（alpha, beta, gamma）で実験

#### 仮説H: クラス不均衡への対処が不十分
- **問題点**:
  - オーバーサンプリング9倍でも、ピクセルレベルでは依然として99.4%が非骨折
  - 損失関数が非骨折ピクセルに支配されている
- **検証方法**:
  - ピクセル単位のクラス重み付けを追加
  - Weighted Focal Loss（骨折ピクセルの重みを大きく）

### 2.5 学習プロセスの問題

#### 仮説I: 学習率が不適切
- **問題点**:
  - 学習率1e-4が高すぎる／低すぎる
  - 学習初期で勾配が爆発／消失している
- **検証方法**:
  - 学習率を変えて実験（1e-3, 1e-4, 1e-5）
  - Learning Rate Finderで最適学習率を探索

#### 仮説J: データ拡張が強すぎる
- **問題点**:
  - 回転±15度、スケール0.95-1.05で、骨折領域が画像外に出る
  - 拡張により、モデルが本質的な特徴を学習できない
- **検証方法**:
  - データ拡張なしで学習
  - 拡張後のサンプルを複数可視化

---

## 3. YOLOが比較的マシな理由（推測）

**注**: YOLOの最終評価指標も0.00であるため、実際には学習に失敗している可能性が高い。以下はあくまで「なぜ物体検出がセグメンテーションより有利か」の一般的な議論。

### 3.1 タスクの抽象度
- YOLOは「骨折がある領域を大まかに囲む」タスク
- セグメンテーションは「骨折のピクセルを正確に塗り分ける」タスク
- → 前者の方が学習が容易

### 3.2 評価指標の寛容さ
- YOLOのIoU閾値0.5は、多少のズレを許容
- セグメンテーションのDice係数は、1ピクセルのズレも厳密に評価
- → 見かけ上、YOLOの方が高スコアになりやすい

### 3.3 小物体検出への最適化
- YOLOv8は小物体検出のための工夫（FPN, PANなど）が組み込まれている
- セグメンテーションのU-Netはダウンサンプリング・アップサンプリングで小物体の情報が失われやすい

### 3.4 アンカー機構
- YOLOは事前定義されたアンカーボックス（または学習されたアンカー）を基準に予測
- セグメンテーションは全ピクセルを均等に扱う
- → YOLOは小さな骨折領域に特化したアンカーが機能する可能性

---

## 4. 推奨される検証ステップ（優先度順）

### 🔴 最優先（原因特定）
1. **データローダーの検証** ✅（実施済み）
   - バッチの可視化（画像・マスクのオーバーレイ）
   - 結果: 修正済み

2. **マスクアノテーションの品質確認**
   - 複数サンプルの目視確認
   - アノテーションの妥当性検証

3. **損失値と予測確率分布の確認**
   - 学習初期（Epoch 1-5）の損失推移
   - モデル出力の確率分布（ヒストグラム）
   - 閾値0.01が妥当か判断

### 🟡 次に重要（パラメータ調整）
4. **閾値探索範囲の拡大**
   - min_threshold: 0.001 → 0.0001
   - より低い閾値で最適化

5. **損失関数のパラメータ変更**
   - alpha=0.3→0.5, beta=0.7→0.5（FP/FNのバランスを変える）
   - gamma=0.75→1.0（困難例への注目を強化）

6. **学習率の調整**
   - Learning Rate Finderで最適値を探索
   - 現在の1e-4から変更

### 🟢 長期的な改善（アーキテクチャ変更）
7. **Attention Gateの可視化**
   - Attentionマップを確認し、機能しているか検証

8. **U-Netの深さとチャンネル数の変更**
   - Depth=3, init_features=32（軽量化）
   - Depth=5, init_features=128（重量化）

9. **代替アーキテクチャの検討**
   - U-Net++ （ネステッドスキップ接続）
   - DeepLabV3+（Atrous Convolution）
   - YOLOv8-Seg（YOLOのセグメンテーション版）

---

## 5. 実験計画（Phase 1.6）

### 実験A: 基礎診断（1-2日）
- [ ] マスクアノテーション品質確認（目視）
- [ ] 予測確率分布のログ追加と分析
- [ ] 損失値の詳細分析（各コンポーネント）

### 実験B: パラメータ探索（3-5日）
- [ ] 閾値探索範囲: [0.0001, 0.95]
- [ ] 損失関数パラメータグリッドサーチ
  - alpha: [0.3, 0.5, 0.7]
  - beta: [0.3, 0.5, 0.7]
  - gamma: [0.5, 0.75, 1.0]
- [ ] 学習率: [1e-5, 5e-5, 1e-4, 5e-4]

### 実験C: アーキテクチャ変更（5-7日）
- [ ] Attention可視化スクリプト実装
- [ ] U-Netの深さ・幅の変更
- [ ] 事前学習済みエンコーダ（ResNet, EfficientNet）の転移学習
- [ ] YOLOv8-Segの実装と比較

---

## 6. 結論と今後の方針

### 現時点での結論
セグメンテーションとYOLOの性能差は、以下の複合的な要因によると考えられる：
1. **タスク定義の違い**: ピクセル単位 vs バウンディングボックス
2. **評価指標の厳格さ**: Dice係数 vs IoU 0.5
3. **小物体への最適化**: U-Netの限界 vs YOLOの強み
4. **データ/アノテーションの品質**: マスクの曖昧さ
5. **損失関数/ハイパーパラメータ**: 未最適化

ただし、**YOLOの最終評価指標も0.00**であることから、両方とも現状では学習に失敗している可能性が高い。根本的な原因（データ品質、前処理、アノテーション）の再検証が必要。

### 次のアクション
1. **まず**: 実験A（基礎診断）を完了させ、原因を特定
2. **次に**: 最も有望な改善策（実験B）を試す
3. **最終的に**: 必要に応じてアーキテクチャ変更（実験C）を検討

### 代替アプローチの検討
セグメンテーションが本質的に難しい場合、以下を検討：
- **YOLOv8-Segへの移行**: 物体検出とセグメンテーションのハイブリッド
- **Two-stage方式**: YOLO（粗検出） → U-Net（精密セグメンテーション）
- **Weakly-supervised segmentation**: バウンディングボックスのみで学習

---

## 付録: 参考文献

### セグメンテーションの改善
- [Attention U-Net原論文](https://arxiv.org/abs/1804.03999)
- [Focal Tversky Loss](https://arxiv.org/abs/1810.07842)
- [U-Net++](https://arxiv.org/abs/1807.10165)

### YOLOセグメンテーション
- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [YOLOv8-Seg Architecture](https://github.com/ultralytics/ultralytics)

### 医療画像セグメンテーション
- [nnU-Net](https://github.com/MIC-DKFZ/nnUNet) - 医療画像セグメンテーションのベストプラクティス
