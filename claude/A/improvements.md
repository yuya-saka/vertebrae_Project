## 2025/11/13

### 優先度【高】：学習の破綻を止める根本的な修正

これらは、`val_loss` が上昇し `val_dice` が0のままという、現在の学習が破綻している状態を解決するための**必須の修正**です。

1. **学習率の引き下げ**
    
    - **要件:** `optimizer` の `lr` (学習率) を `0.001` から **`0.0001` (1e-4) または `0.00001` (1e-5)** に大幅に引き下げる。
        
    - **理由:** 現在の `val_loss` の上昇グラフは、学習率が高すぎて損失が「発散」している典型的な症状を示しています。まずは `val_loss` が（わずかでも）下がり始める学習率を見つけることが最優先です。
        
2. **「ロジット vs 確率」の不整合の修正 (最重要バグ)**
    
    - **要件:** モデルの生の出力（**ロジット**）を、確率（0〜1）として扱っている**すべてのロス関数と評価メトリクス**を修正する。
        
    - **理由:** この不整合により、計算される損失とメトリクスが意味をなさず、正しい勾配が伝わっていません。
        
    - **具体的な修正:**
        
        - **分類ロス (`MultiTaskLoss` 内):**
            
            - `F.binary_cross_entropy` → **`F.binary_cross_entropy_with_logits`** に変更する。
                
        - **Segロス (`DiceLoss`, `FocalLoss`):**
            
            - `forward` 関数の**内部で**、入力された `pred` (ロジット) に **`torch.sigmoid()` を適用**してから、DiceやBCEの計算を行う。
                
        - **評価メトリクス (`dice_coefficient`, `iou_score`):**
            
            - `forward` 関数の**内部で**、入力された `pred` (ロジット) に **`torch.sigmoid()` を適用**し、その「確率」をしきい値（例: 0.5）と比較する。
                
        - **分類メトリクス (`compute_metrics_batch`):**
            
            - `pred_class` (ロジット) の二値化は `> 0.5` ではなく **`> 0.0`** で行う。
                

---

### 優先度【中】：補助タスク（セグメンテーション）の有効化

上記【高】の修正で学習が安定し、`val_loss` が下がり始めた後に、補助タスクを意図通りに機能させるための調整です。

3. **補助ロスの重み（スケール）調整**
    
    - **要件:** `loss` の `w_seg` (補助ロスの重み) を `0.1` から **`1.0` に引き上げる**。
        
    - **理由:** `BCE Loss` と `Dice Loss` (または `Focal Dice Loss`) は値のスケールが異なります。`0.1` では補助ロスの影響がほぼ「ゼロ」になり、セグメンテーションが学習されません（`val_dice` が0のままの原因）。
        
    - **方針:** まずは **`w_class: 1.0`**, **`w_seg: 1.0`** の `1:1` で開始し、両方のタスクが（`val_loss_class` と `val_loss_seg` が共に）学習することを確認します。その後、必要に応じて `w_class` の比率を（例: `2.0 : 1.0` などに）上げてメインタスクを重視します。
        

---

### 優先度【低】：正確な性能評価と最適化

学習が機能し、補助タスクも寄与することが確認できた後に、モデルの真の性能を引き出し、正しく評価するための調整です。

4. **セグメンテーション評価の最適化**
    
    - **要件:** `val_dice` / `val_iou` の計算に、固定の `0.5` しきい値を使うのをやめ、**エポックごとに検証データ全体でDiceを最大化する「最適なしきい値」を探索**するロジックを導入する。
        
    - **理由:** `0.5` は最適なパフォーマンスを反映しておらず、モデルの真のセグメンテーション能力を過小評価している可能性が高いです。エポック終了時にすべての検証予測（確率）を集計し、しきい値（例: 0.1～0.9）をスキャンして最高のDiceスコアをそのエポックの公式な `val_dice` として記録します。